{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c4c3b2",
   "metadata": {},
   "source": [
    "# SPR 2026 - BERTimbau + Focal Loss - Treated v1\n",
    "\n",
    "**Texto tratado: Stop words + Lowercase**\n",
    "\n",
    "Base: BERTimbau + Focal Loss (0.79696)\n",
    "Tratamento: Remo√ß√£o de stop words + lowercase\n",
    "\n",
    "---\n",
    "## üì• MODELO - `models/download_bertimbau.ipynb`\n",
    "\n",
    "**Kaggle Models:** Add Input ‚Üí Models ‚Üí `bertimbau-ptbr-complete` (fabianofilho)\n",
    "\n",
    "---\n",
    "**CONFIGURA√á√ÉO KAGGLE:**\n",
    "1. Settings ‚Üí Internet ‚Üí **OFF**\n",
    "2. Settings ‚Üí Accelerator ‚Üí **GPU T4 x2**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SETUP E IMPORTS =====\n",
    "print(\"[1/9] Configurando ambiente...\")\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 5\n",
    "LR = 2e-5\n",
    "NUM_CLASSES = 7\n",
    "FOCAL_GAMMA = 2.0\n",
    "FOCAL_ALPHA = 0.25\n",
    "\n",
    "DATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "\n",
    "# ==== AUTO-DETECTAR PATH DO MODELO ====\n",
    "def find_model_path():\n",
    "    base = '/kaggle/input'\n",
    "    def has_config(path):\n",
    "        return os.path.isdir(path) and os.path.exists(os.path.join(path, 'config.json'))\n",
    "    def search_dir(directory, depth=0, max_depth=10):\n",
    "        if depth > max_depth:\n",
    "            return None\n",
    "        try:\n",
    "            for item in os.listdir(directory):\n",
    "                path = os.path.join(directory, item)\n",
    "                if os.path.isdir(path):\n",
    "                    if has_config(path):\n",
    "                        return path\n",
    "                    result = search_dir(path, depth + 1, max_depth)\n",
    "                    if result:\n",
    "                        return result\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "    return search_dir(base)\n",
    "\n",
    "MODEL_PATH = find_model_path()\n",
    "if MODEL_PATH is None:\n",
    "    raise FileNotFoundError(\"Adicione o modelo BERTimbau ao notebook!\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "print(f'Model: {MODEL_PATH}')\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb0453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== PREPROCESSAMENTO DE TEXTO ====\n",
    "print(\"[2/9] Definindo preprocessamento...\")\n",
    "\n",
    "# Stop words em portugu√™s (customizada para √°rea m√©dica)\n",
    "STOP_WORDS = {\n",
    "    'a', 'o', 'e', 'de', 'da', 'do', 'em', 'um', 'uma', 'para', 'com', 'n√£o',\n",
    "    'na', 'no', 'os', 'as', 'que', 'se', 'por', 'mais', 'como', 'mas', 'foi',\n",
    "    'ao', 'ele', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus',\n",
    "    'quem', 'nas', 'me', 'esse', 'eles', 'est√£o', 'voc√™', 'tinha', 'foram',\n",
    "    'essa', 'num', 'nem', 'suas', 'meu', '√†s', 'minha', 't√™m', 'numa', 'pelos',\n",
    "    'elas', 'havia', 'seja', 'qual', 'ser√°', 'n√≥s', 'tenho', 'lhe', 'deles',\n",
    "    'essas', 'esses', 'pelas', 'este', 'fosse', 'dele', 'tu', 'te', 'voc√™s',\n",
    "    'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso',\n",
    "    'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas',\n",
    "    'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou',\n",
    "    'est√°', 'estamos', 'est√£o', 'estive', 'esteve', 'estivemos', 'estiveram',\n",
    "    'estava', 'est√°vamos', 'estavam', 'estivera', 'estiv√©ramos', 'esteja',\n",
    "    'haja', 'hajamos', 'hajam', 'houve', 'houvemos', 'houveram', 'houvera',\n",
    "    'houver√°', 'haveria', 'houvesse', 'houv√©ssemos', 'houvessem', 'houver',\n",
    "    'houvermos', 'houverem', 'houverei', 'houveremos', 'houveriam', 'sou',\n",
    "    'somos', 's√£o', 'era', '√©ramos', 'eram', 'fui', 'fomos', 'seremos',\n",
    "    'seria', 'seriam', 'fosse', 'f√¥ssemos', 'fossem', 'for', 'formos', 'forem',\n",
    "    'serei', 'ser√≠amos', 'tenha', 'tenhamos', 'tenham', 'teve', 'tivemos',\n",
    "    'tiveram', 'tivera', 'tiv√©ramos', 'tenha', 'tenhamos', 'tenham', 'tiver',\n",
    "    'tivermos', 'tiverem', 'tivesse', 'tiv√©ssemos', 'tivessem', 'ter√°',\n",
    "    # Palavras comuns em laudos mas n√£o relevantes para classifica√ß√£o\n",
    "    'laudo', 'exame', 'paciente', 'data', 'realizado', 'realizada', 'm√©dico',\n",
    "    'dr', 'dra', 'solicitante', 'hospital', 'cl√≠nica', 'mamografia', 'bilateral'\n",
    "}\n",
    "\n",
    "# N√ÉO REMOVER: termos m√©dicos importantes\n",
    "KEEP_WORDS = {\n",
    "    'birads', 'bi-rads', 'calcifica√ß√£o', 'calcifica√ß√µes', 'n√≥dulo', 'n√≥dulos',\n",
    "    'massa', 'massas', 'assimetria', 'assimetrias', 'benigno', 'benigna',\n",
    "    'maligno', 'maligna', 'suspeito', 'suspeita', 'at√≠pico', 'at√≠pica',\n",
    "    'microcalcifica√ß√£o', 'microcalcifica√ß√µes', 'densidade', 'espiculado',\n",
    "    'irregular', 'circunscrito', 'obscurecido', 'linear', 'segmentar',\n",
    "    'regional', 'difuso', 'heterog√™neo', 'homog√™neo', 'categoria', 'achado',\n",
    "    'negativo', 'positivo', 'provavelmente', 'altamente', 'sugestivo'\n",
    "}\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Remove stop words e converte para lowercase.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Normalizar BI-RADS\n",
    "    text = re.sub(r'bi[\\-\\s]?rads?', 'birads', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remover caracteres especiais (manter letras, n√∫meros, espa√ßos)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Tokenizar\n",
    "    words = text.split()\n",
    "    \n",
    "    # Filtrar stop words (mas manter termos m√©dicos importantes)\n",
    "    filtered = []\n",
    "    for word in words:\n",
    "        if word in KEEP_WORDS:\n",
    "            filtered.append(word)\n",
    "        elif word not in STOP_WORDS and len(word) > 1:\n",
    "            filtered.append(word)\n",
    "    \n",
    "    return ' '.join(filtered)\n",
    "\n",
    "# Teste\n",
    "sample = \"A paciente realizou exame de mamografia bilateral. BI-RADS categoria 2, achado benigno.\"\n",
    "print(f\"Original: {sample}\")\n",
    "print(f\"Tratado:  {preprocess_text(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f26169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== FOCAL LOSS ====\n",
    "print(\"[3/9] Definindo Focal Loss...\")\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        return focal_loss\n",
    "\n",
    "criterion = FocalLoss(alpha=FOCAL_ALPHA, gamma=FOCAL_GAMMA)\n",
    "print(f'Focal Loss: gamma={FOCAL_GAMMA}, alpha={FOCAL_ALPHA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a7a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CARREGAR E PREPROCESSAR DADOS ====\n",
    "print(\"[4/9] Carregando e preprocessando dados...\")\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "\n",
    "# Aplicar preprocessamento\n",
    "train_df['report_treated'] = train_df['report'].apply(preprocess_text)\n",
    "test_df['report_treated'] = test_df['report'].apply(preprocess_text)\n",
    "\n",
    "print(f'Train: {train_df.shape}, Test: {test_df.shape}')\n",
    "print(f'\\nExemplo original:\\n{train_df[\"report\"].iloc[0][:200]}...')\n",
    "print(f'\\nExemplo tratado:\\n{train_df[\"report_treated\"].iloc[0][:200]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd097785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== DATASET CLASS ====\n",
    "print(\"[5/9] Preparando dataset...\")\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_len=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            str(self.texts[idx]),\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        item = {\n",
    "            'input_ids': enc['input_ids'].squeeze(),\n",
    "            'attention_mask': enc['attention_mask'].squeeze(),\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "print('Tokenizer carregado!')\n",
    "\n",
    "# Split - usando texto TRATADO\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['report_treated'].values, train_df['target'].values,\n",
    "    test_size=0.1, random_state=SEED, stratify=train_df['target']\n",
    ")\n",
    "\n",
    "train_ds = TextDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_ds = TextDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_ds = TextDataset(test_df['report_treated'].values, None, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f'Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07dff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== MODELO ====\n",
    "print(\"[6/9] Carregando modelo...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    num_labels=NUM_CLASSES,\n",
    "    local_files_only=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f'Modelo carregado! Parametros: {sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== TREINAMENTO ====\n",
    "print(\"[7/9] Treinando modelo...\")\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "            if 'labels' in batch:\n",
    "                labels.extend(batch['labels'].numpy())\n",
    "    if labels:\n",
    "        return f1_score(labels, preds, average='macro')\n",
    "    return preds\n",
    "\n",
    "best_f1 = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS}')\n",
    "    \n",
    "    for batch in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    val_f1 = evaluate(model, val_loader)\n",
    "    print(f'Epoch {epoch+1}: Loss={total_loss/len(train_loader):.4f}, Val F1={val_f1:.4f}')\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), '/kaggle/working/best_model.pt')\n",
    "        print(f'  -> Melhor modelo salvo! F1={best_f1:.4f}')\n",
    "\n",
    "print(f'\\nMelhor F1 valida√ß√£o: {best_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc2bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== PREDI√á√ÉO ====\n",
    "print(\"[8/9] Gerando predi√ß√µes...\")\n",
    "model.load_state_dict(torch.load('/kaggle/working/best_model.pt'))\n",
    "predictions = evaluate(model, test_loader)\n",
    "print(f'Predi√ß√µes geradas: {len(predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e33cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== SUBMISS√ÉO ====\n",
    "print(\"[9/9] Criando submiss√£o...\")\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_df['ID'],\n",
    "    'target': predictions\n",
    "})\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "print('‚úÖ Submiss√£o salva!')\n",
    "print(f'\\nDistribui√ß√£o das predi√ß√µes:')\n",
    "print(submission['target'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
