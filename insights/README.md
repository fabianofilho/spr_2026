# Insights - An√°lise Metodol√≥gica

Esta pasta cont√©m an√°lises metodol√≥gicas dos resultados de cada categoria de modelos.

## Objetivo

Identificar **por que** certos modelos performam melhor que outros, analisando:
- Caracter√≠sticas do dataset
- Adequa√ß√£o da representa√ß√£o textual
- Hiperpar√¢metros e configura√ß√µes
- Trade-offs entre abordagens

## Arquivos

| Arquivo | Categoria | Melhor Score |
|---------|-----------|---------------|
| [transformers.md](transformers.md) | Transformers | **0.79696** üèÜ |
| [ensemble.md](ensemble.md) | Ensemble | 0.78049 |
| [tfidf.md](tfidf.md) | TF-IDF | 0.77885 |
| [sentence_transformers.md](sentence_transformers.md) | SBERT/Custom | 0.77272 |
| [word2vec.md](word2vec.md) | Word2Vec | 0.66385 |

---

## üèÜ Top 4 Modelos - O Que Funciona

| Rank | Modelo | Score | Categoria |
|------|--------|-------|----------|
| 1 | BERTimbau + Focal Loss | **0.79696** | Transformers |
| 2 | BERTimbau + Focal Loss v2 | 0.79505 | Resubmit |
| 3 | Ensemble Soft Voting | 0.78049 | Ensemble |
| 4 | TF-IDF + LinearSVC | 0.77885 | TF-IDF |

---

## ‚ö†Ô∏è Resubmiss√µes (v2/v3) - Li√ß√µes Aprendidas

| Modelo | Original | Resubmit | Delta | Status |
|--------|----------|----------|-------|--------|
| BERTimbau + Focal v2 | 0.79696 | **0.79505** | -0.2% | ‚úÖ OK |
| BERTimbau + Focal v3 | 0.79696 | 0.72625 | -8.9% | ‚ö†Ô∏è |
| Ensemble Soft Voting v2 | 0.78049 | 0.76387 | -2.1% | ‚ö†Ô∏è |
| Custom Transformer v2 | 0.77272 | 0.41721 | -46% | ‚ùå |
| BioBERTpt + Focal v2 | 0.72480 | 0.26099 | -64% | ‚ùå |

### O que deu errado nas resubmiss√µes?

1. **BioBERTpt + Focal v2 (0.26099):** Focal Loss provavelmente mal configurada para BioBERTpt
2. **Custom Transformer v2 (0.41721):** Altera√ß√µes no tokenizer/arquitetura quebraram o modelo
3. **BERTimbau v3 (0.72625):** v3 adicionou mudan√ßas que prejudicaram generaliza√ß√£o
4. **Ensemble v2 (0.76387):** Composi√ß√£o diferente n√£o funcionou t√£o bem

### O que funcionou?

- **BERTimbau + Focal v2 (0.79505):** Mant√©m 99.8% da performance original
- **Conclus√£o:** Mudan√ßas incrementais pequenas s√£o mais seguras

---

## üîë Fatores de Sucesso Identificados

### 1. **Tratamento de Desbalanceamento de Classes**

O dataset tem classes minorit√°rias (BI-RADS 5 e 6) que s√£o cr√≠ticas para o F1-Macro.

| Modelo | T√©cnica | Impacto |
|--------|---------|----------|
| BERTimbau + Focal | Focal Loss (Œ≥=2) | +15% nas classes raras |
| LinearSVC | class_weight='balanced' | Baseline s√≥lido |
| Ensemble | Voting suaviza erros | Reduz falsos negativos |

**Insight:** Focal Loss > Class Weights > Nada

### 2. **Preserva√ß√£o de Termos Espec√≠ficos**

Termos como "BIRADS", "calcifica√ß√£o", "n√≥dulo espiculado" s√£o altamente discriminativos.

| Abordagem | Preserva Termos? | Score |
|-----------|-----------------|-------|
| TF-IDF | ‚úÖ Sim (exata) | 0.778 |
| BERTimbau | ‚úÖ Sim (contextual) | 0.797 |
| Word2Vec (m√©dia) | ‚ùå Dilui | 0.664 |

**Insight:** M√©todos que preservam lexicalidade vencem.

### 3. **Transfer Learning em Portugu√™s**

| Modelo | L√≠ngua | Score |
|--------|--------|-------|
| BERTimbau (PT) | Portugu√™s | **0.797** |
| BioBERTpt (PT) | Portugu√™s | 0.725 |
| ModernBERT (EN) | Ingl√™s | 0.686 |
| BERT Multilingual | Multi | 0.561 |

**Insight:** Modelos nativos PT > Multilingual > Ingl√™s

### 4. **Diversidade no Ensemble**

Soft Voting combina modelos com erros descorrelacionados:

```
Ensemble Soft Voting (0.78049):
‚îú‚îÄ TF-IDF + LinearSVC (0.778) ‚Üí Captura termos exatos
‚îú‚îÄ TF-IDF + SGD (0.750) ‚Üí Regulariza√ß√£o diferente
‚îî‚îÄ TF-IDF + LogReg (0.729) ‚Üí Probabilidades calibradas
```

**Insight:** Voting > Modelo √∫nico quando modelos s√£o diversos.

### 5. **Arquitetura Custom vs Pr√©-treinado**

Custom Transformer Encoder (0.77272) √© competitivo sem pr√©-treino!

| Vantagem | Descri√ß√£o |
|----------|----------|
| Tokenizer espec√≠fico | Vocabul√°rio do dom√≠nio m√©dico |
| Sem overhead | Modelo menor e mais r√°pido |
| Sem transfer gap | Treinado direto no task |

**Insight:** Custom from scratch pode superar modelos multilingual.

---

## ‚ùå O Que N√£o Funciona

### 1. Word2Vec M√©dia
- M√©dia de embeddings dilui informa√ß√£o discriminativa
- Vocabul√°rio m√©dico sub-representado
- Score: 0.56-0.66 (30% abaixo do baseline)

### 5. Resubmiss√µes com Muitas Altera√ß√µes
- BioBERTpt + Focal (0.26) e Custom v2 (0.41) quebraram completamente
- **Li√ß√£o:** Mudan√ßas radicais s√£o arriscadas
- **Recomenda√ß√£o:** Testar uma altera√ß√£o por vez

### 6. Modelos Multilingual
- BERT Multilingual (0.561) e DistilBERT (0.552) decepcionam
- Tokeniza√ß√£o gen√©rica perde termos m√©dicos PT

### 3. LoRA Offline
- BERTimbau + LoRA: 0.132 (FALHA)
- Adapters n√£o salvam corretamente offline
- Full fine-tuning √© mais confi√°vel

### 4. mDeBERTa + fp16
- Bug de mixed precision no Kaggle
- Score: 0.01 (quase aleat√≥rio)

---

## üí° Recomenda√ß√µes

### Para melhorar ainda mais:

1. **Ensemble com BERTimbau + Focal**
   - Adicionar ao Soft Voting pode superar 0.80
   
2. **Focal Loss em outros modelos**
   - Aplicar em BioBERTpt, Custom Transformer
   
3. **Data Augmentation**
   - EDA para classes 5 e 6 (minorit√°rias)
   - SMOTE no espa√ßo de embeddings
   
4. **Pr√©-treino dom√≠nio**
   - MLM com datasets m√©dicos PT
   - PubMed PT, Medical Transcriptions

---

## Resumo Executivo

### Por que BERTimbau + Focal Loss lidera?

1. **L√≠ngua nativa:** Treinado em portugu√™s, entende nuances
2. **Focal Loss:** Foca em exemplos dif√≠ceis/raros
3. **Fine-tuning:** Transfer learning efetivo
4. **Contexto:** Captura "sem sinais de malignidade" vs "com sinais"

### Por que Ensemble √© vice-campe√£o?

Combina√ß√£o de TF-IDF + SVC/SGD/LogReg tem erros descorrelacionados.
Soft voting suaviza predi√ß√µes e melhora robustez.

### Por que TF-IDF ainda √© top 3?

Termos m√©dicos s√£o altamente discriminativos. "BIRADS 4" sozinho
classifica corretamente. TF-IDF captura isso diretamente.

---

*Atualizado em: 25/02/2026*
