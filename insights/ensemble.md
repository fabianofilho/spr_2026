# Ensemble - An√°lise Metodol√≥gica

## Resultados

| Rank | Modelo | Score | Status |
|------|--------|-------|--------|
| ü•à | **VotingClassifier soft** | **0.78049** | ‚úÖ Submetido |
| 2 | TF-IDF + W2V voting | 0.74667 | ‚úÖ Submetido |
| 3 | Stacking Meta-Learner | 0.73852 | ‚úÖ Submetido |

---

## üèÜ An√°lise: Soft Voting (0.78049) - 2¬∫ MELHOR OVERALL!

**Ensemble com Soft Voting superou TF-IDF baseline!** Score de **0.78049** coloca como 2¬∫ melhor modelo geral.

### Por que funcionou?

1. **Erros descorrelacionados:** Cada modelo erra em exemplos diferentes
2. **Soft voting:** M√©dia de probabilidades √© mais robusta que hard voting
3. **Top 3 TF-IDF:** Combina os melhores modelos da categoria
4. **Mesma representa√ß√£o:** Todos usam TF-IDF, garantindo consist√™ncia

### Composi√ß√£o

```python
VotingClassifier([
    ('tfidf_svc', LinearSVC),      # 0.77885 (l√≠der TF-IDF)
    ('tfidf_sgd', SGDClassifier),  # 0.75019 
    ('tfidf_lr', LogisticRegression),  # 0.72935
], voting='soft')
```

### Por que supera modelos individuais?

| Modelo | Score | Erro |
|--------|-------|------|
| LinearSVC | 0.77885 | Erra exemplos amb√≠guos |
| SGDClassifier | 0.75019 | Regulariza√ß√£o diferente |
| LogReg | 0.72935 | Probabilidades calibradas |
| **Ensemble** | **0.78049** | Vota majoritariamente certo |

**Ganho:** +0.16% sobre o melhor modelo individual

---

## An√°lise: TF-IDF + W2V Voting (0.74667)

Combina√ß√£o de TF-IDF com Word2Vec teve resultado misto.

### Por que n√£o superou TF-IDF puro?

1. **Word2Vec adiciona ru√≠do:** Pior nas classes cr√≠ticas
2. **Representa√ß√µes incompat√≠veis:** TF-IDF sparse vs W2V dense
3. **Correla√ß√£o de erros:** Ambos erram nos mesmos exemplos dif√≠ceis

### Li√ß√£o aprendida

> **Ensemble s√≥ melhora se os modelos tiverem erros descorrelacionados.**
> Combinar TF-IDF + W2V √© pior que TF-IDF + TF-IDF com classificadores diferentes.

---

## An√°lise: Stacking Meta-Learner (0.73852)

Stacking com meta-learner LogReg ficou abaixo do esperado.

### Por que n√£o superou Soft Voting?

1. **Overfitting no meta-learner:** CV interno pode ter vazado
2. **Pouca diversidade:** Base learners muito similares
3. **Dataset pequeno:** Insuficiente para treinar meta-learner robusto

### Quando Stacking funciona melhor?

- Datasets maiores (>10k samples)
- Base learners muito diversos (ex: TF-IDF + Transformers + W2V)
- Meta-learner adequado (n√£o-linear como XGBoost)

---

## üí° Pr√≥ximos Passos

### Ensemble com Transformers

Combinar BERTimbau + Focal (0.797) com TF-IDF Ensemble (0.780):

```python
# Proposta: Weighted Blend
final_pred = 0.6 * bertimbau_probs + 0.4 * tfidf_ensemble_probs
```

**Hip√≥tese:** Pode superar 0.80 se erros forem complementares.

### Stacking com Transformers

Usar embeddings de BERTimbau como features para meta-learner:

```python
StackingClassifier(
    estimators=[bertimbau, linearsvc, biobertpt],
    final_estimator=XGBClassifier()
)
```

---

*Atualizado em: 24/02/2026*
