# DeBERTa Model Configuration
# Microsoft's DeBERTa - excellent for text classification

model:
  name: "microsoft/deberta-v3-base"
  max_length: 512
  hidden_dropout_prob: 0.1
  pooling: "cls"
  
# Alternative models to try:
# - "microsoft/deberta-v3-large"
# - "microsoft/deberta-v3-small"
# - "microsoft/mdeberta-v3-base"  # Multilingual

training:
  batch_size: 16
  learning_rate: 1e-5  # DeBERTa benefits from lower LR
  num_epochs: 5
  warmup_ratio: 0.1
  
# DeBERTa specific settings
deberta:
  use_enhanced_mask_decoder: true
