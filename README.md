# SPR 2026 Mammography Report Classification

RepositÃ³rio para o desafio [SPR 2026 Mammography Report Classification](https://www.kaggle.com/competitions/spr-2026-mammography-report-classification).

## Sobre o Desafio

**Code Competition** da SPR para classificaÃ§Ã£o de relatÃ³rios de mamografia em categorias BI-RADS (0-6).

- **MÃ©trica**: F1-Score Macro
- **Formato**: O teste sÃ³ existe no runtime de avaliaÃ§Ã£o do Kaggle

## Leaderboard Atual (Top 10)

| Rank | Modelo | Score |
|------|--------|-------|
| ğŸ¥‡ | **BERTimbau + Focal Loss** | **0.79696** |
| ğŸ¥ˆ | Ensemble Soft Voting | 0.78049 |
| ğŸ¥‰ | TF-IDF + LinearSVC | 0.77885 |
| 4 | Custom Transformer Encoder | 0.77272 |
| 5 | TF-IDF + SGDClassifier | 0.75019 |
| 6 | Ensemble TF-IDF + W2V | 0.74667 |
| 7 | Stacking Meta-Learner | 0.73852 |
| 8 | TF-IDF + Logistic Regression | 0.72935 |
| 9 | BioBERTpt | 0.72480 |
| 10 | TF-IDF + LightGBM | 0.70273 |

> Ver [TODO.md](TODO.md) para lista completa de 27 submissÃµes.

## Estrutura do RepositÃ³rio

```
spr_2026/
â”œâ”€â”€ submit/                    # ğŸ“¤ Notebooks prontos para submeter no Kaggle
â”‚   â”œâ”€â”€ tfidf/                 # TF-IDF + modelos clÃ¡ssicos (12 notebooks)
â”‚   â”œâ”€â”€ word2vec/              # Word2Vec/FastText embeddings
â”‚   â”œâ”€â”€ transformers/          # BERTimbau, ModernBERT, mDeBERTa, etc.
â”‚   â”œâ”€â”€ sentence_transformers/ # SBERT
â”‚   â”œâ”€â”€ ensemble/              # CombinaÃ§Ãµes de modelos
â”‚   â”œâ”€â”€ llm/                   # LLMs zero-shot (Qwen, Gemma, Llama)
â”‚   â””â”€â”€ resubmit/              # Re-submissÃµes com ajustes
â”œâ”€â”€ submissions/               # ğŸ“ CÃ³pia dos notebooks jÃ¡ submetidos (local)
â”œâ”€â”€ notebooks/                 # ğŸ““ Notebooks de exploraÃ§Ã£o e desenvolvimento
â”œâ”€â”€ insights/                  # ğŸ“Š AnÃ¡lises de resultados por categoria
â”œâ”€â”€ models/                    # ğŸ¤– Scripts para download de modelos
â”œâ”€â”€ tests/                     # ğŸ§ª Experimentos
â”‚   â”œâ”€â”€ augmented/             # Data augmentation
â”‚   â”œâ”€â”€ pretrain/              # PrÃ©-treinamento com dados externos
â”‚   â”œâ”€â”€ treated/               # Dados prÃ©-processados
â”‚   â””â”€â”€ review/                # RevisÃ£o de resultados
â”œâ”€â”€ workflows/                 # ğŸ“ Diagramas Excalidraw dos pipelines
â”œâ”€â”€ TODO.md                    # âœ… Tracking de progresso e leaderboard
â”œâ”€â”€ CLAUDE.md                  # ğŸ¤– InstruÃ§Ãµes para o Copilot
â””â”€â”€ requirements.txt           # ğŸ“¦ DependÃªncias
```

## Quick Start

### Kaggle Notebooks (Recomendado)

1. FaÃ§a upload do notebook da pasta `submit/`
2. Adicione os inputs necessÃ¡rios (modelos, datasets)
3. Execute - o notebook detecta automaticamente o ambiente Kaggle

### Google Colab

1. Configure os **Secrets** do Colab:
   - `KAGGLE_USERNAME`: seu username
   - `KAGGLE_KEY`: sua API key

2. Abra qualquer notebook da pasta `notebooks/` e execute

## Categorias de Modelos

| Categoria | Notebooks | Melhor Score | Status |
|-----------|-----------|--------------|--------|
| Transformers | 11 | **0.79696** | âœ… Completo |
| Ensemble | 3 | 0.78049 | âœ… Completo |
| TF-IDF | 12 | 0.77885 | âœ… Completo |
| Custom Transformer | 1 | 0.77272 | âœ… Completo |
| Word2Vec | 7 | 0.66385 | âœ… Completo |
| SBERT | 1 | 0.48376 | âœ… Completo |
| LLMs | 6 | - | â³ Pendente |

## Insights

AnÃ¡lises metodolÃ³gicas por categoria em `insights/`:
- [TF-IDF](insights/tfidf.md) - Benchmark: 0.77885
- [Word2Vec](insights/word2vec.md) - DiagnÃ³stico de falhas
- [Transformers](insights/transformers.md) - AnÃ¡lise de resultados
- [Sentence Transformers](insights/sentence_transformers.md)
- [Ensemble](insights/ensemble.md)

## Dicas

1. **Melhor modelo atÃ© agora**: BERTimbau + Focal Loss (0.79696)
2. **Ensemble**: Soft Voting (0.78049) Ã© o 2Âº melhor modelo!
3. **Custom Transformer**: Tokenizer from scratch (0.77272) supera maioria dos transformers
4. **Class weights**: Use para lidar com desbalanceamento
5. **Offline**: Sempre use `local_files_only=True` no Kaggle
