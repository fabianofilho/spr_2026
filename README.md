# SPR 2026 Mammography Report Classification

Reposit√≥rio para o desafio [SPR 2026 Mammography Report Classification](https://www.kaggle.com/competitions/spr-2026-mammography-report-classification).

## Sobre o Desafio

**Code Competition** da SPR para classifica√ß√£o de relat√≥rios de mamografia em categorias BI-RADS (0-6).

- **M√©trica**: F1-Score Macro
- **Formato**: O teste s√≥ existe no runtime de avalia√ß√£o do Kaggle

## Leaderboard Atual (Top 10)

| Rank | Modelo | Score |
|------|--------|-------|
| ü•á | **BERTimbau + Focal Loss** | **0.79696** |
| ü•à | BERTimbau + Focal Loss v2 | 0.79505 |
| ü•â | Ensemble Soft Voting | 0.78049 |
| 4 | TF-IDF + LinearSVC | 0.77885 |
| 5 | Custom Transformer Encoder | 0.77272 |
| 6 | Ensemble Soft Voting v2 | 0.76387 |
| 7 | TF-IDF + SGDClassifier | 0.75019 |
| 8 | Ensemble TF-IDF + W2V | 0.74667 |
| 9 | Stacking Meta-Learner | 0.73852 |
| 10 | TF-IDF + Logistic Regression | 0.72935 |

> Ver [TODO.md](TODO.md) para lista completa de 32 submiss√µes (incluindo resubmiss√µes).

## Estrutura do Reposit√≥rio

```
spr_2026/
‚îú‚îÄ‚îÄ submit/                    # üì§ Notebooks prontos para submeter no Kaggle
‚îÇ   ‚îú‚îÄ‚îÄ tfidf/                 # TF-IDF + modelos cl√°ssicos (12 notebooks)
‚îÇ   ‚îú‚îÄ‚îÄ word2vec/              # Word2Vec/FastText embeddings
‚îÇ   ‚îú‚îÄ‚îÄ transformers/          # BERTimbau, ModernBERT, mDeBERTa, etc.
‚îÇ   ‚îú‚îÄ‚îÄ sentence_transformers/ # SBERT
‚îÇ   ‚îú‚îÄ‚îÄ ensemble/              # Combina√ß√µes de modelos
‚îÇ   ‚îú‚îÄ‚îÄ llm/                   # LLMs zero-shot (Qwen, Gemma, Llama)
‚îÇ   ‚îî‚îÄ‚îÄ resubmit/              # Re-submiss√µes com ajustes
‚îú‚îÄ‚îÄ submissions/               # üìÅ C√≥pia dos notebooks j√° submetidos (local)
‚îú‚îÄ‚îÄ notebooks/                 # üìì Notebooks de explora√ß√£o e desenvolvimento
‚îú‚îÄ‚îÄ insights/                  # üìä An√°lises de resultados por categoria
‚îú‚îÄ‚îÄ models/                    # ü§ñ Scripts para download de modelos
‚îú‚îÄ‚îÄ tests/                     # üß™ Experimentos
‚îÇ   ‚îú‚îÄ‚îÄ augmented/             # Data augmentation
‚îÇ   ‚îú‚îÄ‚îÄ pretrain/              # Pr√©-treinamento com dados externos
‚îÇ   ‚îú‚îÄ‚îÄ treated/               # Dados pr√©-processados
‚îÇ   ‚îî‚îÄ‚îÄ review/                # Revis√£o de resultados
‚îú‚îÄ‚îÄ workflows/                 # üìê Diagramas Excalidraw dos pipelines
‚îú‚îÄ‚îÄ TODO.md                    # ‚úÖ Tracking de progresso e leaderboard
‚îú‚îÄ‚îÄ CLAUDE.md                  # ü§ñ Instru√ß√µes para o Copilot
‚îî‚îÄ‚îÄ requirements.txt           # üì¶ Depend√™ncias
```

## Quick Start

### Kaggle Notebooks (Recomendado)

1. Fa√ßa upload do notebook da pasta `submit/`
2. Adicione os inputs necess√°rios (modelos, datasets)
3. Execute - o notebook detecta automaticamente o ambiente Kaggle

### Google Colab

1. Configure os **Secrets** do Colab:
   - `KAGGLE_USERNAME`: seu username
   - `KAGGLE_KEY`: sua API key

2. Abra qualquer notebook da pasta `notebooks/` e execute

## Categorias de Modelos

| Categoria | Notebooks | Melhor Score | Status |
|-----------|-----------|--------------|--------|
| Transformers | 11 | **0.79696** | ‚úÖ Completo |
| Ensemble | 3 | 0.78049 | ‚úÖ Completo |
| TF-IDF | 12 | 0.77885 | ‚úÖ Completo |
| Custom Transformer | 1 | 0.77272 | ‚úÖ Completo |
| Word2Vec | 7 | 0.66385 | ‚úÖ Completo |
| SBERT | 1 | 0.48376 | ‚úÖ Completo |
| LLMs | 6 | - | ‚è≥ Pendente |

## Insights

An√°lises metodol√≥gicas por categoria em `insights/`:
- [TF-IDF](insights/tfidf.md) - Benchmark: 0.77885
- [Word2Vec](insights/word2vec.md) - Diagn√≥stico de falhas
- [Transformers](insights/transformers.md) - An√°lise de resultados
- [Sentence Transformers](insights/sentence_transformers.md)
- [Ensemble](insights/ensemble.md)

### Li√ß√µes das Resubmiss√µes (v2/v3)

| Modelo | Original | Resubmit | Status |
|--------|----------|----------|--------|
| BERTimbau + Focal v2 | 0.79696 | 0.79505 | ‚úÖ OK |
| BERTimbau + Focal v3 | 0.79696 | 0.72625 | ‚ö†Ô∏è -8.9% |
| Ensemble Voting v2 | 0.78049 | 0.76387 | ‚ö†Ô∏è -2.1% |
| Custom Transformer v2 | 0.77272 | 0.41721 | ‚ùå -46% |
| BioBERTpt + Focal v2 | 0.72480 | 0.26099 | ‚ùå -64% |

> **Insight:** Altera√ß√µes prejudicaram os modelos. Ver [NEXT.md](NEXT.md) para pr√≥ximos passos.

## Dicas

1. **Melhor modelo at√© agora**: BERTimbau + Focal Loss (0.79696)
2. **Ensemble**: Soft Voting (0.78049) √© o 2¬∫ melhor modelo!
3. **Custom Transformer**: Tokenizer from scratch (0.77272) supera maioria dos transformers
4. **Class weights**: Use para lidar com desbalanceamento
5. **Offline**: Sempre use `local_files_only=True` no Kaggle
