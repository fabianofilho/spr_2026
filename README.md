# SPR 2026 Mammography Report Classification

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![Transformers](https://img.shields.io/badge/Transformers-4.35+-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

RepositÃ³rio para o desafio [SPR 2026 Mammography Report Classification](https://www.kaggle.com/competitions/spr-2026-mammography-report-classification) do Kaggle.

## ğŸ“‹ Sobre o Desafio

A Sociedade Paulista de Radiologia (SPR) estÃ¡ organizando um Desafio de InteligÃªncia Artificial para CÃ¢ncer de Mama. O objetivo Ã© criar uma soluÃ§Ã£o que prediz a **categoria BI-RADS** a partir da seÃ§Ã£o de achados de relatÃ³rios de mamografia.

### O que Ã© BI-RADS?

O sistema BI-RADS (Breast Imaging Reporting and Data System) foi desenvolvido pelo American College of Radiology para padronizar relatÃ³rios de mamografia:

| Categoria | DescriÃ§Ã£o | AÃ§Ã£o Recomendada |
|-----------|-----------|------------------|
| 0 | Incompleto - necessita avaliaÃ§Ã£o adicional | Recall para exames adicionais |
| 1 | Negativo | Rastreamento de rotina |
| 2 | Achado benigno | Rastreamento de rotina |
| 3 | Provavelmente benigno | Seguimento em curto intervalo |
| 4 | Anormalidade suspeita | Considerar biÃ³psia |
| 5 | Altamente sugestivo de malignidade | AÃ§Ã£o apropriada |
| 6 | Malignidade comprovada por biÃ³psia | Tratamento cirÃºrgico/oncolÃ³gico |

### MÃ©tricas

- **MÃ©trica de avaliaÃ§Ã£o**: F1-Score Macro
- **Formato de submissÃ£o**: `ID,target`

## ğŸ—ï¸ Estrutura do Projeto

```
spr_2026/
â”œâ”€â”€ data/                       # Dados do desafio
â”‚   â”œâ”€â”€ train.csv              # Dados de treino
â”‚   â””â”€â”€ test.csv               # Dados de teste (apenas no Kaggle)
â”‚
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_eda.ipynb           # AnÃ¡lise ExploratÃ³ria
â”‚   â””â”€â”€ 02_bert_baseline.ipynb # Baseline com BERT
â”‚
â”œâ”€â”€ src/                        # CÃ³digo fonte
â”‚   â”œâ”€â”€ configs/               # Arquivos de configuraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ base_config.yaml   # ConfiguraÃ§Ãµes base
â”‚   â”‚   â”œâ”€â”€ bert_config.yaml   # Config para BERT
â”‚   â”‚   â”œâ”€â”€ t5_config.yaml     # Config para T5
â”‚   â”‚   â”œâ”€â”€ gemma_config.yaml  # Config para GEMMA
â”‚   â”‚   â””â”€â”€ deberta_config.yaml# Config para DeBERTa
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                # ImplementaÃ§Ãµes dos modelos
â”‚   â”‚   â”œâ”€â”€ bert/              # BERT, BERTimbau, XLM-RoBERTa
â”‚   â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”‚   â””â”€â”€ inference.py
â”‚   â”‚   â”œâ”€â”€ t5/                # T5, mT5, Flan-T5
â”‚   â”‚   â”‚   â””â”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ gemma/             # GEMMA 3 com LoRA/QLoRA
â”‚   â”‚   â”‚   â””â”€â”€ train.py
â”‚   â”‚   â””â”€â”€ deberta/           # DeBERTa v3
â”‚   â”‚       â””â”€â”€ train.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/                 # UtilitÃ¡rios
â”‚       â”œâ”€â”€ common.py          # FunÃ§Ãµes gerais
â”‚       â”œâ”€â”€ data_utils.py      # Dataset e data loading
â”‚       â””â”€â”€ metrics.py         # MÃ©tricas de avaliaÃ§Ã£o
â”‚
â”œâ”€â”€ experiments/               # Outputs dos experimentos
â”œâ”€â”€ submissions/               # Arquivos de submissÃ£o
â”œâ”€â”€ requirements.txt           # DependÃªncias
â””â”€â”€ README.md
```

## ğŸš€ InstalaÃ§Ã£o

```bash
# Clonar repositÃ³rio
git clone https://github.com/fabianofilho/spr_2026.git
cd spr_2026

# Criar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/macOS
# ou: venv\Scripts\activate  # Windows

# Instalar dependÃªncias
pip install -r requirements.txt
```

## ğŸ“¦ Download dos Dados

```bash
# Fazer login no Kaggle (precisa ter ~/.kaggle/kaggle.json configurado)
kaggle competitions download -c spr-2026-mammography-report-classification

# Extrair dados
unzip spr-2026-mammography-report-classification.zip -d data/
```

## ğŸ¯ Modelos DisponÃ­veis

### 1. BERT / BERTimbau

Modelo encoder baseado em BERT, ideal para classificaÃ§Ã£o de texto em portuguÃªs.

```bash
# Treinar BERT
python src/models/bert/train.py --config src/configs/bert_config.yaml

# Treinar apenas fold especÃ­fico
python src/models/bert/train.py --fold 0

# InferÃªncia (ensemble)
python src/models/bert/inference.py --experiment-dir experiments/bert_xxx --test-path data/test.csv
```

**Modelos recomendados:**
- `neuralmind/bert-base-portuguese-cased` (BERTimbau)
- `neuralmind/bert-large-portuguese-cased`
- `xlm-roberta-base`

### 2. T5 / mT5

Modelo sequence-to-sequence que trata classificaÃ§Ã£o como geraÃ§Ã£o de texto.

```bash
python src/models/t5/train.py --config src/configs/t5_config.yaml
```

**Modelos recomendados:**
- `unicamp-dl/ptt5-base-portuguese-vocab` (PTT5)
- `google/flan-t5-base`
- `google/mt5-base`

### 3. GEMMA 3 (com LoRA/QLoRA)

LLM recente do Google com fine-tuning eficiente via LoRA.

```bash
python src/models/gemma/train.py --config src/configs/gemma_config.yaml
```

**Modelos recomendados:**
- `google/gemma-3-4b-it`
- `google/gemma-3-1b-it`

**Requisitos:**
- GPU com pelo menos 16GB VRAM (com QLoRA 4-bit)
- `bitsandbytes` para quantizaÃ§Ã£o

### 4. DeBERTa

Modelo da Microsoft com atenÃ§Ã£o disentangled, excelente para classificaÃ§Ã£o.

```bash
python src/models/deberta/train.py --config src/configs/deberta_config.yaml
```

**Modelos recomendados:**
- `microsoft/deberta-v3-base`
- `microsoft/mdeberta-v3-base` (multilingual)

## ğŸ“Š Notebooks

| Notebook | DescriÃ§Ã£o |
|----------|-----------|
| [01_eda.ipynb](notebooks/01_eda.ipynb) | AnÃ¡lise exploratÃ³ria dos dados |
| [02_bert_baseline.ipynb](notebooks/02_bert_baseline.ipynb) | Baseline com BERT para submissÃ£o no Kaggle |

## âš™ï¸ ConfiguraÃ§Ãµes

Edite os arquivos em `src/configs/` para ajustar hiperparÃ¢metros:

```yaml
# src/configs/base_config.yaml
training:
  seed: 42
  num_folds: 5
  batch_size: 16
  learning_rate: 2e-5
  num_epochs: 5
  
model:
  name: "neuralmind/bert-base-portuguese-cased"
  max_length: 512
```

## ğŸ“ˆ EstratÃ©gias Recomendadas

1. **Tratamento de Desbalanceamento**:
   - Class weights na loss function
   - Focal Loss
   - Oversampling minoritÃ¡rio

2. **Ensemble**:
   - MÃ©dia de probabilidades entre folds
   - Ensemble de diferentes arquiteturas (BERT + DeBERTa + T5)

3. **Data Augmentation**:
   - Back-translation
   - Synonym replacement

4. **OtimizaÃ§Ã£o**:
   - Learning rate warmup
   - Early stopping
   - Gradient accumulation para batch sizes maiores

## ğŸ† SubmissÃ£o no Kaggle

Esta Ã© uma **Code Competition**. Seu notebook deve:

1. Carregar e treinar usando `train.csv`
2. Carregar o test set oculto em runtime
3. Gerar prediÃ§Ãµes
4. Salvar `submission.csv`

```python
# Template para carregar test set
import os
import pandas as pd

test_path = "/kaggle/input/spr-2026-mammography-report-classification/test.csv"

if os.path.exists(test_path):
    test_df = pd.read_csv(test_path)
else:
    raise FileNotFoundError("test.csv only exists in evaluation runtime")
```

## ğŸ“ LicenÃ§a

Este projeto Ã© distribuÃ­do sob a licenÃ§a MIT.

## ğŸ™ Agradecimentos

- Sociedade Paulista de Radiologia (SPR)
- InstituiÃ§Ãµes doadoras de dados: AC Camargo, Hapvida, Unifesp
- Organizadores: Dr. Felipe Kitamura, Dr. Eduardo Farina e equipe

## ğŸ“š ReferÃªncias

- [BI-RADS - American College of Radiology](https://www.acr.org/Clinical-Resources/Clinical-Tools-and-Reference/Reporting-and-Data-Systems/BI-RADS)
- [BERTimbau - Portuguese BERT](https://github.com/neuralmind-ai/portuguese-bert)
- [HuggingFace Transformers](https://huggingface.co/docs/transformers/)

---

**Bom experimento! ğŸš€**
