{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca2b2e8",
   "metadata": {},
   "source": [
    "# ValidaÃ§Ã£o: Sentence Transformers\n",
    "\n",
    "**SBERT - Embeddings para ClassificaÃ§Ã£o**\n",
    "\n",
    "## ðŸ“Š Abordagens\n",
    "1. Embeddings + LogisticRegression\n",
    "2. Embeddings + SVM\n",
    "3. Embeddings + LightGBM\n",
    "4. SetFit (few-shot fine-tuning)\n",
    "\n",
    "## ðŸŽ¯ Modelos Testados\n",
    "- `paraphrase-multilingual-MiniLM-L12-v2` (multilingual)\n",
    "- `all-MiniLM-L6-v2` (rÃ¡pido, inglÃªs)\n",
    "- Custom embedding com fine-tuning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f7d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    DATA_DIR = '/kaggle/input/competitions/spr-2026-mammography-report-classification'\n",
    "    def find_model_path():\n",
    "        base = '/kaggle/input'\n",
    "        def search_dir(directory, depth=0, max_depth=10):\n",
    "            if depth > max_depth: return None\n",
    "            try:\n",
    "                for item in os.listdir(directory):\n",
    "                    path = os.path.join(directory, item)\n",
    "                    if os.path.isdir(path) and os.path.exists(os.path.join(path, 'modules.json')):\n",
    "                        return path\n",
    "                    result = search_dir(path, depth + 1, max_depth) if os.path.isdir(path) else None\n",
    "                    if result: return result\n",
    "            except: pass\n",
    "            return None\n",
    "        return search_dir(base)\n",
    "    MODEL_PATH = find_model_path()\n",
    "else:\n",
    "    DATA_DIR = '../data'\n",
    "    MODEL_PATH = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "\n",
    "print(f'Model: {MODEL_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c7eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DADOS =====\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['report'].tolist(),\n",
    "    train_df['target'].tolist(),\n",
    "    test_size=0.2,\n",
    "    stratify=train_df['target'],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "print(f'Train: {len(train_texts)}, Val: {len(val_texts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb37965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CARREGAR SENTENCE TRANSFORMER =====\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(MODEL_PATH)\n",
    "print(f'Model loaded: {model.get_sentence_embedding_dimension()} dims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2cf06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== GERAR EMBEDDINGS =====\n",
    "print('Gerando embeddings...')\n",
    "\n",
    "train_embeddings = model.encode(train_texts, show_progress_bar=True)\n",
    "val_embeddings = model.encode(val_texts, show_progress_bar=True)\n",
    "\n",
    "print(f'Train embeddings: {train_embeddings.shape}')\n",
    "print(f'Val embeddings: {val_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8771efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TESTE 1: LOGISTIC REGRESSION =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=SEED, class_weight='balanced')\n",
    "lr_model.fit(train_embeddings, train_labels)\n",
    "\n",
    "lr_preds = lr_model.predict(val_embeddings)\n",
    "lr_f1 = f1_score(val_labels, lr_preds, average='macro')\n",
    "\n",
    "print(f'F1-Macro: {lr_f1:.5f}')\n",
    "print(classification_report(val_labels, lr_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f500fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TESTE 2: SVM =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SVM (RBF kernel)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "svm_model = SVC(kernel='rbf', random_state=SEED, class_weight='balanced')\n",
    "svm_model.fit(train_embeddings, train_labels)\n",
    "\n",
    "svm_preds = svm_model.predict(val_embeddings)\n",
    "svm_f1 = f1_score(val_labels, svm_preds, average='macro')\n",
    "\n",
    "print(f'F1-Macro: {svm_f1:.5f}')\n",
    "print(classification_report(val_labels, svm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2793de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TESTE 3: LIGHTGBM =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LightGBM\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    \n",
    "    lgb_model = lgb.LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        num_leaves=31,\n",
    "        random_state=SEED,\n",
    "        class_weight='balanced',\n",
    "        verbose=-1\n",
    "    )\n",
    "    lgb_model.fit(train_embeddings, train_labels)\n",
    "    \n",
    "    lgb_preds = lgb_model.predict(val_embeddings)\n",
    "    lgb_f1 = f1_score(val_labels, lgb_preds, average='macro')\n",
    "    \n",
    "    print(f'F1-Macro: {lgb_f1:.5f}')\n",
    "    print(classification_report(val_labels, lgb_preds))\n",
    "except ImportError:\n",
    "    print('LightGBM nÃ£o instalado')\n",
    "    lgb_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28963eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TESTE 4: SETFIT (Few-shot) =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SetFit (Few-shot fine-tuning)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    from setfit import SetFitModel, SetFitTrainer\n",
    "    from datasets import Dataset\n",
    "    \n",
    "    # Criar dataset\n",
    "    train_dataset = Dataset.from_dict({'text': train_texts, 'label': train_labels})\n",
    "    val_dataset = Dataset.from_dict({'text': val_texts, 'label': val_labels})\n",
    "    \n",
    "    # Modelo SetFit\n",
    "    setfit_model = SetFitModel.from_pretrained(MODEL_PATH)\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = SetFitTrainer(\n",
    "        model=setfit_model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        num_iterations=20,\n",
    "        num_epochs=1,\n",
    "        batch_size=16,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    setfit_preds = setfit_model.predict(val_texts)\n",
    "    setfit_f1 = f1_score(val_labels, setfit_preds, average='macro')\n",
    "    \n",
    "    print(f'F1-Macro: {setfit_f1:.5f}')\n",
    "except ImportError:\n",
    "    print('SetFit nÃ£o instalado')\n",
    "    setfit_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6972ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== RESUMO =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Š RESUMO - Sentence Transformers Validation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = [\n",
    "    ('LogisticRegression', lr_f1),\n",
    "    ('SVM (RBF)', svm_f1),\n",
    "    ('LightGBM', lgb_f1),\n",
    "    ('SetFit', setfit_f1),\n",
    "]\n",
    "\n",
    "for name, f1 in sorted(results, key=lambda x: -x[1]):\n",
    "    if f1 > 0:\n",
    "        print(f\"{name:<20} {f1:.5f}\")\n",
    "\n",
    "print(f\"\\nðŸ“ ReferÃªncia (TF-IDF): 0.77885\")\n",
    "print(f\"ðŸ“ ReferÃªncia (BERTimbau v4): 0.82073\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe5dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== INSIGHTS =====\n",
    "print(\"\"\"\n",
    "ðŸ“ INSIGHTS - Sentence Transformers\n",
    "====================================\n",
    "\n",
    "1. **Embeddings prÃ©-treinados:**\n",
    "   - RÃ¡pidos para gerar\n",
    "   - Consistentes entre runs\n",
    "\n",
    "2. **ComparaÃ§Ã£o de classificadores:**\n",
    "   - [PREENCHER]\n",
    "\n",
    "3. **SetFit:**\n",
    "   - Fine-tuning sem grandes GPUs\n",
    "   - Bom para few-shot\n",
    "\n",
    "4. **Uso em Ensemble:**\n",
    "   - Pode complementar transformers full\n",
    "   - RÃ¡pido para voting ensemble\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
