{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07f65e1",
   "metadata": {},
   "source": [
    "# Valida√ß√£o: LLMs Zero/Few-shot\n",
    "\n",
    "**Modelos de Linguagem para Classifica√ß√£o**\n",
    "\n",
    "## üìä Modelos Testados\n",
    "- Qwen 3 (4B) - Zero-shot e Few-shot\n",
    "- MedGemma (4B) - Zero-shot com instru√ß√£o BI-RADS\n",
    "- Phi-3.5 (3.8B) - Compara√ß√£o\n",
    "\n",
    "## üéØ Objetivo\n",
    "Avaliar performance de LLMs sem fine-tuning para classifica√ß√£o BI-RADS.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51190bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    DATA_DIR = '/kaggle/input/competitions/spr-2026-mammography-report-classification'\n",
    "    def find_model_path():\n",
    "        base = '/kaggle/input'\n",
    "        def search_dir(directory, depth=0, max_depth=10):\n",
    "            if depth > max_depth: return None\n",
    "            try:\n",
    "                for item in os.listdir(directory):\n",
    "                    path = os.path.join(directory, item)\n",
    "                    if os.path.isdir(path) and os.path.exists(os.path.join(path, 'config.json')):\n",
    "                        return path\n",
    "                    result = search_dir(path, depth + 1, max_depth) if os.path.isdir(path) else None\n",
    "                    if result: return result\n",
    "            except: pass\n",
    "            return None\n",
    "        return search_dir(base)\n",
    "    MODEL_PATH = find_model_path()\n",
    "else:\n",
    "    DATA_DIR = '../data'\n",
    "    MODEL_PATH = 'Qwen/Qwen3-4B-Instruct'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "print(f'Model: {MODEL_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DADOS =====\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "# Usar amostra menor para valida√ß√£o (LLMs s√£o lentos)\n",
    "train_sample = train_df.groupby('target', group_keys=False).apply(\n",
    "    lambda x: x.sample(min(30, len(x)), random_state=SEED)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_sample['report'].tolist(),\n",
    "    train_sample['target'].tolist(),\n",
    "    test_size=0.3,  # Mais para valida√ß√£o porque √© amostra pequena\n",
    "    stratify=train_sample['target'],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "print(f'Train: {len(train_texts)}, Val: {len(val_texts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f253f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== PROMPTS =====\n",
    "\n",
    "# Zero-shot PT-BR\n",
    "SYSTEM_PROMPT_ZERO = \"\"\"Voc√™ √© um radiologista especialista em classifica√ß√£o BI-RADS de mamografias.\n",
    "\n",
    "## Categorias BI-RADS:\n",
    "- 0: Incompleto - necessita imagens adicionais\n",
    "- 1: Negativo - mamografia normal\n",
    "- 2: Benigno - achados definitivamente benignos\n",
    "- 3: Provavelmente benigno - <2% malignidade, seguimento 6 meses\n",
    "- 4: Suspeito - 2-95% malignidade, bi√≥psia recomendada\n",
    "- 5: Altamente sugestivo de malignidade - >95%\n",
    "- 6: Malignidade comprovada por bi√≥psia\n",
    "\n",
    "Responda APENAS com o n√∫mero da categoria (0-6).\"\"\"\n",
    "\n",
    "# Few-shot com exemplos\n",
    "FEW_SHOT_EXAMPLES = \"\"\"\n",
    "## Exemplos:\n",
    "\n",
    "Relat√≥rio: \"Exame realizado para controle. Imagens mostram par√™nquima mam√°rio denso, sem n√≥dulos, calcifica√ß√µes suspeitas ou distor√ß√µes arquiteturais.\"\n",
    "BI-RADS: 1\n",
    "\n",
    "Relat√≥rio: \"Presen√ßa de n√≥dulo oval, circunscrito, paralelo √† pele, no QSE da mama direita, medindo 8mm, com caracter√≠sticas benignas.\"\n",
    "BI-RADS: 2\n",
    "\n",
    "Relat√≥rio: \"N√≥dulo irregular, de contornos microlobulados, com 15mm na JQQ da mama direita. Bi√≥psia recomendada.\"\n",
    "BI-RADS: 4\n",
    "\n",
    "Relat√≥rio: \"Les√£o espiculada, densa, de 25mm na regi√£o retroareolar esquerda, associada a microcalcifica√ß√µes pleom√≥rficas.\"\n",
    "BI-RADS: 5\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_FEW = SYSTEM_PROMPT_ZERO + FEW_SHOT_EXAMPLES\n",
    "\n",
    "USER_TEMPLATE = \"\"\"Relat√≥rio:\n",
    "{report}\n",
    "\n",
    "BI-RADS:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa943b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CARREGAR MODELO =====\n",
    "print(\"Carregando modelo...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH, local_files_only=True,\n",
    "    torch_dtype=torch.bfloat16, device_map=\"auto\", low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"Modelo carregado: {model.config.architectures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8795696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FUN√á√ÉO DE CLASSIFICA√á√ÉO =====\n",
    "def classify_report(report, system_prompt, max_tokens=10):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": USER_TEMPLATE.format(report=report)}\n",
    "    ]\n",
    "    \n",
    "    if hasattr(tokenizer, 'apply_chat_template'):\n",
    "        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    else:\n",
    "        text = f\"{system_prompt}\\n\\n{USER_TEMPLATE.format(report=report)}\"\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=4096)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, max_new_tokens=max_tokens, do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    \n",
    "    # Extrair n√∫mero\n",
    "    for char in response.strip():\n",
    "        if char.isdigit() and char in '0123456':\n",
    "            return int(char)\n",
    "    return 2  # Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b25efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TESTE 1: ZERO-SHOT =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Zero-shot Classification\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "zero_preds = [\n",
    "    classify_report(text, SYSTEM_PROMPT_ZERO) \n",
    "    for text in tqdm(val_texts, desc='Zero-shot')\n",
    "]\n",
    "\n",
    "zero_f1 = f1_score(val_labels, zero_preds, average='macro')\n",
    "print(f'F1-Macro: {zero_f1:.5f}')\n",
    "print(classification_report(val_labels, zero_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c7fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TESTE 2: FEW-SHOT =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Few-shot Classification (4 exemplos)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "few_preds = [\n",
    "    classify_report(text, SYSTEM_PROMPT_FEW) \n",
    "    for text in tqdm(val_texts, desc='Few-shot')\n",
    "]\n",
    "\n",
    "few_f1 = f1_score(val_labels, few_preds, average='macro')\n",
    "print(f'F1-Macro: {few_f1:.5f}')\n",
    "print(classification_report(val_labels, few_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2fd6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== AN√ÅLISE DE ERROS =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"An√°lise de Erros (Few-shot)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "errors = []\n",
    "for i, (text, true, pred) in enumerate(zip(val_texts, val_labels, few_preds)):\n",
    "    if true != pred:\n",
    "        errors.append({\n",
    "            'text': text[:100] + '...',\n",
    "            'true': true,\n",
    "            'pred': pred\n",
    "        })\n",
    "\n",
    "print(f'Total erros: {len(errors)} / {len(val_labels)} ({100*len(errors)/len(val_labels):.1f}%)')\n",
    "print('\\nExemplos de erros:')\n",
    "for e in errors[:5]:\n",
    "    print(f\"  True: {e['true']}, Pred: {e['pred']} | {e['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== RESUMO =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä RESUMO - LLM Validation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = [\n",
    "    ('Zero-shot', zero_f1),\n",
    "    ('Few-shot (4 ex)', few_f1),\n",
    "]\n",
    "\n",
    "for name, f1 in sorted(results, key=lambda x: -x[1]):\n",
    "    print(f\"{name:<20} {f1:.5f}\")\n",
    "\n",
    "print(f\"\\nüìù Refer√™ncia (TF-IDF): 0.77885\")\n",
    "print(f\"üìù Refer√™ncia (BERTimbau v4): 0.82073\")\n",
    "print(f\"\\n‚ö†Ô∏è LLMs s√£o mais lentos (~10x) que transformers fine-tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed35d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== INSIGHTS =====\n",
    "print(\"\"\"\n",
    "üìù INSIGHTS - LLMs Zero/Few-shot\n",
    "=================================\n",
    "\n",
    "1. **Zero vs Few-shot:**\n",
    "   - [PREENCHER AP√ìS EXPERIMENTOS]\n",
    "   - Exemplos geralmente ajudam\n",
    "\n",
    "2. **BI-RADS espec√≠fico:**\n",
    "   - Prompt com descri√ß√µes detalhadas ajuda\n",
    "   - Modelo pode confundir categorias adjacentes\n",
    "\n",
    "3. **Limita√ß√µes:**\n",
    "   - MUITO mais lento que fine-tuning\n",
    "   - N√£o aprende padr√µes espec√≠ficos do dataset\n",
    "   - Token limit pode truncar relat√≥rios longos\n",
    "\n",
    "4. **Quando usar:**\n",
    "   - Como baseline sem treino\n",
    "   - Para casos amb√≠guos (ensemble)\n",
    "   - Para explicabilidade\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
