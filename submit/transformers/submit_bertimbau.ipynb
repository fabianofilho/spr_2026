{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPR 2026 - BERTimbau\n",
    "\n",
    "**Config:** Add Input -> Models -> bertimbau-ptbr-complete (fabianofilho), Internet OFF, GPU T4 x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd, torch, warnings\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED, DATA_DIR = 42, '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "MAX_LENGTH, BATCH_SIZE, EPOCHS, LR = 512, 8, 3, 2e-5\n",
    "\n",
    "def find_model_path():\n",
    "    base = '/kaggle/input'\n",
    "    def search(d, depth=0):\n",
    "        if depth > 10: return None\n",
    "        try:\n",
    "            for item in os.listdir(d):\n",
    "                p = os.path.join(d, item)\n",
    "                if os.path.isdir(p):\n",
    "                    if os.path.exists(os.path.join(p, 'config.json')): return p\n",
    "                    r = search(p, depth+1)\n",
    "                    if r: return r\n",
    "        except: pass\n",
    "        return None\n",
    "    return search(base)\n",
    "\n",
    "MODEL_PATH = find_model_path()\n",
    "if not MODEL_PATH: raise FileNotFoundError('Modelo nao encontrado!')\n",
    "print(f'Model: {MODEL_PATH}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "np.random.seed(SEED); torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "print(f'Train: {train_df.shape}, Test: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_len=512):\n",
    "        self.texts, self.labels, self.tokenizer, self.max_len = texts, labels, tokenizer, max_len\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(str(self.texts[idx]), truncation=True, max_length=self.max_len, padding='max_length', return_tensors='pt')\n",
    "        item = {'input_ids': enc['input_ids'].squeeze(), 'attention_mask': enc['attention_mask'].squeeze()}\n",
    "        if self.labels is not None: item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "\n",
    "# COLUNAS CORRETAS: report e target\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['report'].tolist(), train_df['target'].tolist(), test_size=0.1, stratify=train_df['target'], random_state=SEED)\n",
    "\n",
    "train_ds = TextDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n",
    "val_ds = TextDataset(val_texts, val_labels, tokenizer, MAX_LENGTH)\n",
    "print(f'Train: {len(train_ds)}, Val: {len(val_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p): return {'f1_macro': f1_score(p.label_ids, np.argmax(p.predictions, axis=1), average='macro')}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=7, local_files_only=True)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='/kaggle/working/model', num_train_epochs=EPOCHS, per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE*2, learning_rate=LR, weight_decay=0.01, warmup_ratio=0.1,\n",
    "    fp16=torch.cuda.is_available(), eval_strategy='epoch', save_strategy='epoch',\n",
    "    load_best_model_at_end=True, metric_for_best_model='f1_macro', greater_is_better=True, report_to='none', seed=SEED)\n",
    "\n",
    "trainer = Trainer(model=model, args=args, train_dataset=train_ds, eval_dataset=val_ds, compute_metrics=compute_metrics)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicao e Submissao\n",
    "test_ds = TextDataset(test_df['report'].tolist(), None, tokenizer, MAX_LENGTH)\n",
    "preds = np.argmax(trainer.predict(test_ds).predictions, axis=1)\n",
    "\n",
    "# COLUNAS CORRETAS: ID e target\n",
    "submission = pd.DataFrame({'ID': test_df['ID'], 'target': preds})\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "print('CONCLUIDO!')\n",
    "print(dict(submission['target'].value_counts().sort_index()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPR 2026 - BERTimbau\n",
    "\n",
    "**Config:** Add Input -> Models -> bertimbau-ptbr-complete (fabianofilho), Internet OFF, GPU T4 x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd, torch, warnings\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED, DATA_DIR = 42, \"/kaggle/input/spr-2026-mammography-report-classification\"\n",
    "MAX_LENGTH, BATCH_SIZE, EPOCHS, LR = 512, 8, 3, 2e-5\n",
    "\n",
    "def find_model_path():\n",
    "    base = \"/kaggle/input\"\n",
    "    def search(d, depth=0):\n",
    "        if depth > 10: return None\n",
    "        try:\n",
    "            for item in os.listdir(d):\n",
    "                p = os.path.join(d, item)\n",
    "                if os.path.isdir(p):\n",
    "                    if os.path.exists(os.path.join(p, \"config.json\")): return p\n",
    "                    r = search(p, depth+1)\n",
    "                    if r: return r\n",
    "        except: pass\n",
    "        return None\n",
    "    return search(base)\n",
    "\n",
    "MODEL_PATH = find_model_path()\n",
    "if not MODEL_PATH: raise FileNotFoundError(\"Modelo nao encontrado!\")\n",
    "print(f\"Model: {MODEL_PATH}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "np.random.seed(SEED); torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{DATA_DIR}/train.csv\")\n",
    "test_df = pd.read_csv(f\"{DATA_DIR}/test.csv\")\n",
    "print(f\"Train: {train_df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_len=512):\n",
    "        self.texts, self.labels, self.tokenizer, self.max_len = texts, labels, tokenizer, max_len\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(str(self.texts[idx]), truncation=True, max_length=self.max_len, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        item = {\"input_ids\": enc[\"input_ids\"].squeeze(), \"attention_mask\": enc[\"attention_mask\"].squeeze()}\n",
    "        if self.labels is not None: item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "\n",
    "# COLUNAS CORRETAS: report e target\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df[\"report\"].tolist(), train_df[\"target\"].tolist(), test_size=0.1, stratify=train_df[\"target\"], random_state=SEED)\n",
    "\n",
    "train_ds = TextDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n",
    "val_ds = TextDataset(val_texts, val_labels, tokenizer, MAX_LENGTH)\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p): return {\"f1_macro\": f1_score(p.label_ids, np.argmax(p.predictions, axis=1), average=\"macro\")}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=7, local_files_only=True)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/model\", num_train_epochs=EPOCHS, per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE*2, learning_rate=LR, weight_decay=0.01, warmup_ratio=0.1,\n",
    "    fp16=torch.cuda.is_available(), eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True, metric_for_best_model=\"f1_macro\", greater_is_better=True, report_to=\"none\", seed=SEED)\n",
    "\n",
    "trainer = Trainer(model=model, args=args, train_dataset=train_ds, eval_dataset=val_ds, compute_metrics=compute_metrics)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicao e Submissao\n",
    "test_ds = TextDataset(test_df[\"report\"].tolist(), None, tokenizer, MAX_LENGTH)\n",
    "preds = np.argmax(trainer.predict(test_ds).predictions, axis=1)\n",
    "\n",
    "# COLUNAS CORRETAS: ID e target\n",
    "submission = pd.DataFrame({\"ID\": test_df[\"ID\"], \"target\": preds})\n",
    "submission.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "print(\"CONCLUIDO!\")\n",
    "print(dict(submission[\"target\"].value_counts().sort_index()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
