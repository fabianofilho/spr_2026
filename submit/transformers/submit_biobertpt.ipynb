{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08a8335",
   "metadata": {},
   "source": [
    "# SPR 2026 - BioBERTpt (Biom√©dico Portugu√™s)\n",
    "\n",
    "**BioBERTpt pr√©-treinado em textos biom√©dicos PT-BR**\n",
    "\n",
    "- ‚úÖ Dom√≠nio m√©dico espec√≠fico\n",
    "- ‚úÖ PUCPR `pucpr/biobertpt-all`\n",
    "- ‚úÖ Tempo esperado: ~15-20 min\n",
    "\n",
    "---\n",
    "## üì• MODELO - Baixar com: `models/download_biobertpt.ipynb`\n",
    "\n",
    "1. Rode `models/download_biobertpt.ipynb` no Kaggle com Internet ON\n",
    "2. Save Version -> Save & Run All\n",
    "3. Neste notebook: Add Input -> Your Work -> `download-biobertpt`\n",
    "\n",
    "---\n",
    "**CONFIGURA√á√ÉO KAGGLE:**\n",
    "1. Settings ‚Üí Internet ‚Üí **OFF**\n",
    "2. Settings ‚Üí Accelerator ‚Üí **GPU T4 x2**\n",
    "3. Add Input ‚Üí Your Work ‚Üí output do notebook `download-biobertpt`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a25406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Config\n",
    "SEED = 42\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "LR = 2e-5\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "DATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "MODEL_PATH = '/kaggle/input/biobertpt-all'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "\n",
    "print(f'Train: {train_df.shape}')\n",
    "print(f'Test: {test_df.shape}')\n",
    "print(f'\\nDistribui√ß√£o:')\n",
    "print(train_df['target'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c76ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['report'].values,\n",
    "    train_df['target'].values,\n",
    "    test_size=0.15,\n",
    "    random_state=SEED,\n",
    "    stratify=train_df['target']\n",
    ")\n",
    "\n",
    "print(f'Train: {len(train_texts)}, Val: {len(val_texts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer e Dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = tokenizer(\n",
    "            self.texts[idx],\n",
    "            max_length=MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0)\n",
    "        }\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            \n",
    "        return item\n",
    "\n",
    "train_dataset = TextDataset(train_texts, train_labels)\n",
    "val_dataset = TextDataset(val_texts, val_labels)\n",
    "test_dataset = TextDataset(test_df['report'].values)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo BioBERTpt\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    num_labels=NUM_CLASSES\n",
    ").to(device)\n",
    "\n",
    "print(f'Params: {sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer e Scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * total_steps),\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda81049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    for batch in tqdm(loader, desc='Training'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        preds.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
    "        targets.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return total_loss / len(loader), f1_score(targets, preds, average='macro')\n",
    "\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return f1_score(targets, preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185dbdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\nEpoch {epoch+1}/{EPOCHS}')\n",
    "    \n",
    "    train_loss, train_f1 = train_epoch(model, train_loader, criterion, optimizer, scheduler)\n",
    "    val_f1 = evaluate(model, val_loader)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f}')\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(f'Novo melhor modelo! F1: {best_f1:.4f}')\n",
    "\n",
    "print(f'\\nMelhor F1: {best_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173cbee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predi√ß√µes\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Predicting'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "\n",
    "# Submiss√£o\n",
    "submission = pd.DataFrame({'ID': test_df['ID'], 'target': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('submission.csv criado!')\n",
    "print(submission['target'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
