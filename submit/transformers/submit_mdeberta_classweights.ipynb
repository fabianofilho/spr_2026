{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290373cd",
   "metadata": {},
   "source": [
    "# SPR 2026 - mDeBERTa-v3 + Class Weights\n",
    "\n",
    "**mDeBERTa com Class Weights para desbalanceamento**\n",
    "\n",
    "- ‚úÖ Class weights computados automaticamente\n",
    "- ‚úÖ CrossEntropyLoss ponderado\n",
    "- ‚úÖ Tempo esperado: ~15-20 min\n",
    "\n",
    "---\n",
    "## üì• MODELO NECESS√ÅRIO\n",
    "\n",
    "**Op√ß√£o 1 - Notebook de download (recomendado):**\n",
    "1. Rode `models/download_mdeberta.ipynb` no Kaggle com **Internet ON**\n",
    "2. Save Version ‚Üí Save & Run All (Commit)\n",
    "3. Aqui: Add Input ‚Üí **Your Work** ‚Üí selecione o notebook `download-mdeberta`\n",
    "\n",
    "**Op√ß√£o 2 - Kaggle Datasets:**\n",
    "- Add Input ‚Üí **Datasets** ‚Üí buscar `mdeberta_v3_base` (Jonathan Chan)\n",
    "\n",
    "> ‚ö†Ô∏è O c√≥digo usa `find_model_path()` para encontrar automaticamente o modelo em qualquer estrutura de pastas.\n",
    "\n",
    "---\n",
    "**CONFIGURA√á√ÉO KAGGLE:**\n",
    "1. Settings ‚Üí Internet ‚Üí **OFF**\n",
    "2. Settings ‚Üí Accelerator ‚Üí **GPU T4 x2**\n",
    "3. Add Input ‚Üí adicione o modelo (op√ß√£o 1 ou 2 acima)\n",
    "4. **IMPORTANTE:** Execute \"Run All\" ap√≥s commit\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dcae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Config\n",
    "SEED = 42\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "LR = 2e-5\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "DATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "\n",
    "# Paths poss√≠veis para mDeBERTa (datasets do Kaggle)\n",
    "MODEL_PATHS = [\n",
    "    '/kaggle/input/mdeberta-v3-base',\n",
    "    '/kaggle/input/mdeberta_v3_base',\n",
    "    '/kaggle/input/huggingface-deberta',\n",
    "    '/kaggle/input/mdebertav3base',\n",
    "    '/kaggle/input/microsoft-mdeberta-v3-base',\n",
    "]\n",
    "\n",
    "MODEL_PATH = None\n",
    "for path in MODEL_PATHS:\n",
    "    if os.path.exists(path):\n",
    "        MODEL_PATH = path\n",
    "        break\n",
    "\n",
    "if MODEL_PATH is None:\n",
    "    print(\"\\n‚ö†Ô∏è mDeBERTa n√£o encontrado. Datasets dispon√≠veis:\")\n",
    "    for item in os.listdir('/kaggle/input'):\n",
    "        print(f\"  - {item}\")\n",
    "    raise FileNotFoundError(\"Adicione um dataset com mDeBERTa-v3-base!\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "print(f'Model: {MODEL_PATH}')\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f65b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "\n",
    "print(f'Train: {train_df.shape}')\n",
    "print(f'Test: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6409c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(NUM_CLASSES),\n",
    "    y=train_df['target'].values\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(f'Class weights: {class_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['report'].values,\n",
    "    train_df['target'].values,\n",
    "    test_size=0.15,\n",
    "    random_state=SEED,\n",
    "    stratify=train_df['target']\n",
    ")\n",
    "\n",
    "print(f'Train: {len(train_texts)}, Val: {len(val_texts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85b332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer e Dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = tokenizer(\n",
    "            self.texts[idx],\n",
    "            max_length=MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0)\n",
    "        }\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            \n",
    "        return item\n",
    "\n",
    "train_dataset = TextDataset(train_texts, train_labels)\n",
    "val_dataset = TextDataset(val_texts, val_labels)\n",
    "test_dataset = TextDataset(test_df['report'].values)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b438b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    num_labels=NUM_CLASSES\n",
    ").to(device)\n",
    "\n",
    "print(f'Params: {sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6973773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer e Scheduler\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * total_steps),\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ddac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    for batch in tqdm(loader, desc='Training'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        preds.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
    "        targets.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return total_loss / len(loader), f1_score(targets, preds, average='macro')\n",
    "\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return f1_score(targets, preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c54aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\nEpoch {epoch+1}/{EPOCHS}')\n",
    "    \n",
    "    train_loss, train_f1 = train_epoch(model, train_loader, criterion, optimizer, scheduler)\n",
    "    val_f1 = evaluate(model, val_loader)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f}')\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(f'Novo melhor modelo! F1: {best_f1:.4f}')\n",
    "\n",
    "print(f'\\nMelhor F1: {best_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9139972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predi√ß√µes\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Predicting'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "\n",
    "# Submiss√£o\n",
    "submission = pd.DataFrame({'ID': test_df['ID'], 'target': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('submission.csv criado!')\n",
    "print(submission['target'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
