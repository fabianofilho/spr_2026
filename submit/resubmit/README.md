# Resubmit - Modelos Top 5 (Score > 0.7)

## Objetivo
Melhorar os melhores modelos baseline com t√©cnicas para lidar com o **desbalanceamento de classes**.

---

## üèÜ Melhor Modelo: BERTimbau + Focal Loss (0.79696)

| Vers√£o | Notebook | Estrat√©gias | Status |
|--------|----------|-------------|--------|
| v3 | `resubmit_bertimbau_focal_v3.ipynb` | Alpha por classe + Threshold tuning + Label smoothing | ‚è≥ |

---

## üÜï Novos Resubmits (Top 4 - Fev/2026)

| Modelo Base | Score | Notebook v2 | Estrat√©gia |
|-------------|-------|-------------|------------|
| Ensemble Soft Voting | 0.78049 | `resubmit_ensemble_voting_v2.ipynb` | +SGD (3 modelos), pesos otimizados |
| Custom Transformer | 0.77272 | `resubmit_custom_transformer_v2.ipynb` | **Focal Loss** + label smoothing + warmup |
| BioBERTpt | 0.72480 | `resubmit_biobertpt_focal_v2.ipynb` | **Focal Loss** (Œ≥=2) + gradient accumulation |

### Melhorias Implementadas:

**Ensemble Soft Voting v2:**
- Adiciona SGDClassifier ao voting (3 modelos vs 2)
- Pesos baseados nos F1-Scores p√∫blicos: SVC=0.345, SGD=0.332, LR=0.323
- TF-IDF com 25k features (vs 20k)

**Custom Transformer v2:**
- Focal Loss (Œ≥=2) - mesma estrat√©gia do BERTimbau campe√£o
- Label smoothing (0.1) para regulariza√ß√£o
- Learning rate scheduler com warmup
- 15 epochs (vs 10)

**BioBERTpt v2:**
- Focal Loss (Œ≥=2) com class weights
- Gradient accumulation (2 steps)
- 7 epochs (vs 5)
- LR 3e-5 (vs 2e-5)

---

## Notebooks Dispon√≠veis

### Vers√£o 2 (Baseline com class_weight='balanced')
| Rank | Modelo | Score Base | Notebook |
|------|--------|------------|----------|
| üèÜ | BERTimbau + Focal | **0.79696** | `resubmit_bertimbau_v2.ipynb` |
| 2 | LinearSVC | 0.77885 | `resubmit_linearsvc_v2.ipynb` |
| 3 | SGDClassifier | 0.75019 | `resubmit_sgd_v2.ipynb` |
| 4 | Logistic Regression | 0.72935 | `resubmit_logreg_v2.ipynb` |
| 5 | LightGBM | 0.70273 | `resubmit_lgbm_v2.ipynb` |

### Vers√£o 3 (RandomizedSearchCV + Estrat√©gias)
| Modelo | Notebook | Estrat√©gias |
|--------|----------|-------------|
| LinearSVC | `resubmit_linearsvc_v3.ipynb` | RandomSearch + Calibra√ß√£o + Thresholds |
| SGDClassifier | `resubmit_sgd_v3.ipynb` | RandomSearch + Thresholds |
| Logistic Regression | `resubmit_logreg_v3.ipynb` | RandomSearch + Thresholds |
| LightGBM | `resubmit_lgbm_v3.ipynb` | RandomSearch + Early Stop + Thresholds |

---

## Estrat√©gias Implementadas (v3)

### 1. RandomizedSearchCV
- Tuning autom√°tico de hiperpar√¢metros
- 20-30 itera√ß√µes com cross-validation 5-fold
- M√©trica: F1-macro

### 2. Class Weights (j√° ativo em todos)
```python
class_weight='balanced'  # sklearn e LightGBM
```

### 3. SMOTE para Classes Minorit√°rias (5/6)
```python
USE_SMOTE = True  # Ativar no notebook
# Faz oversampling das classes 5 e 6 para 500 amostras
```

### 4. Threshold Tuning por Classe
```python
USE_THRESHOLD_TUNING = True  # Ativo por padr√£o
# Classes 5 e 6 t√™m threshold 0.35 (mais sens√≠vel)
# Outras classes t√™m threshold 0.5
```

### 5. Hip√≥tese Classe 2 (Teste)
```python
REMOVE_CLASS_2 = True  # Ativar para testar
# Remove classe 2 do treino (suspeita de pegadinha)
```

---

## Como Usar

1. **Clonar** o notebook desejado (v3)
2. **Ajustar FLAGS** no in√≠cio:
   - `REMOVE_CLASS_2`: True/False
   - `USE_SMOTE`: True/False
   - `USE_THRESHOLD_TUNING`: True/False
   - `N_SEARCH_ITER`: N√∫mero de itera√ß√µes (20-50)
3. **Submeter** no Kaggle com Internet OFF

---

## Experimentos Planejados

| Vers√£o | Melhoria | Status |
|--------|----------|--------|
| v2 | class_weight='balanced' | ‚è≥ |
| v3 | + tuning hiperpar√¢metros | ‚è≥ |
| v4 | + threshold optimization | ‚è≥ |
| v5 | sem classe 2 | ‚è≥ |

### BERTimbau + Focal Loss (melhorias)
| Vers√£o | Estrat√©gia | Status |
|--------|------------|--------|
| v3 | Alpha por classe + Threshold + Label smoothing | ‚è≥ |
| v4 | + SMOTE classes 5/6 | ‚è≥ |
| v5 | + Mixup augmentation | ‚è≥ |

---

## Como Usar

1. Editar notebook com melhoria desejada
2. Upload no Kaggle
3. Submeter
4. Atualizar `TODO.md` com resultado
