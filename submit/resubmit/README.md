# Resubmit - Modelos Top 5 (Score > 0.7)

## Objetivo
Melhorar os melhores modelos baseline com t√©cnicas para lidar com o **desbalanceamento de classes**.

---

## üèÜ Melhor Modelo: BERTimbau + Focal Loss (0.79696)

| Vers√£o | Notebook | Estrat√©gias | Status |
|--------|----------|-------------|--------|
| v3 | `resubmit_bertimbau_focal_v3.ipynb` | Alpha por classe + Threshold tuning + Label smoothing | ‚è≥ |

---

## Notebooks Dispon√≠veis

### Vers√£o 2 (Baseline com class_weight='balanced')
| Rank | Modelo | Score Base | Notebook |
|------|--------|------------|----------|
| üèÜ | BERTimbau + Focal | **0.79696** | `resubmit_bertimbau_v2.ipynb` |
| 2 | LinearSVC | 0.77885 | `resubmit_linearsvc_v2.ipynb` |
| 3 | SGDClassifier | 0.75019 | `resubmit_sgd_v2.ipynb` |
| 4 | Logistic Regression | 0.72935 | `resubmit_logreg_v2.ipynb` |
| 5 | LightGBM | 0.70273 | `resubmit_lgbm_v2.ipynb` |

### Vers√£o 3 (RandomizedSearchCV + Estrat√©gias)
| Modelo | Notebook | Estrat√©gias |
|--------|----------|-------------|
| LinearSVC | `resubmit_linearsvc_v3.ipynb` | RandomSearch + Calibra√ß√£o + Thresholds |
| SGDClassifier | `resubmit_sgd_v3.ipynb` | RandomSearch + Thresholds |
| Logistic Regression | `resubmit_logreg_v3.ipynb` | RandomSearch + Thresholds |
| LightGBM | `resubmit_lgbm_v3.ipynb` | RandomSearch + Early Stop + Thresholds |

---

## Estrat√©gias Implementadas (v3)

### 1. RandomizedSearchCV
- Tuning autom√°tico de hiperpar√¢metros
- 20-30 itera√ß√µes com cross-validation 5-fold
- M√©trica: F1-macro

### 2. Class Weights (j√° ativo em todos)
```python
class_weight='balanced'  # sklearn e LightGBM
```

### 3. SMOTE para Classes Minorit√°rias (5/6)
```python
USE_SMOTE = True  # Ativar no notebook
# Faz oversampling das classes 5 e 6 para 500 amostras
```

### 4. Threshold Tuning por Classe
```python
USE_THRESHOLD_TUNING = True  # Ativo por padr√£o
# Classes 5 e 6 t√™m threshold 0.35 (mais sens√≠vel)
# Outras classes t√™m threshold 0.5
```

### 5. Hip√≥tese Classe 2 (Teste)
```python
REMOVE_CLASS_2 = True  # Ativar para testar
# Remove classe 2 do treino (suspeita de pegadinha)
```

---

## Como Usar

1. **Clonar** o notebook desejado (v3)
2. **Ajustar FLAGS** no in√≠cio:
   - `REMOVE_CLASS_2`: True/False
   - `USE_SMOTE`: True/False
   - `USE_THRESHOLD_TUNING`: True/False
   - `N_SEARCH_ITER`: N√∫mero de itera√ß√µes (20-50)
3. **Submeter** no Kaggle com Internet OFF

---

## Experimentos Planejados

| Vers√£o | Melhoria | Status |
|--------|----------|--------|
| v2 | class_weight='balanced' | ‚è≥ |
| v3 | + tuning hiperpar√¢metros | ‚è≥ |
| v4 | + threshold optimization | ‚è≥ |
| v5 | sem classe 2 | ‚è≥ |

### BERTimbau + Focal Loss (melhorias)
| Vers√£o | Estrat√©gia | Status |
|--------|------------|--------|
| v3 | Alpha por classe + Threshold + Label smoothing | ‚è≥ |
| v4 | + SMOTE classes 5/6 | ‚è≥ |
| v5 | + Mixup augmentation | ‚è≥ |

---

## Como Usar

1. Editar notebook com melhoria desejada
2. Upload no Kaggle
3. Submeter
4. Atualizar `TODO.md` com resultado
