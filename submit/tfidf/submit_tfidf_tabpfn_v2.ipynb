{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPR 2026 - TF-IDF + TabPFN-2.5 (Offline)\n",
    "\n",
    "## Compativel com competicoes que exigem Internet OFF\n",
    "\n",
    "**Este notebook usa TabPFN-2.5 do Kaggle Models (Prior Labs).**\n",
    "\n",
    "### Configuracao:\n",
    "\n",
    "1. **NAO precisa de internet** - funciona offline\n",
    "2. Add Input -> Models -> pesquise tabpfn -> selecione TabPFN-2.5 (Prior Labs)\n",
    "3. Settings -> Accelerator -> GPU T4 x2\n",
    "4. Run All\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import subprocess, sys, os\nprint('='*60)\nprint('SPR 2026 - TF-IDF + TabPFN-2.5 (OFFLINE)')\nprint('='*60)\n\n# ==== DETECTAR MODELO TABPFN-2.5 ====\nprint('\\n[0/6] Detectando TabPFN-2.5...')\nprint('    Inputs disponiveis:')\nfor item in os.listdir('/kaggle/input'):\n    print(f'      - {item}')\n\n# Path correto do TabPFN-2.5 no Kaggle Models\nTABPFN_PATHS = [\n    '/kaggle/input/models/prior-labsai/tabpfn-2-5/pytorch/default/2',\n    '/kaggle/input/models/prior-labsai/tabpfn-2-5/pytorch/default/1',\n    '/kaggle/input/tabpfn-2.5/pytorch/default/1',\n    '/kaggle/input/tabpfn-2.5',\n]\n\nTABPFN_PATH = None\nfor path in TABPFN_PATHS:\n    if os.path.exists(path):\n        TABPFN_PATH = path\n        print(f'    TabPFN encontrado em: {TABPFN_PATH}')\n        for f in os.listdir(TABPFN_PATH)[:5]:\n            print(f'        - {f}')\n        break\n\nif TABPFN_PATH is None:\n    # Procurar recursivamente\n    print('\\n    Procurando TabPFN recursivamente...')\n    for root, dirs, files in os.walk('/kaggle/input'):\n        if 'tabpfn' in root.lower():\n            TABPFN_PATH = root\n            print(f'    Encontrado em: {root}')\n            break\n    if TABPFN_PATH is None:\n        raise FileNotFoundError('TabPFN-2.5 nao encontrado!')\n\nprint(f'\\n    PATH final: {TABPFN_PATH}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==== INSTALAR TABPFN ====\nprint('\\n[1/6] Instalando TabPFN...')\n\n# Instalar tabpfn via pip (versao 2.0+)\nsubprocess.run([sys.executable, '-m', 'pip', 'install', 'tabpfn>=2.0', '-q'], check=True)\n\n# Configurar para usar checkpoints locais (sem download)\nos.environ['TABPFN_MODEL_PATH'] = TABPFN_PATH\n\nfrom tabpfn import TabPFNClassifier\nprint('    TabPFN importado com sucesso!')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport torch\nimport warnings\nwarnings.filterwarnings('ignore')\n\nSEED = 42\nSVD_COMPONENTS = 100\nMAX_TRAIN_SIZE = 3000\nN_ENSEMBLE_CONFIGS = 16\nDATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\nUSE_GPU = torch.cuda.is_available()\nnp.random.seed(SEED)\nprint(f'    GPU disponivel: {USE_GPU}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print('\\n[2/6] Carregando dados...')\ntrain = pd.read_csv(f'{DATA_DIR}/train.csv')\ntest = pd.read_csv(f'{DATA_DIR}/test.csv')\nprint(f'    Train: {train.shape} | Test: {test.shape}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print('\\n[3/6] Aplicando TF-IDF...')\ntfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=2, max_df=0.95, sublinear_tf=True)\nX_train_tfidf = tfidf.fit_transform(train['report'])\nX_test_tfidf = tfidf.transform(test['report'])\ny_train = train['target'].values\nprint(f'    TF-IDF esparso: {X_train_tfidf.shape}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f'\\n[4/6] Aplicando SVD: {X_train_tfidf.shape[1]} -> {SVD_COMPONENTS} features...')\nsvd = TruncatedSVD(n_components=SVD_COMPONENTS, random_state=SEED)\nX_train_svd = svd.fit_transform(X_train_tfidf)\nX_test_svd = svd.transform(X_test_tfidf)\nprint(f'    Variancia explicada: {svd.explained_variance_ratio_.sum():.2%}')\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train_svd)\nX_test = scaler.transform(X_test_svd)\nprint(f'    Shape final: {X_train.shape}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f'\\n[5/6] Executando TabPFN-2.5...')\ndevice = 'cuda' if USE_GPU else 'cpu'\n\n# TabPFN 2.5 suporta datasets maiores\nif len(X_train) > MAX_TRAIN_SIZE:\n    print(f'    Dataset grande ({len(X_train)}), usando ensemble com subsampling...')\n    n_ensembles = 5\n    all_preds = []\n    splitter = StratifiedShuffleSplit(n_splits=n_ensembles, train_size=MAX_TRAIN_SIZE, random_state=SEED)\n    \n    for i, (train_idx, _) in enumerate(splitter.split(X_train, y_train)):\n        print(f'    Ensemble {i+1}/{n_ensembles}...')\n        X_subset = X_train[train_idx]\n        y_subset = y_train[train_idx]\n        \n        # TabPFN 2.5 - usar inference_mode para melhor performance\n        model = TabPFNClassifier(device=device, N_ensemble_configurations=N_ENSEMBLE_CONFIGS)\n        model.fit(X_subset, y_subset)\n        preds = model.predict_proba(X_test)\n        all_preds.append(preds)\n    \n    avg_probs = np.mean(all_preds, axis=0)\n    predictions = np.argmax(avg_probs, axis=1)\nelse:\n    print(f'    Treinando em {len(X_train)} amostras...')\n    model = TabPFNClassifier(device=device, N_ensemble_configurations=N_ENSEMBLE_CONFIGS)\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n\nprint('    TabPFN-2.5 executado!')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print('\\n[6/6] Gerando submissao...')\nsubmission = pd.DataFrame({'ID': test['ID'], 'target': predictions})\nsubmission.to_csv('submission.csv', index=False)\nprint('='*60)\nprint('CONCLUIDO - submission.csv criado!')\nprint('='*60)\nprint('\\nDistribuicao das predicoes:')\nprint(submission['target'].value_counts().sort_index())"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}