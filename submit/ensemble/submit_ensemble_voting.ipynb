{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87878e47",
   "metadata": {},
   "source": [
    "# SPR 2026 - Ensemble Ponderado (Voting)\n",
    "\n",
    "**Experimento #6 - Média Prioridade**\n",
    "\n",
    "Média ponderada das probabilidades dos melhores modelos.\n",
    "\n",
    "---\n",
    "**CONFIGURAÇÃO:**\n",
    "Este notebook assume que você já tem arquivos de predição (probabilidades) salvos.\n",
    "\n",
    "**Pré-requisitos:**\n",
    "1. Executar modelos individuais e salvar probabilidades como CSV\n",
    "2. Combinar usando pesos baseados no F1-Score de validação\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "PROBA_DIR = '/kaggle/working'  # Ou onde estão salvas as probabilidades\n",
    "\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "print(f'Test: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# OPÇÃO 1: Carregar probabilidades de arquivos salvos\n",
    "# =================================================================\n",
    "# Descomente e ajuste os paths conforme necessário\n",
    "\n",
    "# proba_model1 = np.load(f'{PROBA_DIR}/proba_bertimbau.npy')\n",
    "# proba_model2 = np.load(f'{PROBA_DIR}/proba_deberta.npy')\n",
    "# proba_model3 = np.load(f'{PROBA_DIR}/proba_xlmroberta.npy')\n",
    "\n",
    "# # Pesos baseados no F1-Score de validação\n",
    "# weights = {\n",
    "#     'bertimbau': 0.82,   # F1-Score val\n",
    "#     'deberta': 0.81,\n",
    "#     'xlmroberta': 0.80,\n",
    "# }\n",
    "\n",
    "# # Normalizar pesos\n",
    "# total_weight = sum(weights.values())\n",
    "# weights = {k: v / total_weight for k, v in weights.items()}\n",
    "\n",
    "# # Média ponderada\n",
    "# ensemble_proba = (\n",
    "#     proba_model1 * weights['bertimbau'] +\n",
    "#     proba_model2 * weights['deberta'] +\n",
    "#     proba_model3 * weights['xlmroberta']\n",
    "# )\n",
    "\n",
    "# predictions = ensemble_proba.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# OPÇÃO 2: Voting simples de predições (Hard Voting)\n",
    "# =================================================================\n",
    "# Combine predições de múltiplos arquivos de submissão\n",
    "\n",
    "# sub1 = pd.read_csv(f'{PROBA_DIR}/submission_bertimbau.csv')\n",
    "# sub2 = pd.read_csv(f'{PROBA_DIR}/submission_deberta.csv')\n",
    "# sub3 = pd.read_csv(f'{PROBA_DIR}/submission_xlmroberta.csv')\n",
    "\n",
    "# from scipy import stats\n",
    "\n",
    "# all_preds = np.column_stack([\n",
    "#     sub1['target'].values,\n",
    "#     sub2['target'].values,\n",
    "#     sub3['target'].values\n",
    "# ])\n",
    "\n",
    "# # Modo (voto majoritário)\n",
    "# predictions = stats.mode(all_preds, axis=1)[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# EXEMPLO: Ensemble inline de TF-IDF + Modelo simples\n",
    "# =================================================================\n",
    "# Para demonstração, vamos criar um ensemble simples\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Carregar dados\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(train_df['report'])\n",
    "X_test = tfidf.transform(test_df['report'])\n",
    "y_train = train_df['target'].values\n",
    "\n",
    "print(f'TF-IDF shape: {X_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf09167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar modelos\n",
    "lr = LogisticRegression(C=1.0, max_iter=1000, class_weight='balanced', random_state=42)\n",
    "svc = CalibratedClassifierCV(LinearSVC(C=1.0, max_iter=1000, class_weight='balanced', random_state=42))\n",
    "\n",
    "# Voting Classifier (Soft Voting)\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr),\n",
    "        ('svc', svc),\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[0.6, 0.4]  # Ajustar baseado no F1-Score de cada modelo\n",
    ")\n",
    "\n",
    "# Treinar\n",
    "ensemble.fit(X_train, y_train)\n",
    "print('Ensemble treinado!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef2d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predições\n",
    "predictions = ensemble.predict(X_test)\n",
    "\n",
    "# Submissão\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_df['ID'],\n",
    "    'target': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print('submission.csv criado!')\n",
    "print(submission['target'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
