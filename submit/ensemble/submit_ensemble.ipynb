{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b54846f",
   "metadata": {},
   "source": [
    "# SPR 2026 - Ensemble (TF-IDF + Word2Vec)\n",
    "\n",
    "**Votação majoritária de 3 modelos:**\n",
    "- TF-IDF + Logistic Regression\n",
    "- TF-IDF + LightGBM\n",
    "- Word2Vec + LightGBM\n",
    "\n",
    "- ✅ Não requer modelos externos\n",
    "- ✅ Tempo esperado: ~5-10 min\n",
    "\n",
    "---\n",
    "**CONFIGURAÇÃO KAGGLE:**\n",
    "1. Settings → Internet → **OFF**\n",
    "2. **IMPORTANTE:** Execute \"Run All\" após commit\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SPR 2026 - ENSEMBLE: TF-IDF + WORD2VEC (VOTAÇÃO MAJORITÁRIA)\n",
    "# =============================================================================\n",
    "# - Modelo 1: TF-IDF + Logistic Regression\n",
    "# - Modelo 2: TF-IDF + LightGBM\n",
    "# - Modelo 3: Word2Vec + LightGBM\n",
    "# - Combinação: Votação majoritária (mode)\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.stats import mode\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "EMBEDDING_DIM = 100\n",
    "DATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "np.random.seed(SEED)\n",
    "print('[1/7] Bibliotecas carregadas!')\n",
    "\n",
    "# =============================================================================\n",
    "# CARREGAR DADOS\n",
    "# =============================================================================\n",
    "train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "y = train['target'].values\n",
    "print(f'[2/7] Train: {train.shape} | Test: {test.shape}')\n",
    "\n",
    "# =============================================================================\n",
    "# MODELO 1: TF-IDF + LOGISTIC REGRESSION\n",
    "# =============================================================================\n",
    "tfidf1 = TfidfVectorizer(\n",
    "    max_features=15000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True,\n",
    ")\n",
    "\n",
    "X_tfidf_train = tfidf1.fit_transform(train['report'])\n",
    "X_tfidf_test = tfidf1.transform(test['report'])\n",
    "\n",
    "model_lr = LogisticRegression(C=1.0, max_iter=1000, class_weight='balanced', random_state=SEED, n_jobs=-1)\n",
    "model_lr.fit(X_tfidf_train, y)\n",
    "preds_lr = model_lr.predict(X_tfidf_test)\n",
    "print(f'[3/7] Modelo 1 (TF-IDF + LR): {len(preds_lr)} predições')\n",
    "\n",
    "# =============================================================================\n",
    "# MODELO 2: TF-IDF + LIGHTGBM\n",
    "# =============================================================================\n",
    "tfidf2 = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True,\n",
    ")\n",
    "\n",
    "X_tfidf2_train = tfidf2.fit_transform(train['report'])\n",
    "X_tfidf2_test = tfidf2.transform(test['report'])\n",
    "\n",
    "model_lgbm = lgb.LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    class_weight='balanced',\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "model_lgbm.fit(X_tfidf2_train, y)\n",
    "preds_lgbm = model_lgbm.predict(X_tfidf2_test)\n",
    "print(f'[4/7] Modelo 2 (TF-IDF + LGBM): {len(preds_lgbm)} predições')\n",
    "\n",
    "# =============================================================================\n",
    "# MODELO 3: WORD2VEC + LIGHTGBM\n",
    "# =============================================================================\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-záàâãéèêíïóôõöúçñ\\s]', ' ', text)\n",
    "    return text.split()\n",
    "\n",
    "train['tokens'] = train['report'].apply(preprocess)\n",
    "test['tokens'] = test['report'].apply(preprocess)\n",
    "\n",
    "all_texts = train['tokens'].tolist() + test['tokens'].tolist()\n",
    "w2v = Word2Vec(sentences=all_texts, vector_size=EMBEDDING_DIM, window=5, min_count=2, workers=4, epochs=10, seed=SEED)\n",
    "\n",
    "def text_to_embedding(tokens, model, dim):\n",
    "    vectors = [model.wv[w] for w in tokens if w in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(dim)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "X_w2v_train = np.array([text_to_embedding(t, w2v, EMBEDDING_DIM) for t in train['tokens']])\n",
    "X_w2v_test = np.array([text_to_embedding(t, w2v, EMBEDDING_DIM) for t in test['tokens']])\n",
    "\n",
    "model_w2v = lgb.LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.05,\n",
    "    class_weight='balanced',\n",
    "    random_state=SEED,\n",
    "    verbose=-1\n",
    ")\n",
    "model_w2v.fit(X_w2v_train, y)\n",
    "preds_w2v = model_w2v.predict(X_w2v_test)\n",
    "print(f'[5/7] Modelo 3 (Word2Vec + LGBM): {len(preds_w2v)} predições')\n",
    "\n",
    "# =============================================================================\n",
    "# ENSEMBLE: VOTAÇÃO MAJORITÁRIA\n",
    "# =============================================================================\n",
    "preds_matrix = np.column_stack([preds_lr, preds_lgbm, preds_w2v])\n",
    "ensemble_preds = mode(preds_matrix, axis=1).mode.flatten()\n",
    "print(f'[6/7] Ensemble: {len(ensemble_preds)} predições')\n",
    "\n",
    "# =============================================================================\n",
    "# SUBMISSÃO\n",
    "# =============================================================================\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    'target': ensemble_preds.astype(int)\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('[7/7] ✅ CONCLUÍDO: submission.csv')\n",
    "print(submission['target'].value_counts().sort_index())\n",
    "\n",
    "# Distribuição por modelo\n",
    "print('\\nDistribuição por modelo:')\n",
    "print(f'LR:       {np.bincount(preds_lr, minlength=7)}')\n",
    "print(f'LGBM:     {np.bincount(preds_lgbm, minlength=7)}')\n",
    "print(f'W2V:      {np.bincount(preds_w2v, minlength=7)}')\n",
    "print(f'Ensemble: {np.bincount(ensemble_preds.astype(int), minlength=7)}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
