{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d3b584",
   "metadata": {},
   "source": [
    "# SPR 2026 Mammography Report Classification\n",
    "## Kaggle Submission Notebook\n",
    "\n",
    "Este notebook treina um modelo BERT e gera a submissão para o Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d08965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependências (rodar apenas se necessário)\n",
    "# !pip install transformers accelerate datasets scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurações\n",
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "MODEL_NAME = \"neuralmind/bert-base-portuguese-cased\"  # BERTimbau\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "LR = 2e-5\n",
    "\n",
    "# Caminhos Kaggle\n",
    "INPUT_DIR = \"/kaggle/input/spr-2026-mammography-report-classification\"\n",
    "OUTPUT_DIR = \"/kaggle/working\"\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30455c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edc4fa3",
   "metadata": {},
   "source": [
    "## 1. Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae23f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar treino\n",
    "train_path = os.path.join(INPUT_DIR, \"train.csv\")\n",
    "train_df = pd.read_csv(train_path)\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Target distribution:\\n{train_df['target'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cae140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar teste (disponível apenas durante avaliação)\n",
    "test_path = os.path.join(INPUT_DIR, \"test.csv\")\n",
    "\n",
    "if os.path.exists(test_path):\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    print(f\"Test shape: {test_df.shape}\")\n",
    "else:\n",
    "    print(\"Test file not found - expected in evaluation runtime\")\n",
    "    test_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03218a47",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fe489",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MammographyDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        item = {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "        }\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            \n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf263b",
   "metadata": {},
   "source": [
    "## 3. Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea8775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"f1_macro\": f1_score(labels, predictions, average=\"macro\")}\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# K-Fold\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "oof_predictions = np.zeros((len(train_df), 7))\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3767acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Split data\n",
    "    train_texts = train_df.iloc[train_idx]['report'].tolist()\n",
    "    train_labels = train_df.iloc[train_idx]['target'].tolist()\n",
    "    val_texts = train_df.iloc[val_idx]['report'].tolist()\n",
    "    val_labels = train_df.iloc[val_idx]['target'].tolist()\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = MammographyDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n",
    "    val_dataset = MammographyDataset(val_texts, val_labels, tokenizer, MAX_LENGTH)\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=7,\n",
    "    )\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"{OUTPUT_DIR}/fold_{fold}\",\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "        learning_rate=LR,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        fp16=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_macro\",\n",
    "        greater_is_better=True,\n",
    "        report_to=\"none\",\n",
    "        seed=SEED,\n",
    "    )\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.train()\n",
    "    \n",
    "    # Get OOF predictions\n",
    "    preds = trainer.predict(val_dataset)\n",
    "    oof_predictions[val_idx] = preds.predictions\n",
    "    \n",
    "    # Evaluate\n",
    "    val_pred_labels = np.argmax(preds.predictions, axis=1)\n",
    "    fold_f1 = f1_score(val_labels, val_pred_labels, average=\"macro\")\n",
    "    print(f\"Fold {fold + 1} F1-Macro: {fold_f1:.4f}\")\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOF score\n",
    "oof_pred_labels = np.argmax(oof_predictions, axis=1)\n",
    "oof_f1 = f1_score(train_df['target'], oof_pred_labels, average=\"macro\")\n",
    "print(f\"\\nOverall OOF F1-Macro: {oof_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179db1e4",
   "metadata": {},
   "source": [
    "## 4. Inferência e Submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5671d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_df is not None:\n",
    "    print(\"Generating predictions for test set...\")\n",
    "    \n",
    "    # Create test dataset\n",
    "    test_dataset = MammographyDataset(\n",
    "        test_df['report'].tolist(),\n",
    "        labels=None,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=MAX_LENGTH,\n",
    "    )\n",
    "    \n",
    "    # Ensemble predictions\n",
    "    all_predictions = []\n",
    "    \n",
    "    for fold, model in enumerate(models):\n",
    "        print(f\"Predicting with model {fold + 1}/{len(models)}\")\n",
    "        model.eval()\n",
    "        \n",
    "        trainer = Trainer(model=model)\n",
    "        preds = trainer.predict(test_dataset)\n",
    "        all_predictions.append(preds.predictions)\n",
    "    \n",
    "    # Average predictions\n",
    "    test_predictions = np.mean(all_predictions, axis=0)\n",
    "    test_pred_labels = np.argmax(test_predictions, axis=1)\n",
    "    \n",
    "    # Create submission\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_df['ID'],\n",
    "        'target': test_pred_labels,\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(f\"\\nSubmission saved!\")\n",
    "    print(f\"Submission shape: {submission.shape}\")\n",
    "    print(f\"Prediction distribution:\\n{submission['target'].value_counts().sort_index()}\")\n",
    "else:\n",
    "    print(\"Test file not available - run this in Kaggle evaluation environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c58fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview submission\n",
    "if os.path.exists('submission.csv'):\n",
    "    submission = pd.read_csv('submission.csv')\n",
    "    print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
