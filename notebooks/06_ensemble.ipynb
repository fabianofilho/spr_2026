{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514d6f4d",
   "metadata": {},
   "source": [
    "# SPR 2026 - Ensemble\n",
    "\n",
    "Combina predições de múltiplos modelos.\n",
    "\n",
    "**Estratégias:**\n",
    "- Votação majoritária\n",
    "- Média ponderada de probabilidades\n",
    "\n",
    "**Formato:** Code Competition (Kaggle) / Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP - Ambiente e Dados\n",
    "# ============================================================\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Verificar Colab PRIMEIRO (mais confiável)\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input') and not IS_COLAB\n",
    "\n",
    "print(f\"Ambiente: {'Kaggle' if IS_KAGGLE else 'Colab' if IS_COLAB else 'Local'}\")\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    DRIVE_BASE = '/content/drive/MyDrive/SPR_2026_outputs'\n",
    "    DATA_DIR = f'{DRIVE_BASE}/data'\n",
    "    OUTPUT_DIR = DRIVE_BASE\n",
    "    \n",
    "    # Verificar se dados existem no Drive\n",
    "    if not os.path.exists(f'{DATA_DIR}/train.csv'):\n",
    "        print(\"⚠️ Dados não encontrados no Drive!\")\n",
    "        print(\"Execute primeiro o notebook 00_download_data.ipynb\")\n",
    "        raise FileNotFoundError(f\"Arquivo não encontrado: {DATA_DIR}/train.csv\")\n",
    "elif IS_KAGGLE:\n",
    "    DATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "    OUTPUT_DIR = '/kaggle/working'\n",
    "else:\n",
    "    DATA_DIR = '../data'\n",
    "    OUTPUT_DIR = '../submissions'\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d4932b",
   "metadata": {},
   "source": [
    "## 1. Carregar Submissões dos Modelos\n",
    "\n",
    "Coloque os arquivos de submissão de cada modelo no mesmo diretório ou ajuste os paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b91d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de submissões (arquivos salvos no Google Drive pelos outros notebooks)\n",
    "submission_files = [\n",
    "    'submission_tfidf.csv',\n",
    "    'submission_word2vec.csv',\n",
    "    'submission_bertimbau.csv',\n",
    "    'submission_flan_t5.csv',\n",
    "    'submission_distilbert.csv',\n",
    "    'submission_deberta.csv',\n",
    "    'submission_sbert.csv',\n",
    "]\n",
    "\n",
    "# Pesos para cada modelo (ajuste baseado em OOF F1)\n",
    "weights = {\n",
    "    'submission_tfidf.csv': 0.10,\n",
    "    'submission_word2vec.csv': 0.10,\n",
    "    'submission_bertimbau.csv': 0.20,\n",
    "    'submission_flan_t5.csv': 0.15,\n",
    "    'submission_distilbert.csv': 0.10,\n",
    "    'submission_deberta.csv': 0.25,\n",
    "    'submission_sbert.csv': 0.10,\n",
    "}\n",
    "\n",
    "# Carregar submissões disponíveis do OUTPUT_DIR (Google Drive)\n",
    "submissions = {}\n",
    "for f in submission_files:\n",
    "    filepath = os.path.join(OUTPUT_DIR, f)\n",
    "    if os.path.exists(filepath):\n",
    "        df = pd.read_csv(filepath)\n",
    "        submissions[f] = df\n",
    "        print(f\"Loaded: {f} ({len(df)} rows)\")\n",
    "    else:\n",
    "        print(f\"Not found: {f}\")\n",
    "\n",
    "print(f\"\\nTotal modelos carregados: {len(submissions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cdcf0e",
   "metadata": {},
   "source": [
    "## 2. Votação Majoritária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(submissions) >= 2:\n",
    "    # Alinhar por ID\n",
    "    first_key = list(submissions.keys())[0]\n",
    "    ids = submissions[first_key]['ID'].values\n",
    "    \n",
    "    # Criar matriz de predições\n",
    "    preds_matrix = np.column_stack([\n",
    "        submissions[k].set_index('ID').loc[ids, 'target'].values\n",
    "        for k in submissions.keys()\n",
    "    ])\n",
    "    \n",
    "    print(f\"Matriz de predições: {preds_matrix.shape}\")\n",
    "    \n",
    "    # Votação majoritária\n",
    "    ensemble_preds = mode(preds_matrix, axis=1).mode.flatten()\n",
    "    \n",
    "    # Criar submissão\n",
    "    ensemble_vote = pd.DataFrame({'ID': ids, 'target': ensemble_preds})\n",
    "    ensemble_vote.to_csv(os.path.join(OUTPUT_DIR, 'submission_ensemble_vote.csv'), index=False)\n",
    "    \n",
    "    print(\"\\nVotação Majoritária:\")\n",
    "    print(ensemble_vote['target'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"Necessário pelo menos 2 submissões\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f31de7",
   "metadata": {},
   "source": [
    "## 3. Média Ponderada (se tiver probabilidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se você salvou probabilidades ao invés de classes,\n",
    "# pode fazer a média ponderada aqui.\n",
    "# Exemplo com probabilidades:\n",
    "\n",
    "# proba_files = [\n",
    "#     ('model1_proba.npy', 0.4),\n",
    "#     ('model2_proba.npy', 0.35),\n",
    "#     ('model3_proba.npy', 0.25),\n",
    "# ]\n",
    "# \n",
    "# weighted_proba = np.zeros((n_samples, 7))\n",
    "# for f, w in proba_files:\n",
    "#     proba = np.load(f)\n",
    "#     weighted_proba += w * proba\n",
    "# \n",
    "# final_preds = np.argmax(weighted_proba, axis=1)\n",
    "\n",
    "print(\"Para média ponderada, salve as probabilidades de cada modelo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d8fbf0",
   "metadata": {},
   "source": [
    "## 4. Submissão Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95166d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Geração de Submissão Final\n",
    "# ============================================================\n",
    "# Use a submissão do ensemble ou a melhor individual\n",
    "if len(submissions) >= 2:\n",
    "    final_submission = ensemble_vote.copy()\n",
    "    \n",
    "    # SEMPRE salvar submission.csv no diretório atual (exigido pelo Kaggle)\n",
    "    final_submission.to_csv('submission.csv', index=False)\n",
    "    print(\"✅ submission.csv salvo no diretório atual\")\n",
    "    \n",
    "    # Também salvar no OUTPUT_DIR para persistência (Colab/Local)\n",
    "    if not IS_KAGGLE:\n",
    "        submission_path = os.path.join(OUTPUT_DIR, 'submission_ensemble.csv')\n",
    "        final_submission.to_csv(submission_path, index=False)\n",
    "        print(f\"✅ Cópia salva em: {submission_path}\")\n",
    "    \n",
    "    print(f\"\\nDistribuição das predições (ensemble):\")\n",
    "    print(final_submission['target'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"Use a melhor submissão individual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85501d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download no Colab (opcional)\n",
    "if IS_COLAB and os.path.exists('submission.csv'):\n",
    "    from google.colab import files\n",
    "    files.download('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
