{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f43535",
   "metadata": {},
   "source": [
    "# SPR 2026 - Word Embeddings (Word2Vec, FastText, GloVe)\n",
    "## Notebook para Google Colab\n",
    "\n",
    "Abordagem usando word embeddings pré-treinados com classificadores.\n",
    "\n",
    "**Embeddings testados:**\n",
    "- Word2Vec (NILC - Portuguese)\n",
    "- FastText (Portuguese)\n",
    "- GloVe (Portuguese)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263aaae",
   "metadata": {},
   "source": [
    "## 1. Setup e Download dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867caeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependências\n",
    "!pip install kaggle gensim lightgbm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5237db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar Kaggle API\n",
    "import os\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
    "    os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
    "    print(\"Kaggle credentials loaded from Colab secrets\")\n",
    "except:\n",
    "    # os.environ['KAGGLE_USERNAME'] = 'seu_username'\n",
    "    # os.environ['KAGGLE_KEY'] = 'sua_key'\n",
    "    print(\"Configure suas credenciais Kaggle manualmente\")\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!echo '{\"username\":\"'$KAGGLE_USERNAME'\",\"key\":\"'$KAGGLE_KEY'\"}' > ~/.kaggle/kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fbda17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dos dados da competição\n",
    "!kaggle competitions download -c spr-2026-mammography-report-classification\n",
    "!unzip -o spr-2026-mammography-report-classification.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa0657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Word2Vec Português (NILC)\n",
    "# Opções: cbow_s50, cbow_s100, cbow_s300, skip_s50, skip_s100, skip_s300\n",
    "!mkdir -p embeddings\n",
    "!wget -nc http://143.107.183.175:22980/download.php?file=embeddings/word2vec/cbow_s100.zip -O embeddings/cbow_s100.zip\n",
    "!unzip -o embeddings/cbow_s100.zip -d embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90908bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from gensim.models import KeyedVectors\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc188a",
   "metadata": {},
   "source": [
    "## 2. Carregar Dados e Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afc6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "\n",
    "test_path = 'data/test.csv'\n",
    "test_df = pd.read_csv(test_path) if os.path.exists(test_path) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar Word2Vec\n",
    "print(\"Carregando Word2Vec...\")\n",
    "w2v_model = KeyedVectors.load_word2vec_format('embeddings/cbow_s100.txt')\n",
    "print(f\"Vocabulário: {len(w2v_model)} palavras\")\n",
    "print(f\"Dimensão: {w2v_model.vector_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b35eb",
   "metadata": {},
   "source": [
    "## 3. Preprocessamento e Vetorização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocessamento básico do texto.\"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-záàâãéêíóôõúç\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text.split()\n",
    "\n",
    "def get_sentence_embedding(tokens, model, method='mean'):\n",
    "    \"\"\"Obter embedding da sentença.\"\"\"\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in model:\n",
    "            vectors.append(model[token])\n",
    "    \n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "    vectors = np.array(vectors)\n",
    "    \n",
    "    if method == 'mean':\n",
    "        return vectors.mean(axis=0)\n",
    "    elif method == 'max':\n",
    "        return vectors.max(axis=0)\n",
    "    elif method == 'concat':\n",
    "        return np.concatenate([vectors.mean(axis=0), vectors.max(axis=0)])\n",
    "    else:\n",
    "        return vectors.mean(axis=0)\n",
    "\n",
    "def texts_to_embeddings(texts, model, method='mean'):\n",
    "    \"\"\"Converter lista de textos para embeddings.\"\"\"\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        tokens = preprocess_text(text)\n",
    "        emb = get_sentence_embedding(tokens, model, method)\n",
    "        embeddings.append(emb)\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter textos para embeddings\n",
    "print(\"Convertendo textos para embeddings...\")\n",
    "\n",
    "# Testar diferentes métodos de agregação\n",
    "methods = ['mean', 'max', 'concat']\n",
    "embeddings_cache = {}\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"  Método: {method}\")\n",
    "    X = texts_to_embeddings(train_df['report'].tolist(), w2v_model, method)\n",
    "    embeddings_cache[method] = X\n",
    "    print(f\"    Shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49261e9c",
   "metadata": {},
   "source": [
    "## 4. Treinar e Avaliar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1cee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target'].values\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "results = []\n",
    "\n",
    "for method in methods:\n",
    "    X = embeddings_cache[method]\n",
    "    \n",
    "    # Logistic Regression\n",
    "    lr = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED)\n",
    "    scores = cross_val_score(lr, X, y, cv=skf, scoring='f1_macro')\n",
    "    results.append({'method': method, 'model': 'LogisticRegression', 'f1_macro': scores.mean(), 'std': scores.std()})\n",
    "    print(f\"{method} + LR: F1={scores.mean():.4f} (+/- {scores.std()*2:.4f})\")\n",
    "    \n",
    "    # LightGBM\n",
    "    lgbm = lgb.LGBMClassifier(n_estimators=200, class_weight='balanced', random_state=SEED, verbose=-1)\n",
    "    scores = cross_val_score(lgbm, X, y, cv=skf, scoring='f1_macro')\n",
    "    results.append({'method': method, 'model': 'LightGBM', 'f1_macro': scores.mean(), 'std': scores.std()})\n",
    "    print(f\"{method} + LGBM: F1={scores.mean():.4f} (+/- {scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a779480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo\n",
    "results_df = pd.DataFrame(results).sort_values('f1_macro', ascending=False)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMO DOS RESULTADOS\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "best = results_df.iloc[0]\n",
    "print(f\"\\nMelhor: {best['method']} + {best['model']} (F1={best['f1_macro']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c9619",
   "metadata": {},
   "source": [
    "## 5. Treinar Modelo Final e Gerar Submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc60e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar melhor configuração\n",
    "best_method = best['method']\n",
    "X_train = embeddings_cache[best_method]\n",
    "\n",
    "# Treinar modelo final\n",
    "if best['model'] == 'LogisticRegression':\n",
    "    final_model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED)\n",
    "else:\n",
    "    final_model = lgb.LGBMClassifier(n_estimators=200, class_weight='balanced', random_state=SEED, verbose=-1)\n",
    "\n",
    "final_model.fit(X_train, y)\n",
    "print(\"Modelo final treinado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e5921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar submissão\n",
    "if test_df is not None:\n",
    "    X_test = texts_to_embeddings(test_df['report'].tolist(), w2v_model, best_method)\n",
    "    predictions = final_model.predict(X_test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_df['ID'],\n",
    "        'target': predictions,\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission_word2vec.csv', index=False)\n",
    "    print(\"Submissão salva: submission_word2vec.csv\")\n",
    "    print(submission['target'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"Test file não disponível\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('submission_word2vec.csv')\n",
    "except:\n",
    "    print(\"Submissão disponível em: submission_word2vec.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
