{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ebad16",
   "metadata": {},
   "source": [
    "# SPR 2026 - BERTimbau (BERT Português)\n",
    "\n",
    "Fine-tuning do BERTimbau para classificação BI-RADS.\n",
    "\n",
    "**Modelo:** neuralmind/bert-base-portuguese-cased\n",
    "\n",
    "**Formato:** Code Competition (Kaggle) / Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb44dd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente: Colab\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "DATA_DIR: /content/drive/MyDrive/SPR_2026_outputs/data\n",
      "OUTPUT_DIR: /content/drive/MyDrive/SPR_2026_outputs\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SETUP - Ambiente e Dados\n",
    "# ============================================================\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Verificar Colab PRIMEIRO (mais confiável)\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input') and not IS_COLAB\n",
    "\n",
    "print(f\"Ambiente: {'Kaggle' if IS_KAGGLE else 'Colab' if IS_COLAB else 'Local'}\")\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    DRIVE_BASE = '/content/drive/MyDrive/SPR_2026_outputs'\n",
    "    DATA_DIR = f'{DRIVE_BASE}/data'\n",
    "    OUTPUT_DIR = DRIVE_BASE\n",
    "    \n",
    "    # Verificar se dados existem no Drive\n",
    "    if not os.path.exists(f'{DATA_DIR}/train.csv'):\n",
    "        print(\"⚠️ Dados não encontrados no Drive!\")\n",
    "        print(\"Execute primeiro o notebook 00_download_data.ipynb\")\n",
    "        raise FileNotFoundError(f\"Arquivo não encontrado: {DATA_DIR}/train.csv\")\n",
    "elif IS_KAGGLE:\n",
    "    DATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "    OUTPUT_DIR = '/kaggle/working'\n",
    "else:\n",
    "    DATA_DIR = '../data'\n",
    "    OUTPUT_DIR = '../submissions'\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a6d5f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Config\n",
    "SEED = 42\n",
    "MODEL_NAME = 'neuralmind/bert-base-portuguese-cased'\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 3\n",
    "LR = 2e-5\n",
    "N_FOLDS = 5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f219f1f",
   "metadata": {},
   "source": [
    "## 1. Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1a8df72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (18272, 3)\n",
      "Test: (4, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "print(f\"Train: {train.shape}\")\n",
    "\n",
    "test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "if os.path.exists(test_path):\n",
    "    test = pd.read_csv(test_path)\n",
    "    print(f\"Test: {test.shape}\")\n",
    "    assert set(['ID', 'report']).issubset(test.columns)\n",
    "else:\n",
    "    test = None\n",
    "    print(\"test.csv não disponível - será carregado no runtime Kaggle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213202b7",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "206e9ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MammographyDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            str(self.texts[idx]),\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eda21e",
   "metadata": {},
   "source": [
    "## 3. Treinar com K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75348d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Fold 1/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1661528e3ee746439efe56d849f16c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification LOAD REPORT from: neuralmind/bert-base-portuguese-cased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.predictions.decoder.weight             | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "classifier.weight                          | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n",
      "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='5484' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  30/5484 24:09 < 78:24:34, 0.02 it/s, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'f1_macro': f1_score(labels, predictions, average='macro')}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "oof_preds = np.zeros((len(train), 7))\n",
    "fold_scores = []\n",
    "models = []  # Guardar modelos de cada fold\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train, train['target'])):\n",
    "    print(f\"\\n{'='*50}\\nFold {fold+1}/{N_FOLDS}\\n{'='*50}\")\n",
    "    \n",
    "    train_ds = MammographyDataset(\n",
    "        train.iloc[train_idx]['report'].tolist(),\n",
    "        train.iloc[train_idx]['target'].tolist(),\n",
    "        tokenizer, MAX_LENGTH\n",
    "    )\n",
    "    val_ds = MammographyDataset(\n",
    "        train.iloc[val_idx]['report'].tolist(),\n",
    "        train.iloc[val_idx]['target'].tolist(),\n",
    "        tokenizer, MAX_LENGTH\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=7)\n",
    "    model.to(device)  # Mover modelo para GPU\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=f'{OUTPUT_DIR}/bertimbau_fold_{fold}',\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE*2,\n",
    "        learning_rate=LR,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='f1_macro',\n",
    "        greater_is_better=True,\n",
    "        report_to='none',\n",
    "        seed=SEED,\n",
    "        no_cuda=False,  # Garantir uso de GPU\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    # Salvar modelo do fold\n",
    "    model_path = f'{OUTPUT_DIR}/bertimbau_fold_{fold}/best_model'\n",
    "    trainer.save_model(model_path)\n",
    "    models.append(model_path)\n",
    "    print(f\"✅ Modelo salvo: {model_path}\")\n",
    "    \n",
    "    # OOF predictions\n",
    "    preds = trainer.predict(val_ds)\n",
    "    oof_preds[val_idx] = preds.predictions\n",
    "    fold_f1 = f1_score(train.iloc[val_idx]['target'], np.argmax(preds.predictions, axis=1), average='macro')\n",
    "    fold_scores.append(fold_f1)\n",
    "    print(f\"Fold {fold+1} F1: {fold_f1:.4f}\")\n",
    "    \n",
    "    # Liberar memória GPU entre folds\n",
    "    del model, trainer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# OOF Score final\n",
    "oof_final = np.argmax(oof_preds, axis=1)\n",
    "oof_f1 = f1_score(train['target'], oof_final, average='macro')\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"OOF F1-Macro (média folds): {np.mean(fold_scores):.4f} (+/- {np.std(fold_scores):.4f})\")\n",
    "print(f\"OOF F1-Macro (predições): {oof_f1:.4f}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ffe36c",
   "metadata": {},
   "source": [
    "## 4. Gerar Submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Geração de Submissão (Ensemble de N_FOLDS modelos)\n",
    "# ============================================================\n",
    "# Carregar test\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\n",
    "test_ds = MammographyDataset(test['report'].tolist(), None, tokenizer, MAX_LENGTH)\n",
    "\n",
    "# Ensemble: média das predições de todos os folds\n",
    "all_preds = []\n",
    "\n",
    "print(\"Gerando predições com ensemble...\")\n",
    "for fold, model_path in enumerate(models):\n",
    "    print(f\"  Fold {fold+1}/{N_FOLDS}...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    trainer = Trainer(model=model)\n",
    "    preds = trainer.predict(test_ds)\n",
    "    all_preds.append(preds.predictions)\n",
    "\n",
    "# Média das probabilidades de todos os folds\n",
    "avg_preds = np.mean(all_preds, axis=0)\n",
    "predictions = np.argmax(avg_preds, axis=1)\n",
    "\n",
    "# Criar submission\n",
    "submission = pd.DataFrame({'ID': test['ID'], 'target': predictions})\n",
    "\n",
    "# SEMPRE salvar submission.csv no diretório atual (exigido pelo Kaggle)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"✅ submission.csv salvo no diretório atual\")\n",
    "\n",
    "# Também salvar no OUTPUT_DIR para persistência (Colab/Local)\n",
    "if not IS_KAGGLE:\n",
    "    submission_path = os.path.join(OUTPUT_DIR, 'submission_bertimbau.csv')\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\"✅ Cópia salva em: {submission_path}\")\n",
    "    \n",
    "    # Salvar OOF predictions para ensemble futuro\n",
    "    oof_df = pd.DataFrame(oof_preds, columns=[f'pred_{i}' for i in range(7)])\n",
    "    oof_df['target'] = train['target']\n",
    "    oof_df.to_csv(os.path.join(OUTPUT_DIR, 'oof_bertimbau.csv'), index=False)\n",
    "    print(f\"✅ OOF predictions salvas\")\n",
    "\n",
    "print(f\"\\nDistribuição das predições:\")\n",
    "print(submission['target'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa7e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download no Colab (opcional)\n",
    "if IS_COLAB and os.path.exists('submission.csv'):\n",
    "    from google.colab import files\n",
    "    files.download('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2fe917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
