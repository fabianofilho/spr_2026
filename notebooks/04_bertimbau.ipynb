{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ebad16",
   "metadata": {},
   "source": [
    "# SPR 2026 - BERTimbau (BERT Português)\n",
    "\n",
    "Fine-tuning do BERTimbau para classificação BI-RADS.\n",
    "\n",
    "**Modelo:** neuralmind/bert-base-portuguese-cased\n",
    "\n",
    "**Formato:** Code Competition (Kaggle) / Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb44dd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente: Colab\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "DATA_DIR: /content/drive/MyDrive/SPR_2026_outputs/data\n",
      "OUTPUT_DIR: /content/drive/MyDrive/SPR_2026_outputs\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SETUP - Ambiente e Dados\n",
    "# ============================================================\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Verificar Colab PRIMEIRO (mais confiável)\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input') and not IS_COLAB\n",
    "\n",
    "print(f\"Ambiente: {'Kaggle' if IS_KAGGLE else 'Colab' if IS_COLAB else 'Local'}\")\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    DRIVE_BASE = '/content/drive/MyDrive/SPR_2026_outputs'\n",
    "    DATA_DIR = f'{DRIVE_BASE}/data'\n",
    "    OUTPUT_DIR = DRIVE_BASE\n",
    "    \n",
    "    # Verificar se dados existem no Drive\n",
    "    if not os.path.exists(f'{DATA_DIR}/train.csv'):\n",
    "        print(\"⚠️ Dados não encontrados no Drive!\")\n",
    "        print(\"Execute primeiro o notebook 00_download_data.ipynb\")\n",
    "        raise FileNotFoundError(f\"Arquivo não encontrado: {DATA_DIR}/train.csv\")\n",
    "elif IS_KAGGLE:\n",
    "    DATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "    OUTPUT_DIR = '/kaggle/working'\n",
    "else:\n",
    "    DATA_DIR = '../data'\n",
    "    OUTPUT_DIR = '../submissions'\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a6d5f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Config\n",
    "SEED = 42\n",
    "MODEL_NAME = 'neuralmind/bert-base-portuguese-cased'\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 3\n",
    "LR = 2e-5\n",
    "N_FOLDS = 5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f219f1f",
   "metadata": {},
   "source": [
    "## 1. Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a8df72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (18272, 3)\n",
      "Test: (4, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "print(f\"Train: {train.shape}\")\n",
    "\n",
    "test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "if os.path.exists(test_path):\n",
    "    test = pd.read_csv(test_path)\n",
    "    print(f\"Test: {test.shape}\")\n",
    "    assert set(['ID', 'report']).issubset(test.columns)\n",
    "else:\n",
    "    test = None\n",
    "    print(\"test.csv não disponível - será carregado no runtime Kaggle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213202b7",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206e9ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1d2a56e41d487e9009e59ab71ceb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d881f847294a412abdc90ca3fc41d880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ad6325f307418380358729fe689a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c046686429ca4614b85e9e2f025b65a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5da7afe85c402d806d6ba28ef40c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MammographyDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            str(self.texts[idx]),\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eda21e",
   "metadata": {},
   "source": [
    "## 3. Treinar com K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75348d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Fold 1/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae51b1a3cbea4bb3b76c1417af1d2782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6808fddc0e34b8e8ce1755ebd9b426f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification LOAD REPORT from: neuralmind/bert-base-portuguese-cased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.predictions.decoder.weight             | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "classifier.weight                          | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2666658019.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     args = TrainingArguments(\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{OUTPUT_DIR}/fold_{fold}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d8035147924be9bca84e8f866261b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'f1_macro': f1_score(labels, predictions, average='macro')}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "oof_preds = np.zeros((len(train), 7))\n",
    "fold_scores = []\n",
    "models = []  # Guardar modelos de cada fold\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train, train['target'])):\n",
    "    print(f\"\\n{'='*50}\\nFold {fold+1}/{N_FOLDS}\\n{'='*50}\")\n",
    "    \n",
    "    train_ds = MammographyDataset(\n",
    "        train.iloc[train_idx]['report'].tolist(),\n",
    "        train.iloc[train_idx]['target'].tolist(),\n",
    "        tokenizer, MAX_LENGTH\n",
    "    )\n",
    "    val_ds = MammographyDataset(\n",
    "        train.iloc[val_idx]['report'].tolist(),\n",
    "        train.iloc[val_idx]['target'].tolist(),\n",
    "        tokenizer, MAX_LENGTH\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=7)\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=f'{OUTPUT_DIR}/bertimbau_fold_{fold}',\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE*2,\n",
    "        learning_rate=LR,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='f1_macro',\n",
    "        greater_is_better=True,\n",
    "        report_to='none',\n",
    "        seed=SEED,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    # Salvar modelo do fold\n",
    "    model_path = f'{OUTPUT_DIR}/bertimbau_fold_{fold}/best_model'\n",
    "    trainer.save_model(model_path)\n",
    "    models.append(model_path)\n",
    "    print(f\"✅ Modelo salvo: {model_path}\")\n",
    "    \n",
    "    # OOF predictions\n",
    "    preds = trainer.predict(val_ds)\n",
    "    oof_preds[val_idx] = preds.predictions\n",
    "    fold_f1 = f1_score(train.iloc[val_idx]['target'], np.argmax(preds.predictions, axis=1), average='macro')\n",
    "    fold_scores.append(fold_f1)\n",
    "    print(f\"Fold {fold+1} F1: {fold_f1:.4f}\")\n",
    "\n",
    "# OOF Score final\n",
    "oof_final = np.argmax(oof_preds, axis=1)\n",
    "oof_f1 = f1_score(train['target'], oof_final, average='macro')\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"OOF F1-Macro (média folds): {np.mean(fold_scores):.4f} (+/- {np.std(fold_scores):.4f})\")\n",
    "print(f\"OOF F1-Macro (predições): {oof_f1:.4f}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ffe36c",
   "metadata": {},
   "source": [
    "## 4. Gerar Submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Geração de Submissão (Ensemble de N_FOLDS modelos)\n",
    "# ============================================================\n",
    "# Carregar test\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\n",
    "test_ds = MammographyDataset(test['report'].tolist(), None, tokenizer, MAX_LENGTH)\n",
    "\n",
    "# Ensemble: média das predições de todos os folds\n",
    "all_preds = []\n",
    "\n",
    "print(\"Gerando predições com ensemble...\")\n",
    "for fold, model_path in enumerate(models):\n",
    "    print(f\"  Fold {fold+1}/{N_FOLDS}...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    trainer = Trainer(model=model)\n",
    "    preds = trainer.predict(test_ds)\n",
    "    all_preds.append(preds.predictions)\n",
    "\n",
    "# Média das probabilidades de todos os folds\n",
    "avg_preds = np.mean(all_preds, axis=0)\n",
    "predictions = np.argmax(avg_preds, axis=1)\n",
    "\n",
    "# Criar submission\n",
    "submission = pd.DataFrame({'ID': test['ID'], 'target': predictions})\n",
    "\n",
    "# SEMPRE salvar submission.csv no diretório atual (exigido pelo Kaggle)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"✅ submission.csv salvo no diretório atual\")\n",
    "\n",
    "# Também salvar no OUTPUT_DIR para persistência (Colab/Local)\n",
    "if not IS_KAGGLE:\n",
    "    submission_path = os.path.join(OUTPUT_DIR, 'submission_bertimbau.csv')\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\"✅ Cópia salva em: {submission_path}\")\n",
    "    \n",
    "    # Salvar OOF predictions para ensemble futuro\n",
    "    oof_df = pd.DataFrame(oof_preds, columns=[f'pred_{i}' for i in range(7)])\n",
    "    oof_df['target'] = train['target']\n",
    "    oof_df.to_csv(os.path.join(OUTPUT_DIR, 'oof_bertimbau.csv'), index=False)\n",
    "    print(f\"✅ OOF predictions salvas\")\n",
    "\n",
    "print(f\"\\nDistribuição das predições:\")\n",
    "print(submission['target'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa7e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download no Colab (opcional)\n",
    "if IS_COLAB and os.path.exists('submission.csv'):\n",
    "    from google.colab import files\n",
    "    files.download('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2fe917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
