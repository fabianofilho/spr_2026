{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e33951",
   "metadata": {},
   "source": [
    "# SPR 2026 - Word2Vec + Classifiers\n",
    "\n",
    "Embeddings Word2Vec com classificadores ML.\n",
    "\n",
    "**Formato:** Code Competition (Kaggle) / Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6abe9e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente: Colab\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "DATA_DIR: /content/drive/MyDrive/SPR_2026_outputs/data\n",
      "OUTPUT_DIR: /content/drive/MyDrive/SPR_2026_outputs\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SETUP - Ambiente e Dados\n",
    "# ============================================================\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Verificar Colab PRIMEIRO (mais confiável)\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input') and not IS_COLAB\n",
    "\n",
    "print(f\"Ambiente: {'Kaggle' if IS_KAGGLE else 'Colab' if IS_COLAB else 'Local'}\")\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    DRIVE_BASE = '/content/drive/MyDrive/SPR_2026_outputs'\n",
    "    DATA_DIR = f'{DRIVE_BASE}/data'\n",
    "    OUTPUT_DIR = DRIVE_BASE\n",
    "    \n",
    "    # Verificar se dados existem no Drive\n",
    "    if not os.path.exists(f'{DATA_DIR}/train.csv'):\n",
    "        print(\"⚠️ Dados não encontrados no Drive!\")\n",
    "        print(\"Execute primeiro o notebook 00_download_data.ipynb\")\n",
    "        raise FileNotFoundError(f\"Arquivo não encontrado: {DATA_DIR}/train.csv\")\n",
    "elif IS_KAGGLE:\n",
    "    DATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "    OUTPUT_DIR = '/kaggle/working'\n",
    "else:\n",
    "    DATA_DIR = '../data'\n",
    "    OUTPUT_DIR = '../submissions'\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4defb821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install gensim -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f534ade",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1534698690.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "EMBEDDING_DIM = 100\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ddc24",
   "metadata": {},
   "source": [
    "## 1. Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca23b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "print(f\"Train: {train.shape}\")\n",
    "\n",
    "test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "if os.path.exists(test_path):\n",
    "    test = pd.read_csv(test_path)\n",
    "    print(f\"Test: {test.shape}\")\n",
    "else:\n",
    "    test = None\n",
    "    print(\"test.csv não disponível - será carregado no runtime Kaggle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bde4b8",
   "metadata": {},
   "source": [
    "## 2. Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-záàâãéèêíïóôõöúçñ\\s]', ' ', text)\n",
    "    return text.split()\n",
    "\n",
    "train['tokens'] = train['report'].apply(preprocess)\n",
    "if test is not None:\n",
    "    test['tokens'] = test['report'].apply(preprocess)\n",
    "\n",
    "print(f\"Exemplo: {train['tokens'].iloc[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d253a774",
   "metadata": {},
   "source": [
    "## 3. Treinar Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9721b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todos os textos para treinar Word2Vec\n",
    "all_texts = train['tokens'].tolist()\n",
    "if test is not None:\n",
    "    all_texts += test['tokens'].tolist()\n",
    "\n",
    "w2v = Word2Vec(\n",
    "    sentences=all_texts,\n",
    "    vector_size=EMBEDDING_DIM,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    epochs=10,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "print(f\"Vocabulário: {len(w2v.wv)} palavras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39d78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_embedding(tokens, model, dim):\n",
    "    \"\"\"Média dos vetores de palavras\"\"\"\n",
    "    vectors = [model.wv[w] for w in tokens if w in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(dim)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "X = np.array([text_to_embedding(t, w2v, EMBEDDING_DIM) for t in train['tokens']])\n",
    "y = train['target'].values\n",
    "\n",
    "print(f\"X shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a89c1",
   "metadata": {},
   "source": [
    "## 4. Treinar Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bdd55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED),\n",
    "    'LightGBM': lgb.LGBMClassifier(n_estimators=200, max_depth=10, class_weight='balanced', random_state=SEED, verbose=-1),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=skf, scoring='f1_macro', n_jobs=-1)\n",
    "    results[name] = scores\n",
    "    print(f\"{name}: F1-Macro = {scores.mean():.4f} (+/- {scores.std()*2:.4f})\")\n",
    "\n",
    "best_name = max(results, key=lambda k: results[k].mean())\n",
    "print(f\"\\nMelhor: {best_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d25b64c",
   "metadata": {},
   "source": [
    "## 5. Gerar Submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Geração de Submissão\n",
    "# ============================================================\n",
    "# Treinar modelo final\n",
    "best_model = models[best_name]\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# Carregar test\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\n",
    "test['tokens'] = test['report'].apply(preprocess)\n",
    "\n",
    "# Fazer predições\n",
    "X_test = np.array([text_to_embedding(t, w2v, EMBEDDING_DIM) for t in test['tokens']])\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Criar submission\n",
    "submission = pd.DataFrame({'ID': test['ID'], 'target': predictions})\n",
    "\n",
    "# SEMPRE salvar submission.csv no diretório atual (exigido pelo Kaggle)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"✅ submission.csv salvo no diretório atual\")\n",
    "\n",
    "# Também salvar no OUTPUT_DIR para persistência (Colab/Local)\n",
    "if not IS_KAGGLE:\n",
    "    submission_path = os.path.join(OUTPUT_DIR, 'submission_word2vec.csv')\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\"✅ Cópia salva em: {submission_path}\")\n",
    "\n",
    "print(f\"\\nDistribuição das predições:\")\n",
    "print(submission['target'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a99b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download no Colab (opcional)\n",
    "if IS_COLAB and os.path.exists('submission.csv'):\n",
    "    from google.colab import files\n",
    "    files.download('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
