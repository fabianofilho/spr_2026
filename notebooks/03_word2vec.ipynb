{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e33951",
   "metadata": {},
   "source": [
    "# SPR 2026 - Word2Vec + Classifiers\n",
    "\n",
    "Embeddings Word2Vec com classificadores ML.\n",
    "\n",
    "**Formato:** Code Competition (Kaggle) / Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6abe9e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente: Colab\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "DATA_DIR: /content/drive/MyDrive/SPR_2026_outputs/data\n",
      "OUTPUT_DIR: /content/drive/MyDrive/SPR_2026_outputs\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SETUP - Ambiente e Dados\n",
    "# ============================================================\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Verificar Colab PRIMEIRO (mais confiável)\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input') and not IS_COLAB\n",
    "\n",
    "print(f\"Ambiente: {'Kaggle' if IS_KAGGLE else 'Colab' if IS_COLAB else 'Local'}\")\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    DRIVE_BASE = '/content/drive/MyDrive/SPR_2026_outputs'\n",
    "    DATA_DIR = f'{DRIVE_BASE}/data'\n",
    "    OUTPUT_DIR = DRIVE_BASE\n",
    "    \n",
    "    # Verificar se dados existem no Drive\n",
    "    if not os.path.exists(f'{DATA_DIR}/train.csv'):\n",
    "        print(\"⚠️ Dados não encontrados no Drive!\")\n",
    "        print(\"Execute primeiro o notebook 00_download_data.ipynb\")\n",
    "        raise FileNotFoundError(f\"Arquivo não encontrado: {DATA_DIR}/train.csv\")\n",
    "elif IS_KAGGLE:\n",
    "    DATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "    OUTPUT_DIR = '/kaggle/working'\n",
    "else:\n",
    "    DATA_DIR = '../data'\n",
    "    OUTPUT_DIR = '../submissions'\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4defb821",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f534ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "EMBEDDING_DIM = 100\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ddc24",
   "metadata": {},
   "source": [
    "## 1. Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33ca23b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (18272, 3)\n",
      "Test: (4, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "print(f\"Train: {train.shape}\")\n",
    "\n",
    "test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "if os.path.exists(test_path):\n",
    "    test = pd.read_csv(test_path)\n",
    "    print(f\"Test: {test.shape}\")\n",
    "else:\n",
    "    test = None\n",
    "    print(\"test.csv não disponível - será carregado no runtime Kaggle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bde4b8",
   "metadata": {},
   "source": [
    "## 2. Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11b2b311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo: ['indicação', 'clínica', 'rastreamento', 'achados', 'mamas', 'parcialmente', 'lipossubstituídas', 'calcificações', 'benignas', 'esparsas']\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-záàâãéèêíïóôõöúçñ\\s]', ' ', text)\n",
    "    return text.split()\n",
    "\n",
    "train['tokens'] = train['report'].apply(preprocess)\n",
    "if test is not None:\n",
    "    test['tokens'] = test['report'].apply(preprocess)\n",
    "\n",
    "print(f\"Exemplo: {train['tokens'].iloc[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d253a774",
   "metadata": {},
   "source": [
    "## 3. Treinar Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9721b194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário: 1712 palavras\n"
     ]
    }
   ],
   "source": [
    "# Combinar todos os textos para treinar Word2Vec\n",
    "all_texts = train['tokens'].tolist()\n",
    "if test is not None:\n",
    "    all_texts += test['tokens'].tolist()\n",
    "\n",
    "w2v = Word2Vec(\n",
    "    sentences=all_texts,\n",
    "    vector_size=EMBEDDING_DIM,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    epochs=10,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "print(f\"Vocabulário: {len(w2v.wv)} palavras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f39d78f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (18272, 100)\n"
     ]
    }
   ],
   "source": [
    "def text_to_embedding(tokens, model, dim):\n",
    "    \"\"\"Média dos vetores de palavras\"\"\"\n",
    "    vectors = [model.wv[w] for w in tokens if w in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(dim)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "X = np.array([text_to_embedding(t, w2v, EMBEDDING_DIM) for t in train['tokens']])\n",
    "y = train['target'].values\n",
    "\n",
    "print(f\"X shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a89c1",
   "metadata": {},
   "source": [
    "## 4. Treinar Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01bdd55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: F1-Macro = 0.5163 (+/- 0.0187)\n",
      "LightGBM: F1-Macro = 0.5401 (+/- 0.0871)\n",
      "\n",
      "Melhor: LightGBM\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED),\n",
    "    'LightGBM': lgb.LGBMClassifier(n_estimators=200, max_depth=10, class_weight='balanced', random_state=SEED, verbose=-1),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=skf, scoring='f1_macro', n_jobs=-1)\n",
    "    results[name] = scores\n",
    "    print(f\"{name}: F1-Macro = {scores.mean():.4f} (+/- {scores.std()*2:.4f})\")\n",
    "\n",
    "best_name = max(results, key=lambda k: results[k].mean())\n",
    "print(f\"\\nMelhor: {best_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d25b64c",
   "metadata": {},
   "source": [
    "## 5. Gerar Submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df84551e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ submission.csv salvo no diretório atual\n",
      "✅ Cópia salva em: /content/drive/MyDrive/SPR_2026_outputs/submission_word2vec.csv\n",
      "\n",
      "Distribuição das predições:\n",
      "target\n",
      "1    1\n",
      "2    2\n",
      "3    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Geração de Submissão\n",
    "# ============================================================\n",
    "# Treinar modelo final\n",
    "best_model = models[best_name]\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# Carregar test\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\n",
    "test['tokens'] = test['report'].apply(preprocess)\n",
    "\n",
    "# Fazer predições\n",
    "X_test = np.array([text_to_embedding(t, w2v, EMBEDDING_DIM) for t in test['tokens']])\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Criar submission\n",
    "submission = pd.DataFrame({'ID': test['ID'], 'target': predictions})\n",
    "\n",
    "# SEMPRE salvar submission.csv no diretório atual (exigido pelo Kaggle)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"✅ submission.csv salvo no diretório atual\")\n",
    "\n",
    "# Também salvar no OUTPUT_DIR para persistência (Colab/Local)\n",
    "if not IS_KAGGLE:\n",
    "    submission_path = os.path.join(OUTPUT_DIR, 'submission_word2vec.csv')\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\"✅ Cópia salva em: {submission_path}\")\n",
    "\n",
    "print(f\"\\nDistribuição das predições:\")\n",
    "print(submission['target'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a99b1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_0afa2db2-ef47-4c31-87c0-a1b272f32f82\", \"submission.csv\", 39)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download no Colab (opcional)\n",
    "if IS_COLAB and os.path.exists('submission.csv'):\n",
    "    from google.colab import files\n",
    "    files.download('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c1028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
