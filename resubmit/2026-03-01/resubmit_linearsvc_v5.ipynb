{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d282b3f",
   "metadata": {},
   "source": [
    "# SPR 2026 - LinearSVC v5 (Tratamento + Aumentação + SMOTE)\n",
    "\n",
    "**Score baseline:** 0.77885 (4º melhor)\n",
    "\n",
    "## Melhorias v5:\n",
    "1. **Tratamento de dados:**\n",
    "   - Normalização de termos médicos\n",
    "   - Limpeza de caracteres especiais\n",
    "   - Padronização de formatos\n",
    "\n",
    "2. **Aumentação de dados:**\n",
    "   - SMOTE para classes 5 e 6 (minoritárias)\n",
    "\n",
    "3. **Melhores práticas:**\n",
    "   - TF-IDF 15k features, ngram 1-2, sublinear_tf\n",
    "   - class_weight='balanced'\n",
    "   - CalibratedClassifierCV para probabilidades\n",
    "\n",
    "**Meta:** Superar 0.78+ F1-Macro\n",
    "\n",
    "---\n",
    "## CONFIGURAÇÃO KAGGLE:\n",
    "1. **Add Input** → **Competition** → `spr-2026-mammography-report-classification`\n",
    "2. **Settings** → Internet → **OFF**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SPR 2026 - LINEARSVC v5 (TRATAMENTO + SMOTE) =====\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SPR 2026 - LinearSVC v5 (Tratamento + SMOTE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "SEED = 42\n",
    "DATA_DIR = '/kaggle/input/competitions/spr-2026-mammography-report-classification'\n",
    "\n",
    "# ========== VERIFICAR DATASET PRIMEIRO ==========\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ERRO: Dataset não encontrado!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nAdicione o dataset:\")\n",
    "    print(\"Add Input -> Competition -> spr-2026-mammography-report-classification\")\n",
    "    raise FileNotFoundError(f\"Dataset não encontrado: {DATA_DIR}\")\n",
    "print(f\"Dataset: {DATA_DIR}\")\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ========== CONFIGURAÇÕES ==========\n",
    "USE_SMOTE = True\n",
    "SMOTE_TARGET_5 = 500\n",
    "SMOTE_TARGET_6 = 500\n",
    "USE_CALIBRATION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc769e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== FUNÇÕES DE TRATAMENTO DE DADOS ==========\n",
    "print(\"\\n[1/6] Definindo funções de tratamento...\")\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Limpeza básica do texto.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    # Normalizar espaços\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remover caracteres de controle\n",
    "    text = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def normalize_medical_terms(text):\n",
    "    \"\"\"Normaliza termos médicos comuns em mamografia.\"\"\"\n",
    "    # Normalizar variações de BI-RADS\n",
    "    text = re.sub(r'bi-?rads?', 'BIRADS', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'birads\\s*(\\d)', r'BIRADS \\1', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Normalizar termos anatômicos\n",
    "    text = re.sub(r'qse|quadrante\\s*superior\\s*externo', 'quadrante_superior_externo', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'qsi|quadrante\\s*superior\\s*interno', 'quadrante_superior_interno', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'qie|quadrante\\s*inferior\\s*externo', 'quadrante_inferior_externo', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'qii|quadrante\\s*inferior\\s*interno', 'quadrante_inferior_interno', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Normalizar achados\n",
    "    text = re.sub(r'micro-?calcifica[çc][õo]es', 'microcalcificacoes', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'n[oó]dulo', 'nodulo', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'assimetria\\s*focal', 'assimetria_focal', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'distorção\\s*arquitetural', 'distorcao_arquitetural', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Criar features para negações (importante para classificação)\n",
    "    text = re.sub(r'ausência\\s*de|sem\\s*evidência\\s*de|não\\s*se\\s*observa', 'NEGACAO', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Pipeline completo de pré-processamento.\"\"\"\n",
    "    text = clean_text(text)\n",
    "    text = normalize_medical_terms(text)\n",
    "    return text\n",
    "\n",
    "print(\"Funções de tratamento definidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12004b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CARREGAR E TRATAR DADOS ==========\n",
    "print(\"\\n[2/6] Carregando e tratando dados...\")\n",
    "\n",
    "train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "print(f\"Train: {train.shape} | Test: {test.shape}\")\n",
    "\n",
    "# Auto-detectar colunas\n",
    "def find_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "        for col in df.columns:\n",
    "            if col.lower() == c.lower():\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "TEXT_COL = find_col(train, ['report', 'text', 'laudo', 'texto', 'content'])\n",
    "LABEL_COL = find_col(train, ['target', 'label', 'birads', 'classe', 'class'])\n",
    "ID_COL = find_col(test, ['ID', 'id', 'Id', 'index', 'idx'])\n",
    "print(f\"Colunas: texto={TEXT_COL}, label={LABEL_COL}, id={ID_COL}\")\n",
    "\n",
    "# Aplicar tratamento\n",
    "print(\"\\nAplicando tratamento de texto...\")\n",
    "train['text_processed'] = train[TEXT_COL].apply(preprocess_text)\n",
    "test['text_processed'] = test[TEXT_COL].apply(preprocess_text)\n",
    "\n",
    "# Mostrar exemplo\n",
    "print(\"\\nExemplo de tratamento:\")\n",
    "print(f\"Original: {train[TEXT_COL].iloc[0][:150]}...\")\n",
    "print(f\"Tratado:  {train['text_processed'].iloc[0][:150]}...\")\n",
    "\n",
    "# Distribuição de classes\n",
    "print(\"\\nDistribuição de classes:\")\n",
    "print(train[LABEL_COL].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TF-IDF ==========\n",
    "print(\"\\n[3/6] TF-IDF...\")\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=15000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(train['text_processed'])\n",
    "X_test = tfidf.transform(test['text_processed'])\n",
    "y_train = train[LABEL_COL].values\n",
    "\n",
    "print(f\"TF-IDF shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae1bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SMOTE ==========\n",
    "print(\"\\n[4/6] SMOTE para classes minoritárias...\")\n",
    "\n",
    "if USE_SMOTE:\n",
    "    try:\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        \n",
    "        # Verificar contagem atual\n",
    "        unique, counts = np.unique(y_train, return_counts=True)\n",
    "        print(\"Antes do SMOTE:\")\n",
    "        for u, c in zip(unique, counts):\n",
    "            print(f\"  Classe {u}: {c}\")\n",
    "        \n",
    "        # Aplicar SMOTE\n",
    "        smote = SMOTE(\n",
    "            sampling_strategy={5: SMOTE_TARGET_5, 6: SMOTE_TARGET_6},\n",
    "            random_state=SEED,\n",
    "            k_neighbors=3\n",
    "        )\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        print(f\"\\nApós SMOTE: {X_train_smote.shape[0]} amostras\")\n",
    "        unique, counts = np.unique(y_train_smote, return_counts=True)\n",
    "        for u, c in zip(unique, counts):\n",
    "            print(f\"  Classe {u}: {c}\")\n",
    "            \n",
    "        X_train_final = X_train_smote\n",
    "        y_train_final = y_train_smote\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"imblearn não disponível, usando dados originais\")\n",
    "        X_train_final = X_train\n",
    "        y_train_final = y_train\n",
    "else:\n",
    "    X_train_final = X_train\n",
    "    y_train_final = y_train\n",
    "    print(\"SMOTE desabilitado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TREINAMENTO ==========\n",
    "print(\"\\n[5/6] Treinando LinearSVC...\")\n",
    "\n",
    "# Modelo base\n",
    "base_svc = LinearSVC(\n",
    "    C=1.0,\n",
    "    class_weight='balanced',\n",
    "    random_state=SEED,\n",
    "    max_iter=5000,\n",
    "    tol=1e-4,\n",
    "    dual=True\n",
    ")\n",
    "\n",
    "if USE_CALIBRATION:\n",
    "    print(\"Usando CalibratedClassifierCV...\")\n",
    "    model = CalibratedClassifierCV(base_svc, cv=5, method='sigmoid')\n",
    "else:\n",
    "    model = base_svc\n",
    "\n",
    "# Cross-validation\n",
    "print(\"\\nCross-validation (5-fold)...\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "cv_scores = cross_val_score(base_svc, X_train_final, y_train_final, cv=cv, scoring='f1_macro')\n",
    "print(f\"CV F1-Macro: {cv_scores.mean():.5f} (+/- {cv_scores.std()*2:.5f})\")\n",
    "\n",
    "# Treinar modelo final\n",
    "print(\"\\nTreinando modelo final...\")\n",
    "model.fit(X_train_final, y_train_final)\n",
    "print(\"Modelo treinado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308ffc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== PREDIÇÃO E SUBMISSION ==========\n",
    "print(\"\\n[6/6] Gerando predições...\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Gerar submission\n",
    "submission = pd.DataFrame({\n",
    "    ID_COL: test[ID_COL],\n",
    "    LABEL_COL: predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"\\nSubmission salva: submission.csv\")\n",
    "print(submission.head())\n",
    "print(f\"\\nDistribuição das predições:\")\n",
    "print(pd.Series(predictions).value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
