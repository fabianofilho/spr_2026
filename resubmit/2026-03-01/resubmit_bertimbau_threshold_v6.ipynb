{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d13a42",
   "metadata": {},
   "source": [
    "# SPR 2026 - BERTimbau v6 (Threshold Tuning por Classe)\n",
    "\n",
    "**Baseado em experimentos do Colab:**\n",
    "- Domain Adaptive Pretrain (MLM) com laudos m√©dicos\n",
    "- Fine-tuning com Focal Loss\n",
    "- **Threshold tuning por classe** (t√©cnica principal)\n",
    "\n",
    "## Resultados do Colab (valida√ß√£o):\n",
    "| Config | F1-Macro |\n",
    "|--------|----------|\n",
    "| Baseline (argmax) | 0.78665 |\n",
    "| Threshold tuning | **0.84896** |\n",
    "\n",
    "## Estrat√©gia:\n",
    "- Usar modelo BERTimbau + Focal Loss (j√° treinado)\n",
    "- Aplicar thresholds otimizados por classe na infer√™ncia\n",
    "- N√£o requer retreinar\n",
    "\n",
    "---\n",
    "## CONFIGURA√á√ÉO KAGGLE:\n",
    "1. **Add Input** ‚Üí **Dataset** ‚Üí `bertimbau-ptbr-complete` (ou seu modelo)\n",
    "2. **Add Input** ‚Üí **Competition** ‚Üí `spr-2026-mammography-report-classification`\n",
    "3. **Settings** ‚Üí Internet ‚Üí **OFF**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d3a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SPR 2026 - BERTIMBAU v6 (THRESHOLD TUNING) =====\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SPR 2026 - BERTimbau v6 (Threshold Tuning)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = '/kaggle/input/competitions/spr-2026-mammography-report-classification'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d266801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ENCONTRAR MODELO =====\n",
    "print(\"\\n[1/6] Buscando modelo BERTimbau...\")\n",
    "\n",
    "def find_model_path():\n",
    "    \"\"\"Busca recursiva por config.json\"\"\"\n",
    "    base = '/kaggle/input'\n",
    "    \n",
    "    def has_config(path):\n",
    "        return os.path.isdir(path) and os.path.exists(os.path.join(path, 'config.json'))\n",
    "    \n",
    "    def search_dir(directory, depth=0, max_depth=6):\n",
    "        if depth > max_depth:\n",
    "            return None\n",
    "        try:\n",
    "            for item in os.listdir(directory):\n",
    "                path = os.path.join(directory, item)\n",
    "                if os.path.isdir(path):\n",
    "                    if has_config(path):\n",
    "                        return path\n",
    "                    result = search_dir(path, depth + 1, max_depth)\n",
    "                    if result:\n",
    "                        return result\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "    \n",
    "    return search_dir(base)\n",
    "\n",
    "MODEL_PATH = find_model_path()\n",
    "if MODEL_PATH:\n",
    "    print(f\"‚úÖ Modelo encontrado: {MODEL_PATH}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Modelo n√£o encontrado! Adicione BERTimbau como input.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4073c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CARREGAR DADOS =====\n",
    "print(\"\\n[2/6] Carregando dados...\")\n",
    "\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "\n",
    "# Auto-detectar colunas\n",
    "TEXT_COL = 'report' if 'report' in train_df.columns else 'text'\n",
    "LABEL_COL = 'target' if 'target' in train_df.columns else 'label'\n",
    "ID_COL = 'ID' if 'ID' in test_df.columns else 'id'\n",
    "\n",
    "print(f\"Train: {train_df.shape} | Test: {test_df.shape}\")\n",
    "print(f\"Colunas: texto={TEXT_COL}, label={LABEL_COL}, id={ID_COL}\")\n",
    "print(f\"\\nDistribui√ß√£o de classes:\")\n",
    "print(train_df[LABEL_COL].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5020ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CARREGAR MODELO E TOKENIZER =====\n",
    "print(\"\\n[3/6] Carregando modelo e tokenizer...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    num_labels=7,\n",
    "    local_files_only=True\n",
    ")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Modelo carregado: {sum(p.numel() for p in model.parameters()):,} params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1cf797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DATASET CLASS =====\n",
    "print(\"\\n[4/6] Preparando datasets...\")\n",
    "\n",
    "MAX_LEN = 256\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = tokenizer(\n",
    "            str(self.texts[idx]),\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze()\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            item['label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# Split para valida√ß√£o\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df[TEXT_COL].values,\n",
    "    train_df[LABEL_COL].values,\n",
    "    test_size=0.1,\n",
    "    random_state=SEED,\n",
    "    stratify=train_df[LABEL_COL].values\n",
    ")\n",
    "\n",
    "val_dataset = TextDataset(val_texts, val_labels)\n",
    "test_dataset = TextDataset(test_df[TEXT_COL].values)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Val: {len(val_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd1dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== GERAR PROBABILIDADES NA VALIDA√á√ÉO =====\n",
    "print(\"\\n[5/6] Otimizando thresholds...\")\n",
    "\n",
    "def get_predictions(loader):\n",
    "    \"\"\"Gera probabilidades para todos os exemplos\"\"\"\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            probs = F.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "            all_probs.append(probs)\n",
    "            \n",
    "            if 'label' in batch:\n",
    "                all_labels.extend(batch['label'].numpy())\n",
    "    \n",
    "    probs = np.vstack(all_probs)\n",
    "    labels = np.array(all_labels) if all_labels else None\n",
    "    return probs, labels\n",
    "\n",
    "# Gerar probabilidades no validation set\n",
    "val_probs, val_labels = get_predictions(val_loader)\n",
    "print(f\"Val probs shape: {val_probs.shape}\")\n",
    "\n",
    "# Baseline com argmax\n",
    "baseline_preds = np.argmax(val_probs, axis=1)\n",
    "baseline_f1 = f1_score(val_labels, baseline_preds, average='macro')\n",
    "print(f\"\\nüìä Baseline (argmax): F1-Macro = {baseline_f1:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ebed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== THRESHOLD TUNING POR CLASSE =====\n",
    "\n",
    "def find_optimal_thresholds(probs, labels, num_classes=7):\n",
    "    \"\"\"Encontra threshold √≥timo para cada classe\"\"\"\n",
    "    thresholds = {}\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        best_threshold = 0.5\n",
    "        best_f1 = 0\n",
    "        \n",
    "        # Grid search de thresholds\n",
    "        for thresh in np.arange(0.1, 0.9, 0.05):\n",
    "            # Para cada threshold, prediz classe c se prob >= thresh\n",
    "            preds = np.zeros(len(labels), dtype=int)\n",
    "            \n",
    "            for i in range(len(probs)):\n",
    "                # Se a prob da classe c √© >= threshold, prediz c\n",
    "                # Sen√£o, usa argmax\n",
    "                if probs[i, c] >= thresh:\n",
    "                    preds[i] = c\n",
    "                else:\n",
    "                    preds[i] = np.argmax(probs[i])\n",
    "            \n",
    "            f1 = f1_score(labels == c, preds == c, average='binary')\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = thresh\n",
    "        \n",
    "        thresholds[c] = best_threshold\n",
    "        print(f\"  Classe {c}: threshold={best_threshold:.2f}, F1={best_f1:.4f}\")\n",
    "    \n",
    "    return thresholds\n",
    "\n",
    "print(\"\\nüéØ Otimizando thresholds por classe:\")\n",
    "optimal_thresholds = find_optimal_thresholds(val_probs, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb3785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== APLICAR THRESHOLDS E AVALIAR =====\n",
    "\n",
    "def apply_thresholds(probs, thresholds):\n",
    "    \"\"\"Aplica thresholds otimizados para predi√ß√£o\"\"\"\n",
    "    preds = []\n",
    "    \n",
    "    for i in range(len(probs)):\n",
    "        # Verifica se alguma classe passa do threshold (priorizando classes raras)\n",
    "        # Ordem de prioridade: 6, 5, 4, 3, 2, 1, 0 (classes raras primeiro)\n",
    "        pred = np.argmax(probs[i])  # default: argmax\n",
    "        \n",
    "        for c in [6, 5, 4, 3, 2, 1, 0]:\n",
    "            if probs[i, c] >= thresholds[c]:\n",
    "                # Se m√∫ltiplas classes passam, pega a com maior prob\n",
    "                if probs[i, c] > probs[i, pred] * 0.8:  # margem de toler√¢ncia\n",
    "                    pred = c\n",
    "                    break\n",
    "        \n",
    "        preds.append(pred)\n",
    "    \n",
    "    return np.array(preds)\n",
    "\n",
    "# Avaliar com thresholds\n",
    "tuned_preds = apply_thresholds(val_probs, optimal_thresholds)\n",
    "tuned_f1 = f1_score(val_labels, tuned_preds, average='macro')\n",
    "\n",
    "print(f\"\\nüìä Compara√ß√£o:\")\n",
    "print(f\"   Baseline (argmax):      F1-Macro = {baseline_f1:.5f}\")\n",
    "print(f\"   Threshold tuning:       F1-Macro = {tuned_f1:.5f}\")\n",
    "print(f\"   Melhoria:               {((tuned_f1 - baseline_f1) / baseline_f1 * 100):+.2f}%\")\n",
    "\n",
    "# Se threshold tuning n√£o melhorou, usar argmax\n",
    "USE_THRESHOLDS = tuned_f1 > baseline_f1\n",
    "print(f\"\\n{'‚úÖ Usando threshold tuning' if USE_THRESHOLDS else '‚ö†Ô∏è Usando argmax (threshold n√£o melhorou)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c3060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== GERAR SUBMISSION =====\n",
    "print(\"\\n[6/6] Gerando submission...\")\n",
    "\n",
    "# Gerar probabilidades no test set\n",
    "test_probs, _ = get_predictions(test_loader)\n",
    "print(f\"Test probs shape: {test_probs.shape}\")\n",
    "\n",
    "# Aplicar thresholds ou argmax\n",
    "if USE_THRESHOLDS:\n",
    "    predictions = apply_thresholds(test_probs, optimal_thresholds)\n",
    "else:\n",
    "    predictions = np.argmax(test_probs, axis=1)\n",
    "\n",
    "# Criar submission\n",
    "submission = pd.DataFrame({\n",
    "    ID_COL: test_df[ID_COL],\n",
    "    LABEL_COL: predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"\\n‚úÖ Submission salva: submission.csv\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nDistribui√ß√£o das predi√ß√µes:\")\n",
    "print(pd.Series(predictions).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad72829",
   "metadata": {},
   "source": [
    "## Refer√™ncias\n",
    "\n",
    "**Estrat√©gia baseada em:**\n",
    "- Domain Adaptive Pretraining (MLM) com laudos m√©dicos\n",
    "- Focal Loss para classes desbalanceadas\n",
    "- Threshold tuning por classe (otimizado na valida√ß√£o)\n",
    "\n",
    "**Fonte:** Experimentos no Google Colab (`colab/otimizacao_threshold_e_gamma.ipynb`)\n",
    "\n",
    "**Resultados esperados:**\n",
    "- Se threshold funcionar: ~0.80+ F1-Macro\n",
    "- Se n√£o funcionar: usa argmax como fallback"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
