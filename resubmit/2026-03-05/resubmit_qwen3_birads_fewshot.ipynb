{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d642c724",
   "metadata": {},
   "source": [
    "# SPR 2026 - Qwen 3 4B Few-shot BI-RADS\n",
    "\n",
    "**Modelo:** Qwen/Qwen3-4B-Instruct\n",
    "\n",
    "**Características:**\n",
    "- Few-shot learning com 1 exemplo por categoria\n",
    "- Prompt refinado com exemplos reais\n",
    "- 4B parâmetros - cabe em T4\n",
    "\n",
    "**Hipótese:** Exemplos concretos melhoram a classificação vs zero-shot\n",
    "\n",
    "---\n",
    "## CONFIGURAÇÃO KAGGLE:\n",
    "1. **Add Input** → **Models** → `qwen3-4b-instruct`\n",
    "2. **Add Input** → **Competition** → `spr-2026-mammography-report-classification`\n",
    "3. **Settings** → Internet → **OFF**, GPU → **T4 x2**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a89622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== QWEN 3 4B FEW-SHOT =====\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SPR 2026 - Qwen 3 4B Few-shot BI-RADS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "SEED = 42\n",
    "MAX_NEW_TOKENS = 10\n",
    "DATA_DIR = '/kaggle/input/competitions/spr-2026-mammography-report-classification'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def find_model_path():\n",
    "    base = '/kaggle/input'\n",
    "    def search_dir(directory, depth=0, max_depth=10):\n",
    "        if depth > max_depth: return None\n",
    "        try:\n",
    "            for item in os.listdir(directory):\n",
    "                path = os.path.join(directory, item)\n",
    "                if os.path.isdir(path) and os.path.exists(os.path.join(path, 'config.json')):\n",
    "                    return path\n",
    "                result = search_dir(path, depth + 1, max_depth) if os.path.isdir(path) else None\n",
    "                if result: return result\n",
    "        except: pass\n",
    "        return None\n",
    "    return search_dir(base)\n",
    "\n",
    "MODEL_PATH = find_model_path()\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Model: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c638ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FEW-SHOT EXAMPLES =====\n",
    "\n",
    "FEW_SHOT_EXAMPLES = \"\"\"\n",
    "## Exemplos:\n",
    "\n",
    "Relatório: \"Exame realizado para controle. Imagens mostram parênquima mamário denso, sem nódulos, calcificações suspeitas ou distorções arquiteturais. Pele e subcutâneo preservados. Axilas livres.\"\n",
    "BI-RADS: 1\n",
    "\n",
    "Relatório: \"Presença de nódulo oval, circunscrito, paralelo à pele, no QSE da mama direita, medindo 8mm, com características benignas. Sugere-se fibroadenoma.\"\n",
    "BI-RADS: 2\n",
    "\n",
    "Relatório: \"Identificado nódulo sólido, oval, circunscrito, de 12mm no QIE esquerdo. Provavelmente benigno. Recomenda-se controle em 6 meses.\"\n",
    "BI-RADS: 3\n",
    "\n",
    "Relatório: \"Nódulo irregular, de contornos microlobulados, com 15mm na JQQ da mama direita. Apresenta algumas microcalcificações agrupadas. Biópsia recomendada.\"\n",
    "BI-RADS: 4\n",
    "\n",
    "Relatório: \"Lesão espiculada, densa, de 25mm na região retroareolar esquerda, associada a microcalcificações pleomórficas agrupadas. Altamente sugestiva de malignidade.\"\n",
    "BI-RADS: 5\n",
    "\n",
    "Relatório: \"Paciente com carcinoma ductal invasivo confirmado por biópsia prévia. Estadiamento pré-operatório.\"\n",
    "BI-RADS: 6\n",
    "\n",
    "Relatório: \"Estudo prejudicado por compressão incompleta. Necessária complementação com incidências adicionais.\"\n",
    "BI-RADS: 0\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"Você é um radiologista especialista em classificação BI-RADS de mamografias.\n",
    "\n",
    "## Categorias BI-RADS:\n",
    "- 0: Incompleto - necessita imagens adicionais\n",
    "- 1: Negativo - mamografia normal\n",
    "- 2: Benigno - achados definitivamente benignos\n",
    "- 3: Provavelmente benigno - <2% malignidade, seguimento 6 meses\n",
    "- 4: Suspeito - 2-95% malignidade, biópsia recomendada\n",
    "- 5: Altamente sugestivo de malignidade - >95%\n",
    "- 6: Malignidade comprovada por biópsia\n",
    "\n",
    "{FEW_SHOT_EXAMPLES}\n",
    "\n",
    "Responda APENAS com o número da categoria (0-6).\"\"\"\n",
    "\n",
    "USER_TEMPLATE = \"\"\"Relatório:\n",
    "{report}\n",
    "\n",
    "BI-RADS:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db71474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CARREGAR MODELO =====\n",
    "print(\"Carregando modelo...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH, local_files_only=True,\n",
    "    torch_dtype=torch.bfloat16, device_map=\"auto\", low_cpu_mem_usage=True\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"Modelo: {model.config.architectures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DADOS =====\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "print(f\"Train: {len(train_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e3eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CLASSIFICAÇÃO =====\n",
    "def classify_report(report, model, tokenizer):\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": USER_TEMPLATE.format(report=report)}]\n",
    "    \n",
    "    if hasattr(tokenizer, 'apply_chat_template'):\n",
    "        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    else:\n",
    "        text = f\"{SYSTEM_PROMPT}\\n\\n{USER_TEMPLATE.format(report=report)}\"\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=4096)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=MAX_NEW_TOKENS, do_sample=False,\n",
    "                                  pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    for char in response.strip():\n",
    "        if char.isdigit() and char in '0123456':\n",
    "            return int(char)\n",
    "    return 2\n",
    "\n",
    "# Teste\n",
    "sample = train_df.iloc[0]\n",
    "print(f\"Real: {sample['target']}, Pred: {classify_report(sample['report'], model, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df9415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== VALIDAÇÃO =====\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "val_sample = train_df.groupby('target', group_keys=False).apply(lambda x: x.sample(min(20, len(x)), random_state=SEED))\n",
    "val_preds = [classify_report(row['report'], model, tokenizer) for _, row in tqdm(val_sample.iterrows(), total=len(val_sample))]\n",
    "val_labels = val_sample['target'].values\n",
    "\n",
    "print(f\"\\nF1-Macro: {f1_score(val_labels, val_preds, average='macro'):.5f}\")\n",
    "print(classification_report(val_labels, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ade2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SUBMISSION =====\n",
    "test_preds = [classify_report(row['report'], model, tokenizer) for _, row in tqdm(test_df.iterrows(), total=len(test_df))]\n",
    "\n",
    "submission = pd.DataFrame({'ID': test_df['ID'], 'target': test_preds})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission salva!\")\n",
    "print(submission['target'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
