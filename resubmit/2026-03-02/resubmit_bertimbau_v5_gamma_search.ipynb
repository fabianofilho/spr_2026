{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b86e89a",
   "metadata": {},
   "source": [
    "# SPR 2026 - BERTimbau v5 (Gamma Search)\n",
    "\n",
    "**Baseado em:** BERTimbau v4 (0.82073) ðŸ†\n",
    "\n",
    "**Melhoria:** Testar diferentes valores de Î³ para Focal Loss\n",
    "\n",
    "**EstratÃ©gia:**\n",
    "- Î³ = 1.0: Mais prÃ³ximo de CE\n",
    "- Î³ = 1.5: IntermediÃ¡rio\n",
    "- Î³ = 2.0: Original (baseline)\n",
    "- Î³ = 2.5: Agressivo\n",
    "- Î³ = 3.0: Muito agressivo\n",
    "\n",
    "---\n",
    "## CONFIGURAÃ‡ÃƒO KAGGLE:\n",
    "1. **Add Input** â†’ **Models** â†’ `bertimbau-ptbr-complete`\n",
    "2. **Add Input** â†’ **Competition** â†’ `spr-2026-mammography-report-classification`\n",
    "3. **Settings** â†’ Internet â†’ **OFF**, GPU â†’ **T4 x2**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2eed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== BERTIMBAU v5 - GAMMA SEARCH =====\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SPR 2026 - BERTimbau v5 (Gamma Search)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ===== CONFIG =====\n",
    "SEED = 42\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 3  # Reduzido para testar mÃºltiplos gammas\n",
    "LR = 2e-5\n",
    "NUM_CLASSES = 7\n",
    "FOCAL_ALPHA = 0.25\n",
    "\n",
    "# GAMMAS A TESTAR\n",
    "GAMMAS_TO_TEST = [1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "\n",
    "DATA_DIR = '/kaggle/input/competitions/spr-2026-mammography-report-classification'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def find_model_path():\n",
    "    base = '/kaggle/input'\n",
    "    def has_config(path):\n",
    "        return os.path.isdir(path) and os.path.exists(os.path.join(path, 'config.json'))\n",
    "    def search_dir(directory, depth=0, max_depth=10):\n",
    "        if depth > max_depth: return None\n",
    "        try:\n",
    "            for item in os.listdir(directory):\n",
    "                path = os.path.join(directory, item)\n",
    "                if os.path.isdir(path):\n",
    "                    if has_config(path): return path\n",
    "                    result = search_dir(path, depth + 1, max_depth)\n",
    "                    if result: return result\n",
    "        except: pass\n",
    "        return None\n",
    "    return search_dir(base)\n",
    "\n",
    "MODEL_PATH = find_model_path()\n",
    "print(f\"Device: {device} | Model: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FOCAL LOSS =====\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba03dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DATASET =====\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_len=256):\n",
    "        self.texts, self.labels, self.tokenizer, self.max_len = texts, labels, tokenizer, max_len\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(str(self.texts[idx]), truncation=True, max_length=self.max_len, padding='max_length', return_tensors='pt')\n",
    "        item = {'input_ids': enc['input_ids'].squeeze(), 'attention_mask': enc['attention_mask'].squeeze()}\n",
    "        if self.labels is not None: item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['report'].values, train_df['target'].values,\n",
    "    test_size=0.1, random_state=SEED, stratify=train_df['target']\n",
    ")\n",
    "\n",
    "train_ds = TextDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_ds = TextDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_ds = TextDataset(test_df['report'].values, None, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5329e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TESTAR GAMMAS =====\n",
    "results = {}\n",
    "THRESHOLDS = {0: 0.50, 1: 0.50, 2: 0.50, 3: 0.50, 4: 0.50, 5: 0.30, 6: 0.25}\n",
    "\n",
    "def apply_thresholds(probs, thresholds):\n",
    "    preds = []\n",
    "    for i in range(len(probs)):\n",
    "        pred = np.argmax(probs[i])\n",
    "        for c in [6, 5]:\n",
    "            if probs[i, c] >= thresholds[c]:\n",
    "                pred = c\n",
    "                break\n",
    "        preds.append(pred)\n",
    "    return np.array(preds)\n",
    "\n",
    "for gamma in GAMMAS_TO_TEST:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testando Î³ = {gamma}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    torch.manual_seed(SEED)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=NUM_CLASSES, local_files_only=True)\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = FocalLoss(alpha=FOCAL_ALPHA, gamma=gamma)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*EPOCHS)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"  Loss: {total_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    # Avaliar\n",
    "    model.eval()\n",
    "    all_probs, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            outputs = model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "            all_probs.append(F.softmax(outputs.logits, dim=-1).cpu().numpy())\n",
    "            all_labels.extend(batch['labels'].numpy())\n",
    "    \n",
    "    probs = np.vstack(all_probs)\n",
    "    labels = np.array(all_labels)\n",
    "    preds = apply_thresholds(probs, THRESHOLDS)\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    results[gamma] = {'f1': f1, 'model': model, 'probs': probs}\n",
    "    print(f\"  F1-Macro: {f1:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c812bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== RESULTADOS E SUBMISSION =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS GAMMA SEARCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for gamma, res in sorted(results.items(), key=lambda x: x[1]['f1'], reverse=True):\n",
    "    print(f\"Î³ = {gamma:.1f}: F1 = {res['f1']:.5f}\")\n",
    "\n",
    "best_gamma = max(results, key=lambda x: results[x]['f1'])\n",
    "best_model = results[best_gamma]['model']\n",
    "print(f\"\\nâœ… Melhor Î³ = {best_gamma} com F1 = {results[best_gamma]['f1']:.5f}\")\n",
    "\n",
    "# Gerar submission com melhor modelo\n",
    "best_model.eval()\n",
    "all_probs = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        outputs = best_model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "        all_probs.append(F.softmax(outputs.logits, dim=-1).cpu().numpy())\n",
    "\n",
    "test_probs = np.vstack(all_probs)\n",
    "predictions = apply_thresholds(test_probs, THRESHOLDS)\n",
    "\n",
    "submission = pd.DataFrame({'ID': test_df['ID'], 'target': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"\\nSubmission salva!\")\n",
    "print(submission['target'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
