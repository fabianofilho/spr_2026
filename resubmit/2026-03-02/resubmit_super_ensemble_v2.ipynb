{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4463afba",
   "metadata": {},
   "source": [
    "# SPR 2026 - Super Ensemble v2 (Stacking + Tratamento + SMOTE)\n",
    "\n",
    "**Histórico:**\n",
    "- Super Ensemble v1: 0.78729\n",
    "\n",
    "## Melhorias v2:\n",
    "1. **Tratamento de dados:**\n",
    "   - Normalização de termos médicos\n",
    "   - Features para negações\n",
    "\n",
    "2. **SMOTE:**\n",
    "   - Oversample classes 5 e 6\n",
    "\n",
    "3. **Stacking:**\n",
    "   - Base: LinearSVC, SGD, LogReg, RidgeClassifier\n",
    "   - Meta: LogisticRegression\n",
    "\n",
    "**Meta:** Superar 0.79+ F1-Macro\n",
    "\n",
    "---\n",
    "## CONFIGURAÇÃO KAGGLE:\n",
    "1. **Add Input** → **Competition** → `spr-2026-mammography-report-classification`\n",
    "2. **Settings** → Internet → **OFF**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ccb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SPR 2026 - SUPER ENSEMBLE v2 =====\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SPR 2026 - Super Ensemble v2 (Stacking)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "SEED = 42\n",
    "DATA_DIR = '/kaggle/input/competitions/spr-2026-mammography-report-classification'\n",
    "\n",
    "# ========== VERIFICAR DATASET PRIMEIRO ==========\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ERRO: Dataset não encontrado!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nAdicione o dataset:\")\n",
    "    print(\"Add Input -> Competition -> spr-2026-mammography-report-classification\")\n",
    "    raise FileNotFoundError(f\"Dataset não encontrado: {DATA_DIR}\")\n",
    "print(f\"Dataset: {DATA_DIR}\")\n",
    "\n",
    "np.random.seed(SEED)\n",
    "USE_SMOTE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da250acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== FUNÇÕES DE TRATAMENTO ==========\n",
    "print(\"\\n[1/6] Funções de tratamento...\")\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def normalize_medical_terms(text):\n",
    "    # BI-RADS\n",
    "    text = re.sub(r'bi-?rads?', 'BIRADS', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'birads\\s*(\\d)', r'BIRADS_\\1', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Quadrantes\n",
    "    text = re.sub(r'qse|quadrante\\s*superior\\s*externo', 'QSE', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'qsi|quadrante\\s*superior\\s*interno', 'QSI', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'qie|quadrante\\s*inferior\\s*externo', 'QIE', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'qii|quadrante\\s*inferior\\s*interno', 'QII', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Achados\n",
    "    text = re.sub(r'micro-?calcifica[çc][õo]es', 'MICROCALCIFICACOES', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'n[oó]dulo', 'NODULO', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'assimetria\\s*focal', 'ASSIMETRIA_FOCAL', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Negações\n",
    "    text = re.sub(r'ausência\\s*de|sem\\s*evidência\\s*de|não\\s*se\\s*observa', 'NEGACAO_', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = clean_text(text)\n",
    "    text = normalize_medical_terms(text)\n",
    "    return text\n",
    "\n",
    "print(\"Funções definidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404d34c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CARREGAR DADOS ==========\n",
    "print(\"\\n[2/6] Carregando dados...\")\n",
    "\n",
    "train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "print(f\"Train: {train.shape} | Test: {test.shape}\")\n",
    "\n",
    "# Auto-detectar colunas\n",
    "def find_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "TEXT_COL = find_col(train, ['report', 'text', 'laudo'])\n",
    "LABEL_COL = find_col(train, ['target', 'label', 'birads'])\n",
    "ID_COL = find_col(test, ['ID', 'id', 'Id'])\n",
    "print(f\"Colunas: texto={TEXT_COL}, label={LABEL_COL}, id={ID_COL}\")\n",
    "\n",
    "# Tratamento\n",
    "train['text_processed'] = train[TEXT_COL].apply(preprocess_text)\n",
    "test['text_processed'] = test[TEXT_COL].apply(preprocess_text)\n",
    "print(\"Texto tratado!\")\n",
    "\n",
    "# TF-IDF\n",
    "print(\"\\n[3/6] TF-IDF (20k features)...\")\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(train['text_processed'])\n",
    "X_test = tfidf.transform(test['text_processed'])\n",
    "y_train = train[LABEL_COL].values\n",
    "print(f\"Shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacccc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SMOTE ==========\n",
    "print(\"\\n[4/6] SMOTE...\")\n",
    "\n",
    "if USE_SMOTE:\n",
    "    try:\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        smote = SMOTE(sampling_strategy={5: 500, 6: 500}, random_state=SEED, k_neighbors=3)\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        print(f\"SMOTE: {X_train.shape[0]} -> {X_train_smote.shape[0]} amostras\")\n",
    "        X_final = X_train_smote\n",
    "        y_final = y_train_smote\n",
    "    except ImportError:\n",
    "        print(\"imblearn não disponível\")\n",
    "        X_final = X_train\n",
    "        y_final = y_train\n",
    "else:\n",
    "    X_final = X_train\n",
    "    y_final = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a2790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== STACKING ENSEMBLE ==========\n",
    "print(\"\\n[5/6] Stacking Ensemble...\")\n",
    "\n",
    "# Base estimators\n",
    "print(\"Definindo base estimators...\")\n",
    "\n",
    "# LinearSVC precisa de calibração para probabilidades\n",
    "svc_base = LinearSVC(C=1.0, class_weight='balanced', random_state=SEED, max_iter=5000)\n",
    "svc_calib = CalibratedClassifierCV(svc_base, cv=3, method='sigmoid')\n",
    "\n",
    "estimators = [\n",
    "    ('svc', svc_calib),\n",
    "    ('sgd', SGDClassifier(\n",
    "        loss='log_loss',\n",
    "        penalty='elasticnet',\n",
    "        alpha=0.0001,\n",
    "        l1_ratio=0.3,\n",
    "        class_weight='balanced',\n",
    "        random_state=SEED,\n",
    "        max_iter=2000,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "    ('logreg', LogisticRegression(\n",
    "        C=1.0,\n",
    "        class_weight='balanced',\n",
    "        random_state=SEED,\n",
    "        max_iter=2000,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "    ('ridge', RidgeClassifier(\n",
    "        alpha=1.0,\n",
    "        class_weight='balanced',\n",
    "        random_state=SEED\n",
    "    ))\n",
    "]\n",
    "\n",
    "# Meta-learner\n",
    "meta_clf = LogisticRegression(\n",
    "    C=0.5,\n",
    "    class_weight='balanced',\n",
    "    random_state=SEED,\n",
    "    max_iter=2000\n",
    ")\n",
    "\n",
    "# Stacking\n",
    "print(\"Criando StackingClassifier...\")\n",
    "stack = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=meta_clf,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED),\n",
    "    stack_method='predict_proba',\n",
    "    passthrough=False,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Treinando...\")\n",
    "stack.fit(X_final, y_final)\n",
    "print(\"Stacking treinado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SUBMISSION ==========\n",
    "print(\"\\n[6/6] Gerando submission...\")\n",
    "\n",
    "predictions = stack.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    ID_COL: test[ID_COL],\n",
    "    LABEL_COL: predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"\\nSubmission salva: submission.csv\")\n",
    "print(submission.head())\n",
    "print(f\"\\nDistribuição:\")\n",
    "print(pd.Series(predictions).value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
