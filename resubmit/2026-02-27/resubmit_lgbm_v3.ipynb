{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPR 2026 - LightGBM v3 (RandomizedSearch)\n",
    "\n",
    "**Score baseline (v2):** 0.70273\n",
    "\n",
    "**Melhorias:**\n",
    "- RandomizedSearchCV para tuning\n",
    "- Class weights balanceados\n",
    "- TruncatedSVD + StandardScaler\n",
    "- Early stopping\n",
    "- Threshold tuning por classe\n",
    "- SMOTE para classes 5/6 (opcional)\n",
    "- Flag para remover classe 2\n",
    "\n",
    "---\n",
    "**CONFIGURACAO KAGGLE:** Internet OFF, GPU T4 x2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from scipy.stats import randint, uniform\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SPR 2026 - LightGBM v3 (RandomizedSearch)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "SEED = 42\n",
    "SVD_COMPONENTS = 500\n",
    "DATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "\n",
    "# ========== VERIFICAR DATASET PRIMEIRO ==========\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ERRO: Dataset não encontrado!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nAdicione o dataset:\")\n",
    "    print(\"Add Input → Competition → spr-2026-mammography-report-classification\")\n",
    "    raise FileNotFoundError(f\"Dataset não encontrado: {DATA_DIR}\")\n",
    "print(f\"Dataset: {DATA_DIR}\")\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# FLAGS - AJUSTE AQUI\n",
    "REMOVE_CLASS_2 = False\n",
    "USE_SMOTE = False\n",
    "USE_THRESHOLD_TUNING = True\n",
    "N_SEARCH_ITER = 20\n",
    "\n",
    "print(f\"GPU: {USE_GPU}\")\n",
    "\n",
    "# Dados\n",
    "print(\"\\n[1/7] Carregando dados...\")\n",
    "train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "print(f\"Train: {train.shape} | Test: {test.shape}\")\n",
    "\n",
    "# Auto-detectar colunas\n",
    "def find_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "        for col in df.columns:\n",
    "            if col.lower() == c.lower():\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "TEXT_COL = find_col(train, ['report', 'text', 'laudo', 'texto', 'content'])\n",
    "LABEL_COL = find_col(train, ['target', 'label', 'birads', 'classe', 'class'])\n",
    "ID_COL = find_col(test, ['ID', 'id', 'Id', 'index', 'idx'])\n",
    "print(f\"Colunas: texto={TEXT_COL}, label={LABEL_COL}, id={ID_COL}\")\n",
    "\n",
    "if REMOVE_CLASS_2:\n",
    "    train = train[train[LABEL_COL] != 2].reset_index(drop=True)\n",
    "    print(f\"Sem classe 2: {train.shape}\")\n",
    "\n",
    "# TF-IDF\n",
    "print(\"\\n[2/7] TF-IDF...\")\n",
    "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1,2), min_df=2, max_df=0.95, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(train[TEXT_COL])\n",
    "X_test_tfidf = tfidf.transform(test[TEXT_COL])\n",
    "y_train = train[LABEL_COL].values\n",
    "print(f\"TF-IDF: {X_train_tfidf.shape}\")\n",
    "\n",
    "# SVD\n",
    "print(f\"\\n[3/7] SVD -> {SVD_COMPONENTS} features...\")\n",
    "svd = TruncatedSVD(n_components=SVD_COMPONENTS, random_state=SEED)\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "print(f\"Variancia: {svd.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_svd)\n",
    "X_test = scaler.transform(X_test_svd)\n",
    "\n",
    "# SMOTE opcional\n",
    "if USE_SMOTE:\n",
    "    try:\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        smote = SMOTE(sampling_strategy={5:500, 6:500}, random_state=SEED, k_neighbors=3)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        print(f\"SMOTE: {X_train.shape}\")\n",
    "    except ImportError:\n",
    "        print(\"imblearn nao disponivel\")\n",
    "\n",
    "# RandomizedSearch\n",
    "print(f\"\\n[4/7] RandomizedSearchCV ({N_SEARCH_ITER} iter)...\")\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(4, 12),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'num_leaves': randint(15, 63),\n",
    "    'min_child_samples': randint(10, 50),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1),\n",
    "}\n",
    "base = lgb.LGBMClassifier(class_weight='balanced', device='gpu' if USE_GPU else 'cpu', random_state=SEED, n_jobs=-1, verbose=-1)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "search = RandomizedSearchCV(base, param_dist, n_iter=N_SEARCH_ITER, cv=cv, scoring='f1_macro', n_jobs=1, random_state=SEED, verbose=1)\n",
    "search.fit(X_train, y_train)\n",
    "print(f\"Best params: {search.best_params_}\")\n",
    "print(f\"Best F1-macro: {search.best_score_:.4f}\")\n",
    "\n",
    "# Retreinar com early stopping\n",
    "print(\"\\n[5/7] Retreinando com early stopping...\")\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=SEED, stratify=y_train)\n",
    "best_params = search.best_params_.copy()\n",
    "best_params['n_estimators'] = 500\n",
    "final_model = lgb.LGBMClassifier(**best_params, class_weight='balanced', device='gpu' if USE_GPU else 'cpu', random_state=SEED, n_jobs=-1, verbose=-1)\n",
    "final_model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(30, verbose=True), lgb.log_evaluation(50)])\n",
    "print(f\"Best iteration: {final_model.best_iteration_}\")\n",
    "\n",
    "# Threshold tuning\n",
    "if USE_THRESHOLD_TUNING:\n",
    "    print(\"\\n[6/7] Threshold tuning...\")\n",
    "    proba = final_model.predict_proba(X_test)\n",
    "    classes = final_model.classes_\n",
    "    thresholds = {0:0.5, 1:0.5, 2:0.5, 3:0.5, 4:0.5, 5:0.35, 6:0.35}\n",
    "    preds = []\n",
    "    for i in range(len(proba)):\n",
    "        adj = proba[i].copy()\n",
    "        for j,c in enumerate(classes):\n",
    "            if c in thresholds:\n",
    "                adj[j] *= (0.5/thresholds[c])\n",
    "        preds.append(classes[np.argmax(adj)])\n",
    "    predictions = np.array(preds)\n",
    "else:\n",
    "    print(\"\\n[6/7] Predicao padrao...\")\n",
    "    predictions = final_model.predict(X_test)\n",
    "\n",
    "# Submissao\n",
    "print(\"\\n[7/7] Gerando submissao...\")\n",
    "\n",
    "# Ler sample_submission para colunas corretas\n",
    "sample_path = f'{DATA_DIR}/sample_submission.csv'\n",
    "if os.path.exists(sample_path):\n",
    "    sample_sub = pd.read_csv(sample_path)\n",
    "    SUB_ID = sample_sub.columns[0]\n",
    "    SUB_LABEL = sample_sub.columns[1]\n",
    "else:\n",
    "    SUB_ID = ID_COL\n",
    "    SUB_LABEL = LABEL_COL\n",
    "\n",
    "submission = pd.DataFrame({SUB_ID: test[ID_COL], SUB_LABEL: predictions})\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "print(\"=\"*60)\n",
    "print(\"CONCLUIDO!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDistribuicao:\")\n",
    "print(submission[SUB_LABEL].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
