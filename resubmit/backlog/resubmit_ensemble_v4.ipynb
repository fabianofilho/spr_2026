{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e1d76e2",
   "metadata": {},
   "source": [
    "# SPR 2026 - Ensemble v4 (Top TF-IDF + Tratamento + SMOTE)\n",
    "\n",
    "**Scores dos modelos base:**\n",
    "- LinearSVC: 0.77885\n",
    "- SGDClassifier v3: 0.77036\n",
    "- LogisticRegression: 0.72935\n",
    "\n",
    "## Melhorias v4:\n",
    "1. **Tratamento de dados:**\n",
    "   - Normalização de termos médicos\n",
    "   - Features para negações\n",
    "\n",
    "2. **Aumentação:**\n",
    "   - SMOTE para classes 5 e 6\n",
    "\n",
    "3. **Ensemble:**\n",
    "   - Weighted soft voting\n",
    "   - Pesos proporcionais ao score\n",
    "   - CalibratedClassifierCV para probabilidades\n",
    "\n",
    "**Meta:** Superar 0.79+ F1-Macro\n",
    "\n",
    "---\n",
    "## CONFIGURAÇÃO KAGGLE:\n",
    "1. **Add Input** → **Competition** → `spr-2026-mammography-report-classification`\n",
    "2. **Settings** → Internet → **OFF**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SPR 2026 - ENSEMBLE v4 =====\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SPR 2026 - Ensemble v4 (Top TF-IDF + Tratamento + SMOTE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "SEED = 42\n",
    "DATA_DIR = '/kaggle/input/competitions/spr-2026-mammography-report-classification'\n",
    "\n",
    "# ========== VERIFICAR DATASET PRIMEIRO ==========\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ERRO: Dataset não encontrado!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nAdicione o dataset:\")\n",
    "    print(\"Add Input -> Competition -> spr-2026-mammography-report-classification\")\n",
    "    raise FileNotFoundError(f\"Dataset não encontrado: {DATA_DIR}\")\n",
    "print(f\"Dataset: {DATA_DIR}\")\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ========== PESOS DO ENSEMBLE ==========\n",
    "# Baseado nos scores públicos (normalizados)\n",
    "WEIGHTS = {\n",
    "    'linearsvc': 0.40,   # 0.77885 - melhor TF-IDF\n",
    "    'sgd': 0.35,         # 0.77036 - único que melhorou\n",
    "    'logreg': 0.25       # 0.72935 - para diversidade\n",
    "}\n",
    "print(f\"Pesos: {WEIGHTS}\")\n",
    "\n",
    "USE_SMOTE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8342e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== FUNÇÕES DE TRATAMENTO ==========\n",
    "print(\"\\n[1/7] Funções de tratamento...\")\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def normalize_medical_terms(text):\n",
    "    # BI-RADS\n",
    "    text = re.sub(r'bi-?rads?', 'BIRADS', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'birads\\s*(\\d)', r'BIRADS_\\1', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Quadrantes\n",
    "    text = re.sub(r'qse|quadrante\\s*superior\\s*externo', 'QSE', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'qsi|quadrante\\s*superior\\s*interno', 'QSI', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'qie|quadrante\\s*inferior\\s*externo', 'QIE', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'qii|quadrante\\s*inferior\\s*interno', 'QII', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Achados\n",
    "    text = re.sub(r'micro-?calcifica[çc][õo]es', 'MICROCALCIFICACOES', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'n[oó]dulo', 'NODULO', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'assimetria\\s*focal', 'ASSIMETRIA_FOCAL', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'distorção\\s*arquitetural', 'DISTORCAO_ARQUITETURAL', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Negações importantes\n",
    "    text = re.sub(r'ausência\\s*de|sem\\s*evidência\\s*de|não\\s*se\\s*observa', 'NEGACAO_', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = clean_text(text)\n",
    "    text = normalize_medical_terms(text)\n",
    "    return text\n",
    "\n",
    "print(\"Funções definidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e08755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CARREGAR DADOS ==========\n",
    "print(\"\\n[2/7] Carregando dados...\")\n",
    "\n",
    "train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "print(f\"Train: {train.shape} | Test: {test.shape}\")\n",
    "\n",
    "# Auto-detectar colunas\n",
    "def find_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "TEXT_COL = find_col(train, ['report', 'text', 'laudo'])\n",
    "LABEL_COL = find_col(train, ['target', 'label', 'birads'])\n",
    "ID_COL = find_col(test, ['ID', 'id', 'Id'])\n",
    "print(f\"Colunas: texto={TEXT_COL}, label={LABEL_COL}, id={ID_COL}\")\n",
    "\n",
    "# Tratamento\n",
    "train['text_processed'] = train[TEXT_COL].apply(preprocess_text)\n",
    "test['text_processed'] = test[TEXT_COL].apply(preprocess_text)\n",
    "print(\"Tratamento aplicado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TF-IDF ==========\n",
    "print(\"\\n[3/7] TF-IDF...\")\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(train['text_processed'])\n",
    "X_test = tfidf.transform(test['text_processed'])\n",
    "y_train = train[LABEL_COL].values\n",
    "print(f\"Shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040081d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SMOTE ==========\n",
    "print(\"\\n[4/7] SMOTE...\")\n",
    "\n",
    "if USE_SMOTE:\n",
    "    try:\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        smote = SMOTE(sampling_strategy={5: 500, 6: 500}, random_state=SEED, k_neighbors=3)\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        print(f\"SMOTE: {X_train.shape[0]} -> {X_train_smote.shape[0]} amostras\")\n",
    "        X_train_final, y_train_final = X_train_smote, y_train_smote\n",
    "    except ImportError:\n",
    "        print(\"imblearn não disponível\")\n",
    "        X_train_final, y_train_final = X_train, y_train\n",
    "else:\n",
    "    X_train_final, y_train_final = X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108da53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TREINAR MODELOS ==========\n",
    "print(\"\\n[5/7] Treinando modelos...\")\n",
    "\n",
    "# LinearSVC + Calibração\n",
    "print(\"LinearSVC...\")\n",
    "svc_base = LinearSVC(C=1.0, class_weight='balanced', random_state=SEED, max_iter=5000, dual=True)\n",
    "svc = CalibratedClassifierCV(svc_base, cv=5, method='sigmoid')\n",
    "svc.fit(X_train_final, y_train_final)\n",
    "\n",
    "# SGDClassifier (config v3)\n",
    "print(\"SGDClassifier...\")\n",
    "sgd = SGDClassifier(\n",
    "    loss='log_loss',\n",
    "    penalty='elasticnet',\n",
    "    alpha=0.0001,\n",
    "    l1_ratio=0.3,\n",
    "    class_weight='balanced',\n",
    "    random_state=SEED,\n",
    "    max_iter=2000,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sgd.fit(X_train_final, y_train_final)\n",
    "\n",
    "# LogisticRegression\n",
    "print(\"LogisticRegression...\")\n",
    "logreg = LogisticRegression(\n",
    "    C=1.0,\n",
    "    class_weight='balanced',\n",
    "    random_state=SEED,\n",
    "    max_iter=2000,\n",
    "    n_jobs=-1\n",
    ")\n",
    "logreg.fit(X_train_final, y_train_final)\n",
    "\n",
    "print(\"Todos os modelos treinados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== ENSEMBLE VOTING ==========\n",
    "print(\"\\n[6/7] Ensemble soft voting...\")\n",
    "\n",
    "# Obter probabilidades\n",
    "probs_svc = svc.predict_proba(X_test)\n",
    "probs_sgd = sgd.predict_proba(X_test)\n",
    "probs_logreg = logreg.predict_proba(X_test)\n",
    "\n",
    "# Weighted average\n",
    "probs_ensemble = (\n",
    "    WEIGHTS['linearsvc'] * probs_svc +\n",
    "    WEIGHTS['sgd'] * probs_sgd +\n",
    "    WEIGHTS['logreg'] * probs_logreg\n",
    ")\n",
    "\n",
    "predictions = np.argmax(probs_ensemble, axis=1)\n",
    "print(f\"Predições geradas: {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076de55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SUBMISSION ==========\n",
    "print(\"\\n[7/7] Gerando submission...\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    ID_COL: test[ID_COL],\n",
    "    LABEL_COL: predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"\\nSubmission salva: submission.csv\")\n",
    "print(submission.head())\n",
    "print(f\"\\nDistribuição:\")\n",
    "print(pd.Series(predictions).value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
