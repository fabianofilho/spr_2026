{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a363c2",
   "metadata": {},
   "source": [
    "# SPR 2026 - ClinicalBERT (Classificação Direta)\n",
    "\n",
    "**Modelo:** medicalai/ClinicalBERT\n",
    "\n",
    "**Características:**\n",
    "- Modelo BERT encoder adaptado para texto clínico\n",
    "- Classificação direta (não generativa)\n",
    "- Mais eficiente para classificação de categorias fixas\n",
    "- Fine-tuning similar ao BERTimbau\n",
    "\n",
    "**Abordagem:** Fine-tuning para classificação (7 classes)\n",
    "\n",
    "---\n",
    "## CONFIGURAÇÃO KAGGLE:\n",
    "1. **Add Input** → **Models** → `clinicalbert` ou similar\n",
    "2. **Add Input** → **Competition** → `spr-2026-mammography-report-classification`\n",
    "3. **Settings** → Internet → **OFF**, GPU → **T4 x2**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CLINICALBERT - CLASSIFICAÇÃO DIRETA =====\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SPR 2026 - ClinicalBERT (Fine-tuning)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ===== CONFIG =====\n",
    "SEED = 42\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 5\n",
    "LR = 2e-5\n",
    "NUM_CLASSES = 7\n",
    "FOCAL_GAMMA = 2.0\n",
    "FOCAL_ALPHA = 0.25\n",
    "THRESHOLDS = {0: 0.50, 1: 0.50, 2: 0.50, 3: 0.50, 4: 0.50, 5: 0.30, 6: 0.25}\n",
    "\n",
    "DATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def find_model_path():\n",
    "    base = '/kaggle/input'\n",
    "    def search_dir(directory, depth=0, max_depth=10):\n",
    "        if depth > max_depth: return None\n",
    "        try:\n",
    "            for item in os.listdir(directory):\n",
    "                path = os.path.join(directory, item)\n",
    "                if os.path.isdir(path) and os.path.exists(os.path.join(path, 'config.json')):\n",
    "                    return path\n",
    "                result = search_dir(path, depth + 1, max_depth) if os.path.isdir(path) else None\n",
    "                if result: return result\n",
    "        except: pass\n",
    "        return None\n",
    "    return search_dir(base)\n",
    "\n",
    "MODEL_PATH = find_model_path()\n",
    "print(f\"Device: {device} | Model: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c5923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FOCAL LOSS =====\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha, self.gamma = alpha, gamma\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        return (self.alpha * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "criterion = FocalLoss(alpha=FOCAL_ALPHA, gamma=FOCAL_GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1898d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DATASET =====\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_len=256):\n",
    "        self.texts, self.labels, self.tokenizer, self.max_len = texts, labels, tokenizer, max_len\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(str(self.texts[idx]), truncation=True, max_length=self.max_len, padding='max_length', return_tensors='pt')\n",
    "        item = {'input_ids': enc['input_ids'].squeeze(), 'attention_mask': enc['attention_mask'].squeeze()}\n",
    "        if self.labels is not None: item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['report'].values, train_df['target'].values,\n",
    "    test_size=0.1, random_state=SEED, stratify=train_df['target']\n",
    ")\n",
    "\n",
    "train_ds = TextDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_ds = TextDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "test_ds = TextDataset(test_df['report'].values, None, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TREINAR =====\n",
    "print(\"\\nTreinando ClinicalBERT...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=NUM_CLASSES, local_files_only=True)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*EPOCHS)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "        loss = criterion(outputs.logits, batch['labels'].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"  Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733b2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== AVALIAR =====\n",
    "def apply_thresholds(probs, thresholds):\n",
    "    preds = []\n",
    "    for i in range(len(probs)):\n",
    "        pred = np.argmax(probs[i])\n",
    "        for c in [6, 5]:\n",
    "            if probs[i, c] >= thresholds[c]:\n",
    "                pred = c\n",
    "                break\n",
    "        preds.append(pred)\n",
    "    return np.array(preds)\n",
    "\n",
    "model.eval()\n",
    "val_probs = []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        outputs = model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "        val_probs.append(F.softmax(outputs.logits, dim=-1).cpu().numpy())\n",
    "\n",
    "val_probs = np.vstack(val_probs)\n",
    "\n",
    "baseline_preds = np.argmax(val_probs, axis=1)\n",
    "tuned_preds = apply_thresholds(val_probs, THRESHOLDS)\n",
    "\n",
    "print(f\"Baseline F1: {f1_score(val_labels, baseline_preds, average='macro'):.5f}\")\n",
    "print(f\"Threshold F1: {f1_score(val_labels, tuned_preds, average='macro'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d83a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SUBMISSION =====\n",
    "test_probs = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        outputs = model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "        test_probs.append(F.softmax(outputs.logits, dim=-1).cpu().numpy())\n",
    "\n",
    "test_probs = np.vstack(test_probs)\n",
    "predictions = apply_thresholds(test_probs, THRESHOLDS)\n",
    "\n",
    "submission = pd.DataFrame({'ID': test_df['ID'], 'target': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"\\nSubmission salva!\")\n",
    "print(submission['target'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3af99a",
   "metadata": {},
   "source": [
    "## Comparação: ClinicalBERT vs BERTimbau\n",
    "\n",
    "| Aspecto | ClinicalBERT | BERTimbau |\n",
    "|---------|--------------|-----------|\n",
    "| Idioma | Inglês (clínico) | Português |\n",
    "| Domínio | Textos clínicos | Geral PT-BR |\n",
    "| Arquitetura | BERT encoder | BERT encoder |\n",
    "| Vantagem | Terminologia médica inglês | Língua nativa dos laudos |\n",
    "\n",
    "**Hipótese:** BERTimbau pode ter vantagem por entender português, mas ClinicalBERT conhece terminologia médica."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
