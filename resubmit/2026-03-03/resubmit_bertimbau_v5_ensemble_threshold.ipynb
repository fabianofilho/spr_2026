{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87b9f351",
   "metadata": {},
   "source": [
    "# SPR 2026 - BERTimbau v5 (Ensemble + Threshold)\n",
    "\n",
    "**Baseado em:** BERTimbau v4 (0.82073) ðŸ†\n",
    "\n",
    "**Melhoria:** Combinar mÃºltiplos transformers + threshold tuning\n",
    "\n",
    "**EstratÃ©gia:**\n",
    "- BERTimbau (principal)\n",
    "- BioBERTpt (especializado)\n",
    "- MÃ©dia ponderada das probabilidades\n",
    "- Threshold tuning no ensemble\n",
    "\n",
    "---\n",
    "## CONFIGURAÃ‡ÃƒO KAGGLE:\n",
    "1. **Add Input** â†’ **Models** â†’ `bertimbau-ptbr-complete`\n",
    "2. **Add Input** â†’ **Models** â†’ `biobert-pt` (se disponÃ­vel)\n",
    "3. **Add Input** â†’ **Competition** â†’ `spr-2026-mammography-report-classification`\n",
    "4. **Settings** â†’ Internet â†’ **OFF**, GPU â†’ **T4 x2**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa12da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== BERTIMBAU v5 - ENSEMBLE + THRESHOLD =====\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SPR 2026 - BERTimbau v5 (Ensemble + Threshold)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ===== CONFIG =====\n",
    "SEED = 42\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 3\n",
    "LR = 2e-5\n",
    "NUM_CLASSES = 7\n",
    "FOCAL_GAMMA = 2.0\n",
    "FOCAL_ALPHA = 0.25\n",
    "THRESHOLDS = {0: 0.50, 1: 0.50, 2: 0.50, 3: 0.50, 4: 0.50, 5: 0.30, 6: 0.25}\n",
    "\n",
    "DATA_DIR = '/kaggle/input/spr-2026-mammography-report-classification'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Encontrar todos os modelos disponÃ­veis\n",
    "def find_all_models():\n",
    "    base = '/kaggle/input'\n",
    "    models = []\n",
    "    def has_config(path):\n",
    "        return os.path.isdir(path) and os.path.exists(os.path.join(path, 'config.json'))\n",
    "    def search_dir(directory, depth=0, max_depth=10):\n",
    "        if depth > max_depth: return\n",
    "        try:\n",
    "            for item in os.listdir(directory):\n",
    "                path = os.path.join(directory, item)\n",
    "                if os.path.isdir(path):\n",
    "                    if has_config(path):\n",
    "                        models.append(path)\n",
    "                    search_dir(path, depth + 1, max_depth)\n",
    "        except: pass\n",
    "    search_dir(base)\n",
    "    return models\n",
    "\n",
    "MODEL_PATHS = find_all_models()\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Modelos encontrados: {len(MODEL_PATHS)}\")\n",
    "for p in MODEL_PATHS:\n",
    "    print(f\"  - {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94716f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FOCAL LOSS & DATASET =====\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha, self.gamma = alpha, gamma\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        return (self.alpha * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_len=256):\n",
    "        self.texts, self.labels, self.tokenizer, self.max_len = texts, labels, tokenizer, max_len\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(str(self.texts[idx]), truncation=True, max_length=self.max_len, padding='max_length', return_tensors='pt')\n",
    "        item = {'input_ids': enc['input_ids'].squeeze(), 'attention_mask': enc['attention_mask'].squeeze()}\n",
    "        if self.labels is not None: item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['report'].values, train_df['target'].values,\n",
    "    test_size=0.1, random_state=SEED, stratify=train_df['target']\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_texts)}, Val: {len(val_texts)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TREINAR CADA MODELO =====\n",
    "val_probs_ensemble = []\n",
    "test_probs_ensemble = []\n",
    "model_weights = []  # Para weighted average\n",
    "criterion = FocalLoss(alpha=FOCAL_ALPHA, gamma=FOCAL_GAMMA)\n",
    "\n",
    "for model_path in MODEL_PATHS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Treinando: {model_path.split('/')[-1]}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "        \n",
    "        train_ds = TextDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "        val_ds = TextDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "        test_ds = TextDataset(test_df['report'].values, None, tokenizer, MAX_LEN)\n",
    "        \n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "        test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "        \n",
    "        torch.manual_seed(SEED)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=NUM_CLASSES, local_files_only=True)\n",
    "        model.to(device)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*EPOCHS)\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            model.train()\n",
    "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "                loss = criterion(outputs.logits, batch['labels'].to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "        \n",
    "        # Coletar probabilidades\n",
    "        model.eval()\n",
    "        val_probs, test_probs = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                outputs = model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "                val_probs.append(F.softmax(outputs.logits, dim=-1).cpu().numpy())\n",
    "            for batch in test_loader:\n",
    "                outputs = model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "                test_probs.append(F.softmax(outputs.logits, dim=-1).cpu().numpy())\n",
    "        \n",
    "        val_probs = np.vstack(val_probs)\n",
    "        test_probs = np.vstack(test_probs)\n",
    "        \n",
    "        # F1 individual\n",
    "        preds = np.argmax(val_probs, axis=1)\n",
    "        f1 = f1_score(val_labels, preds, average='macro')\n",
    "        print(f\"  F1-Macro: {f1:.5f}\")\n",
    "        \n",
    "        val_probs_ensemble.append(val_probs)\n",
    "        test_probs_ensemble.append(test_probs)\n",
    "        model_weights.append(f1)  # Peso = F1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ Erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ENSEMBLE E SUBMISSION =====\n",
    "def apply_thresholds(probs, thresholds):\n",
    "    preds = []\n",
    "    for i in range(len(probs)):\n",
    "        pred = np.argmax(probs[i])\n",
    "        for c in [6, 5]:\n",
    "            if probs[i, c] >= thresholds[c]:\n",
    "                pred = c\n",
    "                break\n",
    "        preds.append(pred)\n",
    "    return np.array(preds)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS ENSEMBLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Normalizar pesos\n",
    "weights = np.array(model_weights) / sum(model_weights)\n",
    "print(f\"Pesos: {weights}\")\n",
    "\n",
    "# Weighted average das probabilidades\n",
    "val_probs_avg = np.average(val_probs_ensemble, axis=0, weights=weights)\n",
    "test_probs_avg = np.average(test_probs_ensemble, axis=0, weights=weights)\n",
    "\n",
    "# Avaliar ensemble\n",
    "baseline_preds = np.argmax(val_probs_avg, axis=1)\n",
    "tuned_preds = apply_thresholds(val_probs_avg, THRESHOLDS)\n",
    "\n",
    "print(f\"Ensemble Baseline F1: {f1_score(val_labels, baseline_preds, average='macro'):.5f}\")\n",
    "print(f\"Ensemble Threshold F1: {f1_score(val_labels, tuned_preds, average='macro'):.5f}\")\n",
    "\n",
    "# Submission\n",
    "predictions = apply_thresholds(test_probs_avg, THRESHOLDS)\n",
    "submission = pd.DataFrame({'ID': test_df['ID'], 'target': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"\\nSubmission salva!\")\n",
    "print(submission['target'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
